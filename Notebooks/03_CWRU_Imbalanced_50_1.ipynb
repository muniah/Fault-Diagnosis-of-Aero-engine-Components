{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bearing Fault Diagnosis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk6QA7sU8I-X"
      },
      "source": [
        "### Load necessary packages and libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6H5bqQk1YMq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import scipy.io \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    log_loss,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    balanced_accuracy_score\n",
        ")\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gge1ED-8MZD"
      },
      "source": [
        "### Import Data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He3WGBPB2A-u",
        "outputId": "81e637c8-1962-4f61-f6b9-23704875251a"
      },
      "outputs": [],
      "source": [
        "folder_path1 = os.path.join(os.getcwd(), 'CWRU_data', '2HP')\n",
        "folder_path2 = os.path.join(os.getcwd(), 'CWRU_data', '3HP')\n",
        "\n",
        "def load_cwru_data(folder_path = folder_path1):\n",
        "    \"\"\"\n",
        "    Load CWRU bearing data from .mat files into a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the dataset folder.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with columns for condition, fault size, label, and signal.\n",
        "    \"\"\"\n",
        "    data_dict = {\n",
        "        'Condition': [],\n",
        "        'Fault Size (mm)': [],\n",
        "        'Fault Label': [],\n",
        "        'Signal': []\n",
        "    }\n",
        "\n",
        "    # Define file mappings: (file_id, condition, fault_size, fault_label)\n",
        "    file_mappings_2HP = [\n",
        "        ('99', 'Normal', 0, 0),\n",
        "        ('124', 'RE (Rolling element)', 0.18, 1),\n",
        "        ('111', 'IR (Inner ring)', 0.18, 2),\n",
        "        ('137', 'OR (Outer ring)', 0.18, 3),\n",
        "        ('191', 'RE (Rolling element)', 0.36, 4),\n",
        "        ('176', 'IR (Inner ring)', 0.36, 5),\n",
        "        ('203', 'OR (Outer ring)', 0.36, 6),\n",
        "        ('228', 'RE (Rolling element)', 0.54, 7),\n",
        "        ('215', 'IR (Inner ring)', 0.54, 8),\n",
        "        ('240', 'OR (Outer ring)', 0.54, 9)\n",
        "    ]\n",
        "    # file_mappings_3HP = [\n",
        "    #     ('100', 'Normal', 0, 0),\n",
        "    #     ('125', 'RE (Rolling element)', 0.18, 1),\n",
        "    #     ('112', 'IR (Inner ring)', 0.18, 2),\n",
        "    #     ('138', 'OR (Outer ring)', 0.18, 3),\n",
        "    #     ('192', 'RE (Rolling element)', 0.36, 4),\n",
        "    #     ('177', 'IR (Inner ring)', 0.36, 5),\n",
        "    #     ('204', 'OR (Outer ring)', 0.36, 6),\n",
        "    #     ('229', 'RE (Rolling element)', 0.54, 7),\n",
        "    #     ('217', 'IR (Inner ring)', 0.54, 8),\n",
        "    #     ('241', 'OR (Outer ring)', 0.54, 9)\n",
        "    # ]\n",
        "\n",
        "    for file_id, condition, fault_size, fault_label in file_mappings_2HP:\n",
        "    # for file_id, condition, fault_size, fault_label in file_mappings_3HP:\n",
        "        file_path = os.path.join(folder_path, f'{file_id}.mat')\n",
        "        if file_id == '99':\n",
        "            signal = scipy.io.loadmat(file_path)[f'X0{file_id}_DE_time'].flatten()\n",
        "        else:\n",
        "            signal = scipy.io.loadmat(file_path)[f'X{file_id}_DE_time'].flatten()\n",
        "        data_dict['Condition'].append(condition)\n",
        "        data_dict['Fault Size (mm)'].append(fault_size)\n",
        "        data_dict['Fault Label'].append(fault_label)\n",
        "        data_dict['Signal'].append(signal)\n",
        "\n",
        "    return pd.DataFrame(data_dict)\n",
        "\n",
        "df = load_cwru_data(folder_path=folder_path1)\n",
        "\n",
        "\n",
        "# Function to preprocess data for imbalance with different points for each label\n",
        "def preprocess_data_for_imbalance(df, start_point_dict, num_points_dict):\n",
        "    \"\"\"\n",
        "    Preprocess data by selecting a section of the signal for each fault label\n",
        "    based on a given start point and number of points for each label.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input DataFrame containing signals and labels.\n",
        "        start_point_dict (dict): Dictionary specifying the start point for each label.\n",
        "        num_points_dict (dict): Dictionary specifying the number of points for each label.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Processed DataFrame with signals for each label.\n",
        "    \"\"\"\n",
        "    processed_data = {\n",
        "        'Condition': [],\n",
        "        'Fault Size (mm)': [],\n",
        "        'Fault Label': [],\n",
        "        'Signal': []\n",
        "    }\n",
        "\n",
        "    for fault_label in df['Fault Label'].unique():\n",
        "        subset = df[df['Fault Label'] == fault_label]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        signal = subset.iloc[0]['Signal']\n",
        "        condition = subset.iloc[0]['Condition']\n",
        "        fault_size = subset.iloc[0]['Fault Size (mm)']\n",
        "\n",
        "        # Get start point and number of points for the current label\n",
        "        start_point = start_point_dict.get(fault_label, 0)  # Default start_point is 0\n",
        "        num_points = num_points_dict.get(fault_label, len(signal))  # Default is full signal length\n",
        "\n",
        "        # Validate range\n",
        "        if start_point >= len(signal):\n",
        "            print(f\"Start point {start_point} is out of range for signal with length {len(signal)}. Skipping Fault Label {fault_label}.\")\n",
        "            continue\n",
        "\n",
        "        end_point = min(start_point + num_points, len(signal))\n",
        "        signal_section = signal[start_point:end_point]\n",
        "\n",
        "        # Append to processed data\n",
        "        processed_data['Condition'].append(condition)\n",
        "        processed_data['Fault Size (mm)'].append(fault_size)\n",
        "        processed_data['Fault Label'].append(fault_label)\n",
        "        processed_data['Signal'].append(signal_section)\n",
        "\n",
        "    return pd.DataFrame(processed_data)\n",
        "\n",
        "# All classes start at index 0\n",
        "start_point_dict_train = {label: 0 for label in range(10)}\n",
        "\n",
        "# Imbalanced case: IR ratio = 50:1 for normal (class 0) vs. faults (classes 1–9)\n",
        "num_points_dict_train = {0: 480000, **{label: 9600 for label in range(1, 10)}}\n",
        "\n",
        "\n",
        "# Preprocess data and save to df_imbalance\n",
        "df_imbalance_train = preprocess_data_for_imbalance(df, start_point_dict_train, num_points_dict_train)\n",
        "\n",
        "\n",
        "# Function to preprocess data for imbalance with different points for each label\n",
        "\n",
        "# Sampling function\n",
        "def sampling(data, interval_length, samples_per_block, ignore_points=0):\n",
        "    \"\"\"\n",
        "    Split signal data into blocks with specified intervals and block size.\n",
        "    \n",
        "    Args:\n",
        "        data (np.array): Input signal data.\n",
        "        interval_length (int): Step size for sampling.\n",
        "        samples_per_block (int): Number of samples per block.\n",
        "        ignore_points (int): Number of points to ignore at the start and end.\n",
        "    \n",
        "    Returns:\n",
        "        np.array: Split data blocks.\n",
        "    \"\"\"\n",
        "    adjusted_length = len(data) - 2 * ignore_points\n",
        "    num_blocks = (\n",
        "        round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1\n",
        "    )\n",
        "    split_data = np.zeros([num_blocks, samples_per_block])\n",
        "\n",
        "    for i in range(num_blocks):\n",
        "        start_idx = ignore_points + i * interval_length\n",
        "        split_data[i, :] = data[start_idx:(start_idx + samples_per_block)].T\n",
        "\n",
        "    return split_data\n",
        "\n",
        "\n",
        "def data_preparation(data, interval_length, samples_per_block):\n",
        "    \"\"\"\n",
        "    Prepare data by splitting and labeling for multi-class classification.\n",
        "    \n",
        "    Args:\n",
        "        data (list): List of signal data for all classes.\n",
        "        interval_length (int): Step size for sampling.\n",
        "        samples_per_block (int): Number of samples per block.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: Prepared data (X), positional labels (y_positional), and class labels (y_class).\n",
        "    \"\"\"\n",
        "    for count, signal in enumerate(data):\n",
        "        split_data = sampling(signal, interval_length, samples_per_block)\n",
        "        y = np.zeros([len(split_data), 10])  # One-hot encoding\n",
        "        y[:, count] = 1\n",
        "        y_class = np.zeros([len(split_data), 1])\n",
        "        y_class[:, 0] = count\n",
        "\n",
        "        if count == 0:\n",
        "            X = split_data\n",
        "            y_positional = y\n",
        "            y_label = y_class\n",
        "        else:\n",
        "            X = np.append(X, split_data, axis=0)\n",
        "            y_positional = np.append(y_positional, y, axis=0)\n",
        "            y_label = np.append(y_label, y_class, axis=0)\n",
        "\n",
        "    return X, y_positional, y_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Condition</th>\n",
              "      <th>Fault Size (mm)</th>\n",
              "      <th>Fault Label</th>\n",
              "      <th>Signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Normal</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.06425353846153846, 0.06300184615384616, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RE (Rolling element)</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.09992676923076924, 0.14164984615384615, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IR (Inner ring)</td>\n",
              "      <td>0.18</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.06133292307692308, -0.015646153846153844, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OR (Outer ring)</td>\n",
              "      <td>0.18</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.967796, -1.7336026666666666, -2.226056, -2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RE (Rolling element)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.06446215384615385, 0.09575446153846154, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>IR (Inner ring)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.16568133333333332, 0.116436, 0.0626, 0.0171...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OR (Outer ring)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6</td>\n",
              "      <td>[-0.124752, -0.12913292307692306, -0.132053538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RE (Rolling element)</td>\n",
              "      <td>0.54</td>\n",
              "      <td>7</td>\n",
              "      <td>[-0.20360861538461536, -0.2953993846153846, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>IR (Inner ring)</td>\n",
              "      <td>0.54</td>\n",
              "      <td>8</td>\n",
              "      <td>[-0.3917796923076923, -0.3844781538461538, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>OR (Outer ring)</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9</td>\n",
              "      <td>[-0.3447173333333333, -0.4323573333333333, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Condition  Fault Size (mm)  Fault Label  \\\n",
              "0                Normal             0.00            0   \n",
              "1  RE (Rolling element)             0.18            1   \n",
              "2       IR (Inner ring)             0.18            2   \n",
              "3       OR (Outer ring)             0.18            3   \n",
              "4  RE (Rolling element)             0.36            4   \n",
              "5       IR (Inner ring)             0.36            5   \n",
              "6       OR (Outer ring)             0.36            6   \n",
              "7  RE (Rolling element)             0.54            7   \n",
              "8       IR (Inner ring)             0.54            8   \n",
              "9       OR (Outer ring)             0.54            9   \n",
              "\n",
              "                                              Signal  \n",
              "0  [0.06425353846153846, 0.06300184615384616, -0....  \n",
              "1  [0.09992676923076924, 0.14164984615384615, 0.1...  \n",
              "2  [0.06133292307692308, -0.015646153846153844, -...  \n",
              "3  [-0.967796, -1.7336026666666666, -2.226056, -2...  \n",
              "4  [0.06446215384615385, 0.09575446153846154, 0.1...  \n",
              "5  [0.16568133333333332, 0.116436, 0.0626, 0.0171...  \n",
              "6  [-0.124752, -0.12913292307692306, -0.132053538...  \n",
              "7  [-0.20360861538461536, -0.2953993846153846, -0...  \n",
              "8  [-0.3917796923076923, -0.3844781538461538, -0....  \n",
              "9  [-0.3447173333333333, -0.4323573333333333, -0....  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_imbalance_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare dataset with overlapping windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_datasets(df_imbalance, interval_length, samples_per_block):\n",
        "    \"\"\"\n",
        "    Prepare train or test datasets using the data_preparation function.\n",
        "    \n",
        "    Args:\n",
        "        df_imbalance (pd.DataFrame): DataFrame containing signals and labels.\n",
        "        interval_length (int): Interval length for sampling.\n",
        "        samples_per_block (int): Number of samples per block.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: X (input data), y_positional (one-hot labels), y_class (class labels).\n",
        "    \"\"\"\n",
        "    signals = df_imbalance['Signal'].tolist()\n",
        "    X, y_positional, y_class = data_preparation(signals, interval_length, samples_per_block)\n",
        "    return X, y_positional, y_class\n",
        "\n",
        "\n",
        "# Set parameters\n",
        "interval_length = 320\n",
        "samples_per_block = 1600\n",
        "\n",
        "\n",
        "# Prepare train datasets\n",
        "X, y_positional, y_class = prepare_datasets(df_imbalance_train, interval_length, samples_per_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1710, 1600), (1710, 10), (1710, 1))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y_positional.shape, y_class.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-uFyfwC-YjC"
      },
      "source": [
        "### Manual Splitting & K-Fold Cross Validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "da_1GFBK-arw"
      },
      "outputs": [],
      "source": [
        "def time_series_stratified_split(X, y, train_ratio = 0.8):\n",
        "    num_classes = y.shape[1]\n",
        "    X_train, y_train, X_test, y_test = [], [], [], []\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        cls_indices = np.where(np.argmax(y, axis=1) == cls)[0]\n",
        "        n_train = int(train_ratio * len(cls_indices))\n",
        "        train_idx, test_idx = cls_indices[:n_train], cls_indices[n_train:]\n",
        "        X_train.append(X[train_idx])\n",
        "        # print(\"X_train shape:\", len(X_train))\n",
        "        y_train.append(y[train_idx])\n",
        "        # print(\"y_train shape:\", len(X_train))\n",
        "        X_test.append(X[test_idx])\n",
        "        # print(\"X_train shape:\", len(X_train))\n",
        "        y_test.append(y[test_idx])\n",
        "        # print(\"y_test shape:\", len(X_train))\n",
        "\n",
        "    return (\n",
        "        np.concatenate(X_train),\n",
        "        np.concatenate(y_train),\n",
        "        np.concatenate(X_test),\n",
        "        np.concatenate(y_test)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "foldername_cnn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN\")\n",
        "foldername_cnn_attn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_Attention\")\n",
        "\n",
        "foldername_cnn_lstm = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_LSTM\")\n",
        "foldername_cnn_lstm_attn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_LSTM_Attention\")\n",
        "\n",
        "os.makedirs(foldername_cnn, exist_ok=True)\n",
        "os.makedirs(foldername_cnn_attn, exist_ok=True)\n",
        "os.makedirs(foldername_cnn_lstm, exist_ok=True)\n",
        "os.makedirs(foldername_cnn_lstm_attn, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1366, 1600, 1), (1366,), (344, 1600, 1), (344, 10), (1600, 1))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = time_series_stratified_split(X=X, y=y_positional, train_ratio=0.8)\n",
        "\n",
        "X_1D_train = X_train.reshape([-1, samples_per_block, 1])\n",
        "X_1D_test = X_test.reshape([-1, samples_per_block, 1])\n",
        "\n",
        "input_shape = (samples_per_block, 1)\n",
        "y_train_classes = np.argmax(y_train, axis=1)\n",
        "\n",
        "X_1D_train.shape, y_train_classes.shape, X_1D_test.shape, y_test.shape, input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "k_splits = 5\n",
        "kfold = StratifiedKFold(n_splits=k_splits, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBXqHhbRMNPC"
      },
      "source": [
        "## NEURAL NETWORK MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHL80WK2o_mC"
      },
      "source": [
        "### 1D CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p9VWHhd-6xE",
        "outputId": "dce5140c-5156-4389-e05e-9c992829163a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5616 - loss: 1.5502\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88686, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5804 - loss: 1.4961 - val_accuracy: 0.8869 - val_loss: 2.0761\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9018 - loss: 0.2726\n",
            "Epoch 2: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9018 - loss: 0.2727 - val_accuracy: 0.0146 - val_loss: 2.3637\n",
            "Epoch 3/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9217 - loss: 0.2466\n",
            "Epoch 3: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9216 - loss: 0.2459 - val_accuracy: 0.0146 - val_loss: 2.6490\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9456 - loss: 0.1904\n",
            "Epoch 4: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9453 - loss: 0.1906 - val_accuracy: 0.0146 - val_loss: 2.9543\n",
            "Epoch 5/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9406 - loss: 0.1716\n",
            "Epoch 5: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9404 - loss: 0.1719 - val_accuracy: 0.0146 - val_loss: 3.3448\n",
            "Epoch 6/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9445 - loss: 0.1771\n",
            "Epoch 6: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9448 - loss: 0.1753 - val_accuracy: 0.0146 - val_loss: 3.8462\n",
            "Epoch 7/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9464 - loss: 0.1628\n",
            "Epoch 7: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9470 - loss: 0.1606 - val_accuracy: 0.0146 - val_loss: 4.4266\n",
            "Epoch 8/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9523 - loss: 0.1401\n",
            "Epoch 8: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9526 - loss: 0.1392 - val_accuracy: 0.0146 - val_loss: 5.1120\n",
            "Epoch 9/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9596 - loss: 0.1119\n",
            "Epoch 9: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9594 - loss: 0.1122 - val_accuracy: 0.0146 - val_loss: 5.4644\n",
            "Epoch 10/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9528 - loss: 0.1065\n",
            "Epoch 10: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9533 - loss: 0.1069 - val_accuracy: 0.0146 - val_loss: 6.0474\n",
            "Epoch 11/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9676 - loss: 0.0898\n",
            "Epoch 11: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9674 - loss: 0.0902 - val_accuracy: 0.0146 - val_loss: 6.3213\n",
            "Epoch 12/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9652 - loss: 0.0866\n",
            "Epoch 12: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9647 - loss: 0.0872 - val_accuracy: 0.0146 - val_loss: 5.5580\n",
            "Epoch 13/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9503 - loss: 0.1030\n",
            "Epoch 13: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9509 - loss: 0.1026 - val_accuracy: 0.0292 - val_loss: 5.6466\n",
            "Epoch 14/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9679 - loss: 0.0960\n",
            "Epoch 14: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9681 - loss: 0.0950 - val_accuracy: 0.0401 - val_loss: 5.7638\n",
            "Epoch 15/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9678 - loss: 0.0825\n",
            "Epoch 15: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9681 - loss: 0.0822 - val_accuracy: 0.0365 - val_loss: 5.0522\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9672 - loss: 0.0828\n",
            "Epoch 16: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9674 - loss: 0.0825 - val_accuracy: 0.0547 - val_loss: 4.7742\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9732 - loss: 0.0607\n",
            "Epoch 17: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9733 - loss: 0.0610 - val_accuracy: 0.0547 - val_loss: 2.8153\n",
            "Epoch 18/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9796 - loss: 0.0634\n",
            "Epoch 18: val_accuracy improved from 0.88686 to 0.93431, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9794 - loss: 0.0633 - val_accuracy: 0.9343 - val_loss: 0.6837\n",
            "Epoch 19/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9724 - loss: 0.0720\n",
            "Epoch 19: val_accuracy improved from 0.93431 to 0.95620, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9725 - loss: 0.0710 - val_accuracy: 0.9562 - val_loss: 0.2684\n",
            "Epoch 20/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9749 - loss: 0.0607\n",
            "Epoch 20: val_accuracy improved from 0.95620 to 0.96350, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9748 - loss: 0.0610 - val_accuracy: 0.9635 - val_loss: 0.2496\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_1.keras\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7485 - loss: 1.4075\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7570 - loss: 1.3621 - val_accuracy: 0.8791 - val_loss: 1.7942\n",
            "Epoch 2/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9190 - loss: 0.2787\n",
            "Epoch 2: val_accuracy improved from 0.87912 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9186 - loss: 0.2786 - val_accuracy: 0.8901 - val_loss: 1.8692\n",
            "Epoch 3/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9134 - loss: 0.2522\n",
            "Epoch 3: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9139 - loss: 0.2508 - val_accuracy: 0.0147 - val_loss: 2.1603\n",
            "Epoch 4/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9309 - loss: 0.2054\n",
            "Epoch 4: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9311 - loss: 0.2057 - val_accuracy: 0.0147 - val_loss: 2.5183\n",
            "Epoch 5/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9296 - loss: 0.1785\n",
            "Epoch 5: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9292 - loss: 0.1796 - val_accuracy: 0.0147 - val_loss: 2.9453\n",
            "Epoch 6/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9418 - loss: 0.1835\n",
            "Epoch 6: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9415 - loss: 0.1828 - val_accuracy: 0.0147 - val_loss: 3.4463\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9363 - loss: 0.1769\n",
            "Epoch 7: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9366 - loss: 0.1762 - val_accuracy: 0.0147 - val_loss: 3.7329\n",
            "Epoch 8/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9603 - loss: 0.1309\n",
            "Epoch 8: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9604 - loss: 0.1309 - val_accuracy: 0.0147 - val_loss: 4.1741\n",
            "Epoch 9/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9608 - loss: 0.1284\n",
            "Epoch 9: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.1279 - val_accuracy: 0.0147 - val_loss: 5.0851\n",
            "Epoch 10/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9753 - loss: 0.0878\n",
            "Epoch 10: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9748 - loss: 0.0886 - val_accuracy: 0.0147 - val_loss: 6.1034\n",
            "Epoch 11/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9620 - loss: 0.1105\n",
            "Epoch 11: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9617 - loss: 0.1108 - val_accuracy: 0.0147 - val_loss: 6.4433\n",
            "Epoch 12/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9495 - loss: 0.1110\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9498 - loss: 0.1108 - val_accuracy: 0.0220 - val_loss: 6.8754\n",
            "Epoch 13/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9710 - loss: 0.0866\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9710 - loss: 0.0866 - val_accuracy: 0.0366 - val_loss: 6.2436\n",
            "Epoch 14/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9749 - loss: 0.0682\n",
            "Epoch 14: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9743 - loss: 0.0691 - val_accuracy: 0.0293 - val_loss: 4.1877\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9685 - loss: 0.0878\n",
            "Epoch 15: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9685 - loss: 0.0877 - val_accuracy: 0.0330 - val_loss: 4.3599\n",
            "Epoch 16/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9735 - loss: 0.0696\n",
            "Epoch 16: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9736 - loss: 0.0705 - val_accuracy: 0.0623 - val_loss: 1.6587\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9798 - loss: 0.0631\n",
            "Epoch 17: val_accuracy improved from 0.89011 to 0.93773, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9798 - loss: 0.0632 - val_accuracy: 0.9377 - val_loss: 0.5660\n",
            "Epoch 18/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9753 - loss: 0.0608\n",
            "Epoch 18: val_accuracy improved from 0.93773 to 0.94872, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.0614 - val_accuracy: 0.9487 - val_loss: 0.2074\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9819 - loss: 0.0674\n",
            "Epoch 19: val_accuracy improved from 0.94872 to 0.96337, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9819 - loss: 0.0673 - val_accuracy: 0.9634 - val_loss: 0.1209\n",
            "Epoch 20/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9687 - loss: 0.0594\n",
            "Epoch 20: val_accuracy improved from 0.96337 to 0.96703, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9687 - loss: 0.0594 - val_accuracy: 0.9670 - val_loss: 0.1157\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_2.keras\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5822 - loss: 1.5579\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5935 - loss: 1.5233 - val_accuracy: 0.8791 - val_loss: 1.8625\n",
            "Epoch 2/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9154 - loss: 0.2641\n",
            "Epoch 2: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9148 - loss: 0.2645 - val_accuracy: 0.8755 - val_loss: 1.8948\n",
            "Epoch 3/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9148 - loss: 0.2602\n",
            "Epoch 3: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9151 - loss: 0.2580 - val_accuracy: 0.0256 - val_loss: 2.0834\n",
            "Epoch 4/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9434 - loss: 0.1822\n",
            "Epoch 4: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9432 - loss: 0.1828 - val_accuracy: 0.0147 - val_loss: 2.3980\n",
            "Epoch 5/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9179 - loss: 0.2197\n",
            "Epoch 5: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9188 - loss: 0.2172 - val_accuracy: 0.0147 - val_loss: 2.5849\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9498 - loss: 0.1491\n",
            "Epoch 6: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9499 - loss: 0.1489 - val_accuracy: 0.0220 - val_loss: 2.8186\n",
            "Epoch 7/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9525 - loss: 0.1583\n",
            "Epoch 7: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9522 - loss: 0.1575 - val_accuracy: 0.0147 - val_loss: 3.1037\n",
            "Epoch 8/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9544 - loss: 0.1301\n",
            "Epoch 8: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9542 - loss: 0.1305 - val_accuracy: 0.0147 - val_loss: 3.2704\n",
            "Epoch 9/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9630 - loss: 0.1207\n",
            "Epoch 9: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9631 - loss: 0.1205 - val_accuracy: 0.0147 - val_loss: 3.8072\n",
            "Epoch 10/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9590 - loss: 0.1339\n",
            "Epoch 10: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9593 - loss: 0.1328 - val_accuracy: 0.0147 - val_loss: 3.9955\n",
            "Epoch 11/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9575 - loss: 0.1145\n",
            "Epoch 11: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9577 - loss: 0.1136 - val_accuracy: 0.0147 - val_loss: 4.0493\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9642 - loss: 0.0966\n",
            "Epoch 12: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 0.0966 - val_accuracy: 0.0147 - val_loss: 4.0596\n",
            "Epoch 13/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9792 - loss: 0.0689\n",
            "Epoch 13: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9787 - loss: 0.0697 - val_accuracy: 0.0183 - val_loss: 3.2468\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9778 - loss: 0.0712\n",
            "Epoch 14: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9776 - loss: 0.0717 - val_accuracy: 0.0147 - val_loss: 2.0501\n",
            "Epoch 15/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0614\n",
            "Epoch 15: val_accuracy improved from 0.87912 to 0.91209, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9817 - loss: 0.0623 - val_accuracy: 0.9121 - val_loss: 0.5596\n",
            "Epoch 16/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9598 - loss: 0.0813\n",
            "Epoch 16: val_accuracy improved from 0.91209 to 0.94139, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9603 - loss: 0.0810 - val_accuracy: 0.9414 - val_loss: 0.3225\n",
            "Epoch 17/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9704 - loss: 0.0684\n",
            "Epoch 17: val_accuracy did not improve from 0.94139\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9699 - loss: 0.0693 - val_accuracy: 0.9377 - val_loss: 0.2350\n",
            "Epoch 18/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9739 - loss: 0.0707\n",
            "Epoch 18: val_accuracy improved from 0.94139 to 0.94505, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9739 - loss: 0.0708 - val_accuracy: 0.9451 - val_loss: 0.1253\n",
            "Epoch 19/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.0575\n",
            "Epoch 19: val_accuracy improved from 0.94505 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9823 - loss: 0.0578 - val_accuracy: 0.9707 - val_loss: 0.0856\n",
            "Epoch 20/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9803 - loss: 0.0472\n",
            "Epoch 20: val_accuracy improved from 0.97070 to 0.97436, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9802 - loss: 0.0476 - val_accuracy: 0.9744 - val_loss: 0.0604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_3.keras\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m32/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5255 - loss: 1.8201\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5515 - loss: 1.7447 - val_accuracy: 0.8755 - val_loss: 1.8738\n",
            "Epoch 2/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8859 - loss: 0.3447\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8868 - loss: 0.3426 - val_accuracy: 0.8755 - val_loss: 1.9801\n",
            "Epoch 3/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9133 - loss: 0.2543\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9134 - loss: 0.2541 - val_accuracy: 0.0110 - val_loss: 2.2861\n",
            "Epoch 4/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9135 - loss: 0.2333\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9139 - loss: 0.2333 - val_accuracy: 0.0110 - val_loss: 2.5516\n",
            "Epoch 5/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9266 - loss: 0.2017\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9267 - loss: 0.2027 - val_accuracy: 0.0256 - val_loss: 2.8851\n",
            "Epoch 6/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9349 - loss: 0.1917\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9343 - loss: 0.1926 - val_accuracy: 0.0147 - val_loss: 3.4628\n",
            "Epoch 7/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9398 - loss: 0.1733\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9401 - loss: 0.1730 - val_accuracy: 0.0147 - val_loss: 4.2233\n",
            "Epoch 8/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9634 - loss: 0.1242\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.1256 - val_accuracy: 0.0147 - val_loss: 4.9147\n",
            "Epoch 9/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9537 - loss: 0.1294\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9538 - loss: 0.1294 - val_accuracy: 0.0147 - val_loss: 5.5177\n",
            "Epoch 10/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9468 - loss: 0.1479\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9472 - loss: 0.1468 - val_accuracy: 0.0147 - val_loss: 6.4655\n",
            "Epoch 11/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.1035\n",
            "Epoch 11: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9677 - loss: 0.1043 - val_accuracy: 0.0147 - val_loss: 7.3317\n",
            "Epoch 12/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9657 - loss: 0.0982\n",
            "Epoch 12: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9651 - loss: 0.0990 - val_accuracy: 0.0147 - val_loss: 8.0895\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9746 - loss: 0.0890\n",
            "Epoch 13: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9743 - loss: 0.0894 - val_accuracy: 0.0147 - val_loss: 8.1006\n",
            "Epoch 14/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9676 - loss: 0.0886\n",
            "Epoch 14: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9672 - loss: 0.0891 - val_accuracy: 0.0183 - val_loss: 7.1294\n",
            "Epoch 15/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9594 - loss: 0.1064\n",
            "Epoch 15: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9599 - loss: 0.1049 - val_accuracy: 0.0220 - val_loss: 5.5880\n",
            "Epoch 16/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9720 - loss: 0.0747\n",
            "Epoch 16: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9716 - loss: 0.0753 - val_accuracy: 0.0440 - val_loss: 5.3678\n",
            "Epoch 17/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9690 - loss: 0.0671\n",
            "Epoch 17: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9689 - loss: 0.0677 - val_accuracy: 0.0440 - val_loss: 3.4640\n",
            "Epoch 18/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9694 - loss: 0.0745\n",
            "Epoch 18: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0743 - val_accuracy: 0.0659 - val_loss: 2.1606\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9676 - loss: 0.0820\n",
            "Epoch 19: val_accuracy improved from 0.87546 to 0.93040, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9676 - loss: 0.0817 - val_accuracy: 0.9304 - val_loss: 0.9819\n",
            "Epoch 20/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9662 - loss: 0.0815\n",
            "Epoch 20: val_accuracy improved from 0.93040 to 0.94139, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9669 - loss: 0.0801 - val_accuracy: 0.9414 - val_loss: 0.1456\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m 8/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_4.keras\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,098</span> (51.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,098\u001b[0m (51.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,874</span> (50.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,874\u001b[0m (50.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7098 - loss: 1.2275\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7132 - loss: 1.2142 - val_accuracy: 0.8755 - val_loss: 2.0433\n",
            "Epoch 2/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8960 - loss: 0.2782\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8963 - loss: 0.2770 - val_accuracy: 0.0147 - val_loss: 2.3133\n",
            "Epoch 3/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9246 - loss: 0.2236\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9241 - loss: 0.2237 - val_accuracy: 0.0147 - val_loss: 2.7440\n",
            "Epoch 4/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9209 - loss: 0.2129\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9209 - loss: 0.2123 - val_accuracy: 0.0147 - val_loss: 3.1618\n",
            "Epoch 5/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9281 - loss: 0.1931\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9289 - loss: 0.1921 - val_accuracy: 0.0147 - val_loss: 3.6555\n",
            "Epoch 6/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9315 - loss: 0.1721\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9317 - loss: 0.1719 - val_accuracy: 0.0147 - val_loss: 4.3932\n",
            "Epoch 7/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9489 - loss: 0.1614\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9481 - loss: 0.1611 - val_accuracy: 0.0147 - val_loss: 4.9137\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9490 - loss: 0.1308\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9489 - loss: 0.1313 - val_accuracy: 0.0220 - val_loss: 5.6269\n",
            "Epoch 9/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9555 - loss: 0.1339\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9553 - loss: 0.1339 - val_accuracy: 0.0220 - val_loss: 5.9858\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9638 - loss: 0.1163\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9635 - loss: 0.1166 - val_accuracy: 0.0183 - val_loss: 6.7788\n",
            "Epoch 11/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9632 - loss: 0.1036\n",
            "Epoch 11: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9620 - loss: 0.1049 - val_accuracy: 0.0220 - val_loss: 7.0674\n",
            "Epoch 12/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9525 - loss: 0.1306\n",
            "Epoch 12: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9524 - loss: 0.1301 - val_accuracy: 0.0147 - val_loss: 7.3407\n",
            "Epoch 13/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9579 - loss: 0.1081\n",
            "Epoch 13: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9580 - loss: 0.1079 - val_accuracy: 0.0256 - val_loss: 6.2263\n",
            "Epoch 14/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9547 - loss: 0.1005\n",
            "Epoch 14: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9547 - loss: 0.1005 - val_accuracy: 0.0220 - val_loss: 6.7078\n",
            "Epoch 15/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9705 - loss: 0.0793\n",
            "Epoch 15: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9704 - loss: 0.0794 - val_accuracy: 0.0330 - val_loss: 6.9608\n",
            "Epoch 16/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9676 - loss: 0.0954\n",
            "Epoch 16: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9678 - loss: 0.0945 - val_accuracy: 0.0586 - val_loss: 3.9133\n",
            "Epoch 17/20\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9784 - loss: 0.0741\n",
            "Epoch 17: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9780 - loss: 0.0748 - val_accuracy: 0.0549 - val_loss: 3.6284\n",
            "Epoch 18/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9751 - loss: 0.0813\n",
            "Epoch 18: val_accuracy improved from 0.87546 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9752 - loss: 0.0811 - val_accuracy: 0.9560 - val_loss: 0.8481\n",
            "Epoch 19/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9692 - loss: 0.0688\n",
            "Epoch 19: val_accuracy improved from 0.95604 to 0.96337, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9695 - loss: 0.0687 - val_accuracy: 0.9634 - val_loss: 0.3725\n",
            "Epoch 20/20\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.0572\n",
            "Epoch 20: val_accuracy improved from 0.96337 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9796 - loss: 0.0575 - val_accuracy: 0.9707 - val_loss: 0.1398\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN/best_model_5.keras\n"
          ]
        }
      ],
      "source": [
        "class CNN_1D():\n",
        "    def __init__(self):\n",
        "        self.model = self.CreateModel()\n",
        "        self.model.summary()\n",
        "\n",
        "    def CreateModel(self):\n",
        "        model = models.Sequential([\n",
        "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool1D(pool_size=2),\n",
        "            \n",
        "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool1D(pool_size=2),\n",
        "\n",
        "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool1D(pool_size=2),\n",
        "\n",
        "            layers.GlobalAveragePooling1D(),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        # Optimizer with a slightly higher learning rate\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                      metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "\n",
        "os.makedirs(foldername_cnn, exist_ok=True)\n",
        "\n",
        "\n",
        "# Metric storage\n",
        "accuracy_1D_cnn, precision_1D_cnn, recall_1D_cnn, f1_1D_cnn, log_loss_1D_cnn, balanced_accuracy_1D_cnn = [], [], [], [], [], []\n",
        "accuracy_1D_test_cnn, precision_1D_test_cnn, recall_1D_test_cnn, f1_1D_test_cnn, log_loss_1D_test_cnn, balanced_accuracy_1D_test_cnn = [], [], [], [], [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    checkpoint_filepath = os.path.join(foldername_cnn, f\"best_model_{fold + 1}.keras\")\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "                                 save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    model = CNN_1D()\n",
        "    model.model.fit(\n",
        "        X_1D_train[train_idx], y_train[train_idx],\n",
        "        validation_data=(X_1D_train[val_idx], y_train[val_idx]),\n",
        "        epochs=20,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "\n",
        "    best_model = load_model(checkpoint_filepath)\n",
        "\n",
        "    # Train fold subset evaluation\n",
        "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "\n",
        "    accuracy_1D_cnn.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "    precision_1D_cnn.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    recall_1D_cnn.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    f1_1D_cnn.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    log_loss_1D_cnn.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "    balanced_accuracy_1D_cnn.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "\n",
        "\n",
        "    # Save confusion matrix for train\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'1D CNN Train Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Fixed test set evaluation\n",
        "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "    y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    accuracy_1D_test_cnn.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "    precision_1D_test_cnn.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    recall_1D_test_cnn.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    f1_1D_test_cnn.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    log_loss_1D_test_cnn.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "    balanced_accuracy_1D_test_cnn.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "\n",
        "    # Save confusion matrix for test\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "    plt.title(f'1D CNN Test Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    print(f\"Best model saved at: {checkpoint_filepath}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1D CNN Metrics:\n",
            "Train Accuracy: [0.951, 0.976, 0.983, 0.956, 0.968]\n",
            "Test Accuracy: [0.939, 0.965, 0.962, 0.948, 0.956]\n",
            "Precision: [0.937, 0.961, 0.959, 0.937, 0.956]\n",
            "Recall: [0.939, 0.965, 0.962, 0.948, 0.956]\n",
            "F1 Score: [0.931, 0.96, 0.956, 0.936, 0.952]\n",
            "Log Loss: [0.291, 0.171, 0.094, 0.186, 0.185]\n",
            "Balanced Accuracy: [0.58, 0.76, 0.74, 0.64, 0.7]\n"
          ]
        }
      ],
      "source": [
        "print(\"1D CNN Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_1D_cnn}\")\n",
        "print(f\"Test Accuracy: {accuracy_1D_test_cnn}\")\n",
        "print(f\"Precision: {precision_1D_test_cnn}\")\n",
        "print(f\"Recall: {recall_1D_test_cnn}\")\n",
        "print(f\"F1 Score: {f1_1D_test_cnn}\")\n",
        "print(f\"Log Loss: {log_loss_1D_test_cnn}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_1D_test_cnn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D CNN + Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_85\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_85\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_55… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_56… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_57    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_57… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_57… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_90 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_91 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_55… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_92 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_56… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_57    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_57… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_57… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_85\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_85\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_55… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_56… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_57    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_57… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_57… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_90 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_91 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_55… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_92 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_56… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_57    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_57… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_57… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7630 - loss: 1.0298\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88686, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.7680 - loss: 1.0047 - val_accuracy: 0.8869 - val_loss: 1.2099\n",
            "Epoch 2/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9045 - loss: 0.2790\n",
            "Epoch 2: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9044 - loss: 0.2784 - val_accuracy: 0.8869 - val_loss: 1.2388\n",
            "Epoch 3/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9002 - loss: 0.2949\n",
            "Epoch 3: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9010 - loss: 0.2932 - val_accuracy: 0.0219 - val_loss: 4.9043\n",
            "Epoch 4/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9433 - loss: 0.1956\n",
            "Epoch 4: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9427 - loss: 0.1972 - val_accuracy: 0.0292 - val_loss: 5.0327\n",
            "Epoch 5/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9190 - loss: 0.2237\n",
            "Epoch 5: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9193 - loss: 0.2229 - val_accuracy: 0.0146 - val_loss: 5.6131\n",
            "Epoch 6/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9326 - loss: 0.1972\n",
            "Epoch 6: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9327 - loss: 0.1963 - val_accuracy: 0.0146 - val_loss: 5.9524\n",
            "Epoch 7/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9359 - loss: 0.1678\n",
            "Epoch 7: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9361 - loss: 0.1678 - val_accuracy: 0.0146 - val_loss: 6.7815\n",
            "Epoch 8/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9423 - loss: 0.1598\n",
            "Epoch 8: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9427 - loss: 0.1592 - val_accuracy: 0.0146 - val_loss: 7.3728\n",
            "Epoch 9/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9525 - loss: 0.1466\n",
            "Epoch 9: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9526 - loss: 0.1460 - val_accuracy: 0.0146 - val_loss: 7.6709\n",
            "Epoch 10/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9471 - loss: 0.1281\n",
            "Epoch 10: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9476 - loss: 0.1276 - val_accuracy: 0.0146 - val_loss: 8.9205\n",
            "Epoch 11/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9521 - loss: 0.1317\n",
            "Epoch 11: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9525 - loss: 0.1312 - val_accuracy: 0.0292 - val_loss: 8.3956\n",
            "Epoch 12/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9583 - loss: 0.1173\n",
            "Epoch 12: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9582 - loss: 0.1169 - val_accuracy: 0.0292 - val_loss: 7.9493\n",
            "Epoch 13/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9669 - loss: 0.0949\n",
            "Epoch 13: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9670 - loss: 0.0946 - val_accuracy: 0.0401 - val_loss: 8.8771\n",
            "Epoch 14/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9645 - loss: 0.0992\n",
            "Epoch 14: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9651 - loss: 0.0981 - val_accuracy: 0.0438 - val_loss: 6.9488\n",
            "Epoch 15/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9795 - loss: 0.0666\n",
            "Epoch 15: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9797 - loss: 0.0662 - val_accuracy: 0.0620 - val_loss: 5.9581\n",
            "Epoch 16/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9699 - loss: 0.0830\n",
            "Epoch 16: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9702 - loss: 0.0823 - val_accuracy: 0.0912 - val_loss: 4.9597\n",
            "Epoch 17/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9778 - loss: 0.0568\n",
            "Epoch 17: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9782 - loss: 0.0564 - val_accuracy: 0.1679 - val_loss: 1.5648\n",
            "Epoch 18/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9892 - loss: 0.0405\n",
            "Epoch 18: val_accuracy improved from 0.88686 to 0.98540, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9890 - loss: 0.0407 - val_accuracy: 0.9854 - val_loss: 0.1152\n",
            "Epoch 19/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9864 - loss: 0.0375\n",
            "Epoch 19: val_accuracy improved from 0.98540 to 0.99270, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9865 - loss: 0.0373 - val_accuracy: 0.9927 - val_loss: 0.0408\n",
            "Epoch 20/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9904 - loss: 0.0418\n",
            "Epoch 20: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9906 - loss: 0.0412 - val_accuracy: 0.9708 - val_loss: 0.0560\n",
            "Epoch 21/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9961 - loss: 0.0276\n",
            "Epoch 21: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9959 - loss: 0.0278 - val_accuracy: 0.9891 - val_loss: 0.0284\n",
            "Epoch 22/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9865 - loss: 0.0371\n",
            "Epoch 22: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9865 - loss: 0.0372 - val_accuracy: 0.9854 - val_loss: 0.0545\n",
            "Epoch 23/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9990 - loss: 0.0164\n",
            "Epoch 23: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9990 - loss: 0.0165 - val_accuracy: 0.9927 - val_loss: 0.0382\n",
            "Epoch 24/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9905 - loss: 0.0242\n",
            "Epoch 24: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9906 - loss: 0.0244 - val_accuracy: 0.9745 - val_loss: 0.0465\n",
            "Epoch 25/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9962 - loss: 0.0139\n",
            "Epoch 25: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.9962 - loss: 0.0141 - val_accuracy: 0.9745 - val_loss: 0.0677\n",
            "Epoch 26/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9980 - loss: 0.0109\n",
            "Epoch 26: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9980 - loss: 0.0109 - val_accuracy: 0.9781 - val_loss: 0.0855\n",
            "Epoch 27/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9954 - loss: 0.0160\n",
            "Epoch 27: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9955 - loss: 0.0158 - val_accuracy: 0.9818 - val_loss: 0.0472\n",
            "Epoch 28/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9983 - loss: 0.0082\n",
            "Epoch 28: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9984 - loss: 0.0082 - val_accuracy: 0.9854 - val_loss: 0.0600\n",
            "Epoch 29/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9955 - loss: 0.0137\n",
            "Epoch 29: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.9708 - val_loss: 0.1042\n",
            "Epoch 30/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9947 - loss: 0.0163\n",
            "Epoch 30: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9946 - loss: 0.0164 - val_accuracy: 0.9672 - val_loss: 0.1314\n",
            "Epoch 31/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9973 - loss: 0.0115\n",
            "Epoch 31: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9972 - loss: 0.0116 - val_accuracy: 0.9854 - val_loss: 0.0541\n",
            "Epoch 32/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9981 - loss: 0.0101\n",
            "Epoch 32: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9980 - loss: 0.0102 - val_accuracy: 0.9891 - val_loss: 0.0364\n",
            "Epoch 33/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9964 - loss: 0.0135\n",
            "Epoch 33: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 0.9745 - val_loss: 0.1035\n",
            "Epoch 34/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9971 - loss: 0.0117\n",
            "Epoch 34: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9972 - loss: 0.0114 - val_accuracy: 0.9927 - val_loss: 0.0378\n",
            "Epoch 35/50\n",
            "\u001b[1m33/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 35: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9927 - val_loss: 0.0418\n",
            "Epoch 36/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9999 - loss: 0.0022\n",
            "Epoch 36: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9818 - val_loss: 0.0376\n",
            "Epoch 37/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9909 - loss: 0.0197\n",
            "Epoch 37: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9908 - loss: 0.0198 - val_accuracy: 0.9708 - val_loss: 0.0901\n",
            "Epoch 38/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0056\n",
            "Epoch 38: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9927 - val_loss: 0.0318\n",
            "Epoch 39/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9987 - loss: 0.0072\n",
            "Epoch 39: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9987 - loss: 0.0073 - val_accuracy: 0.9927 - val_loss: 0.0344\n",
            "Epoch 40/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9979 - loss: 0.0058\n",
            "Epoch 40: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9927 - val_loss: 0.0376\n",
            "Epoch 41/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9987 - loss: 0.0041\n",
            "Epoch 41: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9891 - val_loss: 0.0453\n",
            "Epoch 42/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9990 - loss: 0.0111\n",
            "Epoch 42: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9990 - loss: 0.0111 - val_accuracy: 0.9927 - val_loss: 0.0252\n",
            "Epoch 43/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9982 - loss: 0.0061\n",
            "Epoch 43: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9927 - val_loss: 0.0318\n",
            "Epoch 44/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 44: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9927 - val_loss: 0.0345\n",
            "Epoch 45/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9998 - loss: 0.0020\n",
            "Epoch 45: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9927 - val_loss: 0.0433\n",
            "Epoch 46/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 46: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9927 - val_loss: 0.0539\n",
            "Epoch 47/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9984 - loss: 0.0065\n",
            "Epoch 47: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9983 - loss: 0.0066 - val_accuracy: 0.9927 - val_loss: 0.0161\n",
            "Epoch 48/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9982 - loss: 0.0088\n",
            "Epoch 48: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9981 - loss: 0.0090 - val_accuracy: 0.9927 - val_loss: 0.0316\n",
            "Epoch 49/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9983 - loss: 0.0062\n",
            "Epoch 49: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.9891 - val_loss: 0.0211\n",
            "Epoch 50/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 50: val_accuracy improved from 0.99270 to 0.99635, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9964 - val_loss: 0.0276\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_1.keras\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_86\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_86\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_58    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_58… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_59    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_59… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_60    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_60… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_60… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_93 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_58    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_94 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_58… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_59    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_95 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_59… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_60    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_60… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_60… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_86\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_86\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_58    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_58… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_59    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_59… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_60    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_60… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_60… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_93 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_58    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_94 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_58… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_59    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_95 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_59… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_60    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_60… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_60… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6290 - loss: 1.3952\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6392 - loss: 1.3612 - val_accuracy: 0.8791 - val_loss: 0.9440\n",
            "Epoch 2/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9172 - loss: 0.2215\n",
            "Epoch 2: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.9164 - loss: 0.2234 - val_accuracy: 0.0183 - val_loss: 5.5734\n",
            "Epoch 3/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9044 - loss: 0.2501\n",
            "Epoch 3: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9048 - loss: 0.2495 - val_accuracy: 0.0147 - val_loss: 6.0571\n",
            "Epoch 4/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9213 - loss: 0.1967\n",
            "Epoch 4: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9211 - loss: 0.1977 - val_accuracy: 0.0147 - val_loss: 6.6365\n",
            "Epoch 5/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9295 - loss: 0.2109\n",
            "Epoch 5: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9297 - loss: 0.2099 - val_accuracy: 0.0147 - val_loss: 7.2962\n",
            "Epoch 6/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9267 - loss: 0.1964\n",
            "Epoch 6: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9272 - loss: 0.1952 - val_accuracy: 0.0147 - val_loss: 8.0276\n",
            "Epoch 7/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9369 - loss: 0.1622\n",
            "Epoch 7: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9371 - loss: 0.1618 - val_accuracy: 0.0147 - val_loss: 8.6821\n",
            "Epoch 8/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9564 - loss: 0.1353\n",
            "Epoch 8: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9562 - loss: 0.1356 - val_accuracy: 0.0220 - val_loss: 9.8501\n",
            "Epoch 9/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9683 - loss: 0.1095\n",
            "Epoch 9: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9679 - loss: 0.1100 - val_accuracy: 0.0256 - val_loss: 10.8200\n",
            "Epoch 10/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9554 - loss: 0.1090\n",
            "Epoch 10: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9557 - loss: 0.1087 - val_accuracy: 0.0256 - val_loss: 11.1793\n",
            "Epoch 11/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9662 - loss: 0.0951\n",
            "Epoch 11: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9660 - loss: 0.0950 - val_accuracy: 0.0220 - val_loss: 11.4883\n",
            "Epoch 12/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9733 - loss: 0.0849\n",
            "Epoch 12: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9732 - loss: 0.0849 - val_accuracy: 0.0110 - val_loss: 11.9600\n",
            "Epoch 13/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9723 - loss: 0.0812\n",
            "Epoch 13: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9722 - loss: 0.0812 - val_accuracy: 0.0220 - val_loss: 12.0999\n",
            "Epoch 14/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9745 - loss: 0.0712\n",
            "Epoch 14: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9744 - loss: 0.0716 - val_accuracy: 0.0220 - val_loss: 11.8218\n",
            "Epoch 15/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9846 - loss: 0.0529\n",
            "Epoch 15: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9842 - loss: 0.0535 - val_accuracy: 0.0220 - val_loss: 11.5678\n",
            "Epoch 16/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9660 - loss: 0.0744\n",
            "Epoch 16: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9664 - loss: 0.0740 - val_accuracy: 0.0293 - val_loss: 10.5042\n",
            "Epoch 17/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9693 - loss: 0.0703\n",
            "Epoch 17: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9697 - loss: 0.0696 - val_accuracy: 0.0549 - val_loss: 8.6427\n",
            "Epoch 18/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9776 - loss: 0.0572\n",
            "Epoch 18: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9779 - loss: 0.0568 - val_accuracy: 0.0623 - val_loss: 3.1573\n",
            "Epoch 19/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9873 - loss: 0.0532\n",
            "Epoch 19: val_accuracy improved from 0.87912 to 0.97436, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9869 - loss: 0.0533 - val_accuracy: 0.9744 - val_loss: 0.1063\n",
            "Epoch 20/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9780 - loss: 0.0594\n",
            "Epoch 20: val_accuracy improved from 0.97436 to 0.98168, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9782 - loss: 0.0592 - val_accuracy: 0.9817 - val_loss: 0.0521\n",
            "Epoch 21/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9752 - loss: 0.0609\n",
            "Epoch 21: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9749 - loss: 0.0615 - val_accuracy: 0.9670 - val_loss: 0.0823\n",
            "Epoch 22/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9837 - loss: 0.0453\n",
            "Epoch 22: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9838 - loss: 0.0452 - val_accuracy: 0.9634 - val_loss: 0.1364\n",
            "Epoch 23/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9822 - loss: 0.0567\n",
            "Epoch 23: val_accuracy improved from 0.98168 to 0.99634, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9821 - loss: 0.0565 - val_accuracy: 0.9963 - val_loss: 0.0241\n",
            "Epoch 24/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9854 - loss: 0.0323\n",
            "Epoch 24: val_accuracy did not improve from 0.99634\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9853 - loss: 0.0326 - val_accuracy: 0.9817 - val_loss: 0.0385\n",
            "Epoch 25/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9802 - loss: 0.0667\n",
            "Epoch 25: val_accuracy improved from 0.99634 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.9801 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9858 - loss: 0.0435\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9859 - loss: 0.0433 - val_accuracy: 0.9963 - val_loss: 0.0127\n",
            "Epoch 27/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9989 - loss: 0.0097\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - accuracy: 0.9989 - loss: 0.0099 - val_accuracy: 0.9963 - val_loss: 0.0096\n",
            "Epoch 28/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9981 - loss: 0.0148\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.9980 - loss: 0.0151 - val_accuracy: 0.9963 - val_loss: 0.0095\n",
            "Epoch 29/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0121\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 30/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9991 - loss: 0.0072\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9990 - loss: 0.0075 - val_accuracy: 0.9817 - val_loss: 0.0429\n",
            "Epoch 31/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9958 - loss: 0.0163\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.9958 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
            "Epoch 32/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9993 - loss: 0.0064\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9993 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 33/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9967 - loss: 0.0178\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.9967 - loss: 0.0178 - val_accuracy: 0.9963 - val_loss: 0.0081\n",
            "Epoch 34/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9960 - loss: 0.0146\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - accuracy: 0.9959 - loss: 0.0147 - val_accuracy: 0.9853 - val_loss: 0.0556\n",
            "Epoch 35/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9818 - loss: 0.0545\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9817 - loss: 0.0546 - val_accuracy: 0.9963 - val_loss: 0.0154\n",
            "Epoch 36/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9919 - loss: 0.0262\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9920 - loss: 0.0261 - val_accuracy: 0.9963 - val_loss: 0.0064\n",
            "Epoch 37/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9960 - loss: 0.0141\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
            "Epoch 38/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9990 - loss: 0.0082\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9989 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 39/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9990 - loss: 0.0090\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9990 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 40/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 41/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9964 - loss: 0.0126\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9890 - val_loss: 0.0167\n",
            "Epoch 42/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9968 - loss: 0.0087\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9963 - val_loss: 0.0075\n",
            "Epoch 43/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9966 - loss: 0.0096\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 44/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 45/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 7.6598e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 47/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0030\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 5.8806e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 4.6917e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 3.3750e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 3.0673e-04\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_2.keras\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_87\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_87\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_61… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_62… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_63… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_63… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_96 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_22[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_97 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_61… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_98 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_62… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_63… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_63… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_87\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_87\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_61… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_62… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_63… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_63… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_96 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_22[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_97 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_61… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_98 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_62… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_63… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_63… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7061 - loss: 1.1380\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7137 - loss: 1.1092 - val_accuracy: 0.8864 - val_loss: 1.0119\n",
            "Epoch 2/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9049 - loss: 0.2659\n",
            "Epoch 2: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9050 - loss: 0.2652 - val_accuracy: 0.8755 - val_loss: 0.9226\n",
            "Epoch 3/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9304 - loss: 0.2025\n",
            "Epoch 3: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9297 - loss: 0.2035 - val_accuracy: 0.8828 - val_loss: 0.4813\n",
            "Epoch 4/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9243 - loss: 0.1984\n",
            "Epoch 4: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9243 - loss: 0.1989 - val_accuracy: 0.0330 - val_loss: 2.7761\n",
            "Epoch 5/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9311 - loss: 0.1840\n",
            "Epoch 5: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9313 - loss: 0.1841 - val_accuracy: 0.0366 - val_loss: 5.2028\n",
            "Epoch 6/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9390 - loss: 0.1805\n",
            "Epoch 6: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9392 - loss: 0.1797 - val_accuracy: 0.0366 - val_loss: 5.4310\n",
            "Epoch 7/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9411 - loss: 0.1710\n",
            "Epoch 7: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9413 - loss: 0.1697 - val_accuracy: 0.0366 - val_loss: 4.7461\n",
            "Epoch 8/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9581 - loss: 0.1398\n",
            "Epoch 8: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9581 - loss: 0.1390 - val_accuracy: 0.0549 - val_loss: 5.4906\n",
            "Epoch 9/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9593 - loss: 0.1164\n",
            "Epoch 9: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9594 - loss: 0.1160 - val_accuracy: 0.0256 - val_loss: 5.4106\n",
            "Epoch 10/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9617 - loss: 0.0993\n",
            "Epoch 10: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9617 - loss: 0.0991 - val_accuracy: 0.0513 - val_loss: 5.5016\n",
            "Epoch 11/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9701 - loss: 0.0860\n",
            "Epoch 11: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9699 - loss: 0.0866 - val_accuracy: 0.0586 - val_loss: 4.0546\n",
            "Epoch 12/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9766 - loss: 0.0737\n",
            "Epoch 12: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9762 - loss: 0.0741 - val_accuracy: 0.0659 - val_loss: 3.3830\n",
            "Epoch 13/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9782 - loss: 0.0579\n",
            "Epoch 13: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9779 - loss: 0.0585 - val_accuracy: 0.0586 - val_loss: 2.7796\n",
            "Epoch 14/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9747 - loss: 0.0645\n",
            "Epoch 14: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9748 - loss: 0.0643 - val_accuracy: 0.0403 - val_loss: 4.3282\n",
            "Epoch 15/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9803 - loss: 0.0543\n",
            "Epoch 15: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9802 - loss: 0.0548 - val_accuracy: 0.0403 - val_loss: 2.6481\n",
            "Epoch 16/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9785 - loss: 0.0562\n",
            "Epoch 16: val_accuracy improved from 0.88645 to 0.91209, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9784 - loss: 0.0565 - val_accuracy: 0.9121 - val_loss: 0.3673\n",
            "Epoch 17/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9681 - loss: 0.0789\n",
            "Epoch 17: val_accuracy improved from 0.91209 to 0.97802, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9685 - loss: 0.0779 - val_accuracy: 0.9780 - val_loss: 0.0749\n",
            "Epoch 18/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9822 - loss: 0.0412\n",
            "Epoch 18: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.9820 - loss: 0.0417 - val_accuracy: 0.9560 - val_loss: 0.0937\n",
            "Epoch 19/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9863 - loss: 0.0416\n",
            "Epoch 19: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.9862 - loss: 0.0417 - val_accuracy: 0.9707 - val_loss: 0.0995\n",
            "Epoch 20/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9830 - loss: 0.0448\n",
            "Epoch 20: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.9829 - loss: 0.0451 - val_accuracy: 0.9524 - val_loss: 0.1034\n",
            "Epoch 21/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9674 - loss: 0.0665\n",
            "Epoch 21: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9679 - loss: 0.0657 - val_accuracy: 0.9670 - val_loss: 0.0617\n",
            "Epoch 22/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9788 - loss: 0.0438\n",
            "Epoch 22: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.9787 - loss: 0.0439 - val_accuracy: 0.9744 - val_loss: 0.0766\n",
            "Epoch 23/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9848 - loss: 0.0439\n",
            "Epoch 23: val_accuracy improved from 0.97802 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9847 - loss: 0.0439 - val_accuracy: 0.9890 - val_loss: 0.0371\n",
            "Epoch 24/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9916 - loss: 0.0315\n",
            "Epoch 24: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9915 - loss: 0.0316 - val_accuracy: 0.9744 - val_loss: 0.0635\n",
            "Epoch 25/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9878 - loss: 0.0310\n",
            "Epoch 25: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.9879 - loss: 0.0308 - val_accuracy: 0.9817 - val_loss: 0.0435\n",
            "Epoch 26/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9927 - loss: 0.0203\n",
            "Epoch 26: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9927 - loss: 0.0205 - val_accuracy: 0.9890 - val_loss: 0.0297\n",
            "Epoch 27/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9859 - loss: 0.0288\n",
            "Epoch 27: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9858 - loss: 0.0291 - val_accuracy: 0.9890 - val_loss: 0.0320\n",
            "Epoch 28/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9870 - loss: 0.0302\n",
            "Epoch 28: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.9870 - loss: 0.0303 - val_accuracy: 0.9817 - val_loss: 0.0580\n",
            "Epoch 29/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9980 - loss: 0.0182\n",
            "Epoch 29: val_accuracy improved from 0.98901 to 0.99267, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9980 - loss: 0.0182 - val_accuracy: 0.9927 - val_loss: 0.0184\n",
            "Epoch 30/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9897 - loss: 0.0386\n",
            "Epoch 30: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9896 - loss: 0.0389 - val_accuracy: 0.9890 - val_loss: 0.0400\n",
            "Epoch 31/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9782 - loss: 0.0496\n",
            "Epoch 31: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9785 - loss: 0.0493 - val_accuracy: 0.9414 - val_loss: 0.1483\n",
            "Epoch 32/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9916 - loss: 0.0272\n",
            "Epoch 32: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9917 - loss: 0.0271 - val_accuracy: 0.9927 - val_loss: 0.0295\n",
            "Epoch 33/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9653 - loss: 0.1016\n",
            "Epoch 33: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9651 - loss: 0.1022 - val_accuracy: 0.8974 - val_loss: 1.0368\n",
            "Epoch 34/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9797 - loss: 0.0590\n",
            "Epoch 34: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9794 - loss: 0.0595 - val_accuracy: 0.9377 - val_loss: 0.1201\n",
            "Epoch 35/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9688 - loss: 0.0733\n",
            "Epoch 35: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9688 - loss: 0.0734 - val_accuracy: 0.9524 - val_loss: 0.1090\n",
            "Epoch 36/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9813 - loss: 0.0444\n",
            "Epoch 36: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9818 - loss: 0.0437 - val_accuracy: 0.9780 - val_loss: 0.0616\n",
            "Epoch 37/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9904 - loss: 0.0337\n",
            "Epoch 37: val_accuracy improved from 0.99267 to 0.99634, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9905 - loss: 0.0335 - val_accuracy: 0.9963 - val_loss: 0.0261\n",
            "Epoch 38/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9931 - loss: 0.0201\n",
            "Epoch 38: val_accuracy did not improve from 0.99634\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9932 - loss: 0.0200 - val_accuracy: 0.9817 - val_loss: 0.0343\n",
            "Epoch 39/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9936 - loss: 0.0211\n",
            "Epoch 39: val_accuracy did not improve from 0.99634\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9936 - loss: 0.0210 - val_accuracy: 0.9927 - val_loss: 0.0271\n",
            "Epoch 40/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9969 - loss: 0.0173\n",
            "Epoch 40: val_accuracy did not improve from 0.99634\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9970 - loss: 0.0170 - val_accuracy: 0.9890 - val_loss: 0.0295\n",
            "Epoch 41/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9964 - loss: 0.0162\n",
            "Epoch 41: val_accuracy improved from 0.99634 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9964 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 42/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9993 - loss: 0.0094\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9993 - loss: 0.0095 - val_accuracy: 0.9780 - val_loss: 0.0474\n",
            "Epoch 43/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9950 - loss: 0.0153\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.9744 - val_loss: 0.0452\n",
            "Epoch 44/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9985 - loss: 0.0064\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9985 - loss: 0.0065 - val_accuracy: 0.9817 - val_loss: 0.0377\n",
            "Epoch 45/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9975 - loss: 0.0072\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
            "Epoch 46/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9997 - loss: 0.0073\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9997 - loss: 0.0073 - val_accuracy: 0.9963 - val_loss: 0.0153\n",
            "Epoch 47/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9967 - loss: 0.0115\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9968 - loss: 0.0113 - val_accuracy: 0.9890 - val_loss: 0.0226\n",
            "Epoch 48/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9983 - loss: 0.0056\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 49/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0042\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
            "Epoch 50/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_3.keras\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_88\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_88\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_23      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_64    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_64… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_65    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_65… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_66    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_66… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_66… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_50          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_23      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_99 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_64    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_100 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_64… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_65    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_101 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_65… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_66    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_66… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_66… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_50          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_88\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_88\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_23      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_64    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_64… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_65    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_65… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_66    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_66… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_66… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_50          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_23      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_99 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_64    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_100 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_64… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_65    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_101 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_65… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_66    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_66… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_66… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_50          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7315 - loss: 1.0344\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.7378 - loss: 1.0089 - val_accuracy: 0.8901 - val_loss: 0.5470\n",
            "Epoch 2/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9128 - loss: 0.2356\n",
            "Epoch 2: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9120 - loss: 0.2378 - val_accuracy: 0.0256 - val_loss: 5.2417\n",
            "Epoch 3/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9128 - loss: 0.2610\n",
            "Epoch 3: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9131 - loss: 0.2596 - val_accuracy: 0.0110 - val_loss: 5.5341\n",
            "Epoch 4/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9286 - loss: 0.2117\n",
            "Epoch 4: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9290 - loss: 0.2117 - val_accuracy: 0.0110 - val_loss: 5.9582\n",
            "Epoch 5/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9248 - loss: 0.1980\n",
            "Epoch 5: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9253 - loss: 0.1974 - val_accuracy: 0.0110 - val_loss: 6.4408\n",
            "Epoch 6/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9424 - loss: 0.1710\n",
            "Epoch 6: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9423 - loss: 0.1707 - val_accuracy: 0.0110 - val_loss: 7.4136\n",
            "Epoch 7/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9614 - loss: 0.1304\n",
            "Epoch 7: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9609 - loss: 0.1312 - val_accuracy: 0.0110 - val_loss: 8.4860\n",
            "Epoch 8/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9576 - loss: 0.1161\n",
            "Epoch 8: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9571 - loss: 0.1171 - val_accuracy: 0.0110 - val_loss: 8.9745\n",
            "Epoch 9/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9524 - loss: 0.1264\n",
            "Epoch 9: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9525 - loss: 0.1258 - val_accuracy: 0.0147 - val_loss: 8.7657\n",
            "Epoch 10/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9530 - loss: 0.1168\n",
            "Epoch 10: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9533 - loss: 0.1163 - val_accuracy: 0.0110 - val_loss: 9.6854\n",
            "Epoch 11/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9662 - loss: 0.1034\n",
            "Epoch 11: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9660 - loss: 0.1031 - val_accuracy: 0.0220 - val_loss: 10.2079\n",
            "Epoch 12/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9777 - loss: 0.0638\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9775 - loss: 0.0642 - val_accuracy: 0.0256 - val_loss: 10.3865\n",
            "Epoch 13/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9587 - loss: 0.1002\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9589 - loss: 0.0998 - val_accuracy: 0.0110 - val_loss: 10.6014\n",
            "Epoch 14/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9632 - loss: 0.0962\n",
            "Epoch 14: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9635 - loss: 0.0951 - val_accuracy: 0.0403 - val_loss: 10.6871\n",
            "Epoch 15/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9858 - loss: 0.0427\n",
            "Epoch 15: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9855 - loss: 0.0434 - val_accuracy: 0.0110 - val_loss: 11.0767\n",
            "Epoch 16/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9696 - loss: 0.0673\n",
            "Epoch 16: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9697 - loss: 0.0674 - val_accuracy: 0.0659 - val_loss: 10.1998\n",
            "Epoch 17/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9797 - loss: 0.0510\n",
            "Epoch 17: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9799 - loss: 0.0508 - val_accuracy: 0.0769 - val_loss: 4.6151\n",
            "Epoch 18/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9843 - loss: 0.0470\n",
            "Epoch 18: val_accuracy improved from 0.89011 to 0.95971, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9843 - loss: 0.0468 - val_accuracy: 0.9597 - val_loss: 0.4197\n",
            "Epoch 19/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9855 - loss: 0.0386\n",
            "Epoch 19: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9853 - loss: 0.0387 - val_accuracy: 0.9524 - val_loss: 0.2342\n",
            "Epoch 20/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9840 - loss: 0.0572\n",
            "Epoch 20: val_accuracy improved from 0.95971 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9841 - loss: 0.0567 - val_accuracy: 0.9707 - val_loss: 0.0872\n",
            "Epoch 21/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9890 - loss: 0.0399\n",
            "Epoch 21: val_accuracy improved from 0.97070 to 0.97802, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9890 - loss: 0.0396 - val_accuracy: 0.9780 - val_loss: 0.0516\n",
            "Epoch 22/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9951 - loss: 0.0214\n",
            "Epoch 22: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9950 - loss: 0.0216 - val_accuracy: 0.9707 - val_loss: 0.0553\n",
            "Epoch 23/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9794 - loss: 0.0628\n",
            "Epoch 23: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9794 - loss: 0.0628 - val_accuracy: 0.6996 - val_loss: 0.6430\n",
            "Epoch 24/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9909 - loss: 0.0283\n",
            "Epoch 24: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9909 - loss: 0.0281 - val_accuracy: 0.0842 - val_loss: 2.3464\n",
            "Epoch 25/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9885 - loss: 0.0320\n",
            "Epoch 25: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9885 - loss: 0.0320 - val_accuracy: 0.9744 - val_loss: 0.0993\n",
            "Epoch 26/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9911 - loss: 0.0228\n",
            "Epoch 26: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9912 - loss: 0.0228 - val_accuracy: 0.9744 - val_loss: 0.0470\n",
            "Epoch 27/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9881 - loss: 0.0253\n",
            "Epoch 27: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9880 - loss: 0.0256 - val_accuracy: 0.0916 - val_loss: 2.1987\n",
            "Epoch 28/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9954 - loss: 0.0163\n",
            "Epoch 28: val_accuracy improved from 0.97802 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9953 - loss: 0.0167 - val_accuracy: 0.9890 - val_loss: 0.0350\n",
            "Epoch 29/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9970 - loss: 0.0132\n",
            "Epoch 29: val_accuracy improved from 0.98901 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9970 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 30/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9995 - loss: 0.0095\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9994 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
            "Epoch 31/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9845 - loss: 0.0655\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9845 - loss: 0.0654 - val_accuracy: 0.9853 - val_loss: 0.0914\n",
            "Epoch 32/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9797 - loss: 0.0547\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9798 - loss: 0.0544 - val_accuracy: 1.0000 - val_loss: 0.0321\n",
            "Epoch 33/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9973 - loss: 0.0224\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9973 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
            "Epoch 34/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9964 - loss: 0.0164\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9964 - loss: 0.0163 - val_accuracy: 0.9853 - val_loss: 0.0230\n",
            "Epoch 35/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9961 - loss: 0.0137\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9962 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 36/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9993 - loss: 0.0053\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9993 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
            "Epoch 37/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9975 - loss: 0.0082\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 38/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9999 - loss: 0.0026\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 39/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9956 - loss: 0.0135\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 40/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9991 - loss: 0.0059\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 41/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9985 - loss: 0.0063\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
            "Epoch 42/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 43/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9992 - loss: 0.0032\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 44/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 45/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 46/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 6.4989e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 5.6063e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 6.4758e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 5.6456e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 9.8256e-04\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_4.keras\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_89\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_89\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_67    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_67… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_103[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_68    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_68… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_69    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_69… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_69… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_53          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_102 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_24[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_67    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_103 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_67… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_103[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_68    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_104 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_68… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_69    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_69… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_69… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_53          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_89\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_89\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_67    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ max_pooling1d_67… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_103[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_68    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_68… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_69    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ max_pooling1d_69… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_69… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_53          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_102 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ input_layer_24[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_67    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_103 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m1,568\u001b[0m │ max_pooling1d_67… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_103[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_68    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_104 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_68… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_69    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ max_pooling1d_69… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_69… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_53          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,994</span> (117.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,994\u001b[0m (117.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,770</span> (116.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,770\u001b[0m (116.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7219 - loss: 1.1200\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.7288 - loss: 1.0933 - val_accuracy: 0.8755 - val_loss: 1.0321\n",
            "Epoch 2/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8995 - loss: 0.2896\n",
            "Epoch 2: val_accuracy improved from 0.87546 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8995 - loss: 0.2891 - val_accuracy: 0.8901 - val_loss: 0.5462\n",
            "Epoch 3/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9018 - loss: 0.2707\n",
            "Epoch 3: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9024 - loss: 0.2694 - val_accuracy: 0.0183 - val_loss: 4.9174\n",
            "Epoch 4/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9124 - loss: 0.2377\n",
            "Epoch 4: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9132 - loss: 0.2361 - val_accuracy: 0.0147 - val_loss: 6.5224\n",
            "Epoch 5/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9434 - loss: 0.1754\n",
            "Epoch 5: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9433 - loss: 0.1761 - val_accuracy: 0.0147 - val_loss: 7.2308\n",
            "Epoch 6/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9259 - loss: 0.1982\n",
            "Epoch 6: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9268 - loss: 0.1964 - val_accuracy: 0.0147 - val_loss: 7.7479\n",
            "Epoch 7/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9498 - loss: 0.1482\n",
            "Epoch 7: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9497 - loss: 0.1482 - val_accuracy: 0.0147 - val_loss: 9.3138\n",
            "Epoch 8/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9530 - loss: 0.1402\n",
            "Epoch 8: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9529 - loss: 0.1401 - val_accuracy: 0.0147 - val_loss: 8.7685\n",
            "Epoch 9/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9712 - loss: 0.1015\n",
            "Epoch 9: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9706 - loss: 0.1026 - val_accuracy: 0.0147 - val_loss: 8.2024\n",
            "Epoch 10/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9646 - loss: 0.1008\n",
            "Epoch 10: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9639 - loss: 0.1019 - val_accuracy: 0.0147 - val_loss: 8.4265\n",
            "Epoch 11/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9552 - loss: 0.1206\n",
            "Epoch 11: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9554 - loss: 0.1198 - val_accuracy: 0.0147 - val_loss: 7.3182\n",
            "Epoch 12/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9697 - loss: 0.0925\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9695 - loss: 0.0927 - val_accuracy: 0.0256 - val_loss: 6.1887\n",
            "Epoch 13/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9685 - loss: 0.0770\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9683 - loss: 0.0776 - val_accuracy: 0.0293 - val_loss: 6.9579\n",
            "Epoch 14/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9641 - loss: 0.1058\n",
            "Epoch 14: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9639 - loss: 0.1057 - val_accuracy: 0.0293 - val_loss: 8.1331\n",
            "Epoch 15/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9645 - loss: 0.0848\n",
            "Epoch 15: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9647 - loss: 0.0845 - val_accuracy: 0.0293 - val_loss: 7.7403\n",
            "Epoch 16/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9806 - loss: 0.0502\n",
            "Epoch 16: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9803 - loss: 0.0509 - val_accuracy: 0.0586 - val_loss: 7.8865\n",
            "Epoch 17/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9768 - loss: 0.0602\n",
            "Epoch 17: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9769 - loss: 0.0600 - val_accuracy: 0.0476 - val_loss: 8.3671\n",
            "Epoch 18/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9797 - loss: 0.0584\n",
            "Epoch 18: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9796 - loss: 0.0584 - val_accuracy: 0.3590 - val_loss: 1.2379\n",
            "Epoch 19/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - loss: 0.0834\n",
            "Epoch 19: val_accuracy improved from 0.89011 to 0.94505, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9656 - loss: 0.0833 - val_accuracy: 0.9451 - val_loss: 0.1858\n",
            "Epoch 20/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9773 - loss: 0.0597\n",
            "Epoch 20: val_accuracy improved from 0.94505 to 0.97436, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9773 - loss: 0.0596 - val_accuracy: 0.9744 - val_loss: 0.0528\n",
            "Epoch 21/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9811 - loss: 0.0471\n",
            "Epoch 21: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9811 - loss: 0.0472 - val_accuracy: 0.9744 - val_loss: 0.0441\n",
            "Epoch 22/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9867 - loss: 0.0364\n",
            "Epoch 22: val_accuracy improved from 0.97436 to 0.98535, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9865 - loss: 0.0368 - val_accuracy: 0.9853 - val_loss: 0.0397\n",
            "Epoch 23/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9529 - loss: 0.1165\n",
            "Epoch 23: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9533 - loss: 0.1155 - val_accuracy: 0.1941 - val_loss: 2.3108\n",
            "Epoch 24/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9786 - loss: 0.0607\n",
            "Epoch 24: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9786 - loss: 0.0605 - val_accuracy: 0.9817 - val_loss: 0.0680\n",
            "Epoch 25/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9851 - loss: 0.0445\n",
            "Epoch 25: val_accuracy improved from 0.98535 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9852 - loss: 0.0441 - val_accuracy: 0.9890 - val_loss: 0.0356\n",
            "Epoch 26/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9918 - loss: 0.0335\n",
            "Epoch 26: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9917 - loss: 0.0334 - val_accuracy: 0.9853 - val_loss: 0.0307\n",
            "Epoch 27/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9893 - loss: 0.0325\n",
            "Epoch 27: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9894 - loss: 0.0324 - val_accuracy: 0.9890 - val_loss: 0.0221\n",
            "Epoch 28/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9926 - loss: 0.0209\n",
            "Epoch 28: val_accuracy improved from 0.98901 to 0.99267, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9926 - loss: 0.0211 - val_accuracy: 0.9927 - val_loss: 0.0192\n",
            "Epoch 29/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9971 - loss: 0.0150\n",
            "Epoch 29: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9972 - loss: 0.0149 - val_accuracy: 0.9853 - val_loss: 0.0270\n",
            "Epoch 30/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9946 - loss: 0.0219\n",
            "Epoch 30: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9944 - loss: 0.0221 - val_accuracy: 0.9927 - val_loss: 0.0196\n",
            "Epoch 31/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9960 - loss: 0.0179\n",
            "Epoch 31: val_accuracy improved from 0.99267 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9960 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
            "Epoch 32/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9966 - loss: 0.0126\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9967 - loss: 0.0126 - val_accuracy: 0.9963 - val_loss: 0.0064\n",
            "Epoch 33/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9911 - loss: 0.0167\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9911 - loss: 0.0175 - val_accuracy: 0.9963 - val_loss: 0.0128\n",
            "Epoch 34/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9803 - loss: 0.0560\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9804 - loss: 0.0555 - val_accuracy: 0.9963 - val_loss: 0.0321\n",
            "Epoch 35/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9930 - loss: 0.0277\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9932 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
            "Epoch 36/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9956 - loss: 0.0198\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9957 - loss: 0.0196 - val_accuracy: 0.9927 - val_loss: 0.0146\n",
            "Epoch 37/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9951 - loss: 0.0185\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9951 - loss: 0.0185 - val_accuracy: 0.9927 - val_loss: 0.0131\n",
            "Epoch 38/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9945 - loss: 0.0124\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9946 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
            "Epoch 39/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9960 - loss: 0.0142\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9960 - loss: 0.0141 - val_accuracy: 0.9927 - val_loss: 0.0157\n",
            "Epoch 40/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0109\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9985 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 41/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9843 - loss: 0.0402\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9841 - loss: 0.0407 - val_accuracy: 0.9927 - val_loss: 0.0251\n",
            "Epoch 42/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9895 - loss: 0.0278\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9896 - loss: 0.0281 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
            "Epoch 43/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9991 - loss: 0.0099\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9991 - loss: 0.0098 - val_accuracy: 0.9963 - val_loss: 0.0136\n",
            "Epoch 44/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9948 - loss: 0.0106\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9950 - loss: 0.0106 - val_accuracy: 0.9963 - val_loss: 0.0100\n",
            "Epoch 45/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0055\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9963 - val_loss: 0.0124\n",
            "Epoch 46/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9991 - loss: 0.0046\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 47/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9963 - val_loss: 0.0037\n",
            "Epoch 48/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0048\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9963 - val_loss: 0.0097\n",
            "Epoch 49/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9962 - loss: 0.0075\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9964 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 50/50\n",
            "\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_Attention/1D_CNN_Attention_best_model_5.keras\n"
          ]
        }
      ],
      "source": [
        "from keras import layers, models, Input\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D, Conv1D, MaxPooling1D, BatchNormalization\n",
        "\n",
        "class CNN_1D_Attn():\n",
        "    def __init__(self, input_shape):\n",
        "        self.model = self.CreateModel(input_shape)\n",
        "        self.model.summary()\n",
        "\n",
        "    def CreateModel(self, input_shape):\n",
        "        inputs = Input(shape=input_shape)\n",
        "\n",
        "        x = Conv1D(16, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "        x = Conv1D(32, 3, strides=1, padding='same', activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "        x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = MaxPooling1D(pool_size=2)(x)  # Shape: (seq_len, 64)\n",
        "\n",
        "        # Attention Layer\n",
        "        x_norm = LayerNormalization()(x)\n",
        "        attn_output = MultiHeadAttention(num_heads=4, key_dim=16)(x_norm, x_norm)\n",
        "        x = layers.Add()([x, attn_output])  # Residual Connection\n",
        "        x = LayerNormalization()(x)\n",
        "\n",
        "        x = GlobalAveragePooling1D()(x)\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "        model = models.Model(inputs, output)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        model.summary()\n",
        "        return model\n",
        "    \n",
        "os.makedirs(foldername_cnn_attn, exist_ok=True)\n",
        "\n",
        "# Split the data\n",
        "X_train, y_train, X_test, y_test = time_series_stratified_split(X=X, y=y_positional, train_ratio=0.8)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_1D_train = X_train.reshape([-1, samples_per_block, 1])\n",
        "X_1D_test = X_test.reshape([-1, samples_per_block, 1])\n",
        "input_shape = (samples_per_block, 1)\n",
        "\n",
        "# For K-Fold\n",
        "y_train_classes = np.argmax(y_train, axis=1)\n",
        "k_splits = 5\n",
        "kfold = StratifiedKFold(n_splits=k_splits, shuffle=False)\n",
        "\n",
        "# Metric storage\n",
        "accuracy_1D_cnn_attn, precision_1D_cnn_attn, recall_1D_cnn_attn, f1_1D_cnn_attn, log_loss_1D_cnn_attn, balanced_accuracy_1D_cnn_attn = [], [], [], [], [], []\n",
        "accuracy_1D_test_cnn_attn, precision_1D_test_cnn_attn, recall_1D_test_cnn_attn, f1_1D_test_cnn_attn, log_loss_1D_test_cnn_attn, balanced_accuracy_1D_test_cnn_attn = [], [], [], [], [], []\n",
        "\n",
        "# ------------------ Training Loop ------------------\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    checkpoint_filepath = os.path.join(foldername_cnn_attn, f\"1D_CNN_Attention_best_model_{fold + 1}.keras\")\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "                                 save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    model = CNN_1D_Attn(input_shape=(1600, 1))\n",
        "    model.model.fit(\n",
        "        X_1D_train[train_idx], y_train[train_idx],\n",
        "        validation_data=(X_1D_train[val_idx], y_train[val_idx]),\n",
        "        epochs=50,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "    best_model = load_model(checkpoint_filepath)\n",
        "\n",
        "    # Train fold subset evaluation\n",
        "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "\n",
        "    accuracy_1D_cnn_attn.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "    precision_1D_cnn_attn.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    recall_1D_cnn_attn.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    f1_1D_cnn_attn.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    log_loss_1D_cnn_attn.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "    balanced_accuracy_1D_cnn_attn.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "\n",
        "\n",
        "    # Save confusion matrix for train\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'1D CNN + Attention Train Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_attn, f\"1D_CNN_Attention_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Fixed test set evaluation\n",
        "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "    y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    accuracy_1D_test_cnn_attn.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "    precision_1D_test_cnn_attn.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    recall_1D_test_cnn_attn.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    f1_1D_test_cnn_attn.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    log_loss_1D_test_cnn_attn.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "    balanced_accuracy_1D_test_cnn_attn.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "\n",
        "    # Save confusion matrix for test\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "    plt.title(f'1D CNN + Attention Test Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_attn, f\"1D_CNN_Attention_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Best model saved at: {checkpoint_filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1D CNN+Attention Metrics:\n",
            "Train Accuracy: [1.0, 1.0, 1.0, 0.999, 1.0]\n",
            "Test Accuracy: [1.0, 0.98, 0.994, 0.985, 0.988]\n",
            "Precision: [1.0, 0.973, 0.996, 0.991, 0.991]\n",
            "Recall: [1.0, 0.98, 0.994, 0.985, 0.988]\n",
            "F1 Score: [1.0, 0.975, 0.994, 0.983, 0.989]\n",
            "Log Loss: [0.007, 0.06, 0.024, 0.038, 0.025]\n",
            "Balanced Accuracy: [1.0, 0.86, 0.96, 0.9, 0.92]\n"
          ]
        }
      ],
      "source": [
        "print(\"1D CNN+Attention Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_1D_cnn_attn}\")\n",
        "print(f\"Test Accuracy: {accuracy_1D_test_cnn_attn}\")\n",
        "print(f\"Precision: {precision_1D_test_cnn_attn}\")\n",
        "print(f\"Recall: {recall_1D_test_cnn_attn}\")\n",
        "print(f\"F1 Score: {f1_1D_test_cnn_attn}\")\n",
        "print(f\"Log Loss: {log_loss_1D_test_cnn_attn}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_1D_test_cnn_attn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u5DJtLDpLp2"
      },
      "source": [
        "### 1D CNN + LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvJsQZb4APDY",
        "outputId": "4ee0a97c-a946-4458-e0ac-13a5eed044af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_70\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_70\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_16… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_15… │\n",
              "│                     │                   │            │ conv1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_16… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_15… │\n",
              "│                     │                   │            │ conv1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_70\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_70\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_16… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_15… │\n",
              "│                     │                   │            │ conv1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_16… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_15… │\n",
              "│                     │                   │            │ conv1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7750 - loss: 1.7484\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30292, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - accuracy: 0.7772 - loss: 1.7326 - val_accuracy: 0.3029 - val_loss: 2.9008\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8361 - loss: 0.6932\n",
            "Epoch 2: val_accuracy improved from 0.30292 to 0.88321, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.8371 - loss: 0.6910 - val_accuracy: 0.8832 - val_loss: 0.5818\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8959 - loss: 0.5426\n",
            "Epoch 3: val_accuracy improved from 0.88321 to 0.88686, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.8957 - loss: 0.5427 - val_accuracy: 0.8869 - val_loss: 0.4098\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8841 - loss: 0.4179\n",
            "Epoch 4: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.8844 - loss: 0.4164 - val_accuracy: 0.8832 - val_loss: 0.3068\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8902 - loss: 0.3109\n",
            "Epoch 5: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.8904 - loss: 0.3107 - val_accuracy: 0.8832 - val_loss: 0.2844\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9049 - loss: 0.2706\n",
            "Epoch 6: val_accuracy improved from 0.88686 to 0.89416, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.9048 - loss: 0.2710 - val_accuracy: 0.8942 - val_loss: 0.2789\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9095 - loss: 0.2537\n",
            "Epoch 7: val_accuracy improved from 0.89416 to 0.90146, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.9092 - loss: 0.2543 - val_accuracy: 0.9015 - val_loss: 0.2750\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9025 - loss: 0.2569\n",
            "Epoch 8: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.9023 - loss: 0.2575 - val_accuracy: 0.8869 - val_loss: 0.2728\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8944 - loss: 0.2707\n",
            "Epoch 9: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.8944 - loss: 0.2707 - val_accuracy: 0.8942 - val_loss: 0.2698\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9021 - loss: 0.2750\n",
            "Epoch 10: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.9019 - loss: 0.2749 - val_accuracy: 0.8942 - val_loss: 0.2674\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8874 - loss: 0.2734 \n",
            "Epoch 11: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8876 - loss: 0.2731 - val_accuracy: 0.8942 - val_loss: 0.2641\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9030 - loss: 0.2571\n",
            "Epoch 12: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.9030 - loss: 0.2571 - val_accuracy: 0.9015 - val_loss: 0.2602\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.9119 - loss: 0.2347\n",
            "Epoch 13: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9116 - loss: 0.2353 - val_accuracy: 0.8978 - val_loss: 0.2573\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9038 - loss: 0.2570\n",
            "Epoch 14: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.9038 - loss: 0.2570 - val_accuracy: 0.9015 - val_loss: 0.2484\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8936 - loss: 0.2600\n",
            "Epoch 15: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8938 - loss: 0.2596 - val_accuracy: 0.8978 - val_loss: 0.2454\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9026 - loss: 0.2480\n",
            "Epoch 16: val_accuracy did not improve from 0.90146\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.9026 - loss: 0.2479 - val_accuracy: 0.9015 - val_loss: 0.2400\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8904 - loss: 0.2577\n",
            "Epoch 17: val_accuracy improved from 0.90146 to 0.90511, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.8907 - loss: 0.2571 - val_accuracy: 0.9051 - val_loss: 0.2342\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9039 - loss: 0.2394\n",
            "Epoch 18: val_accuracy did not improve from 0.90511\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.9039 - loss: 0.2393 - val_accuracy: 0.9015 - val_loss: 0.2305\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9069 - loss: 0.2334 \n",
            "Epoch 19: val_accuracy did not improve from 0.90511\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.9068 - loss: 0.2334 - val_accuracy: 0.8978 - val_loss: 0.2276\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8886 - loss: 0.2478\n",
            "Epoch 20: val_accuracy did not improve from 0.90511\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.8891 - loss: 0.2472 - val_accuracy: 0.9051 - val_loss: 0.2256\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_1.keras\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_18… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_17… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_18… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_17… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_18… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_17… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_18… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_17… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7764 - loss: 1.7967\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.7783 - loss: 1.7819 - val_accuracy: 0.8755 - val_loss: 0.5867\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8388 - loss: 0.6917\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8330 - loss: 0.7108 - val_accuracy: 0.0256 - val_loss: 2.5886\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4705 - loss: 1.8218\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.4773 - loss: 1.8065 - val_accuracy: 0.8755 - val_loss: 0.6352\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8716 - loss: 0.6597\n",
            "Epoch 4: val_accuracy improved from 0.87546 to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.8717 - loss: 0.6588 - val_accuracy: 0.8791 - val_loss: 0.5360\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8693 - loss: 0.6239 \n",
            "Epoch 5: val_accuracy did not improve from 0.87912\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.8695 - loss: 0.6235 - val_accuracy: 0.8791 - val_loss: 0.4816\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8831 - loss: 0.4981\n",
            "Epoch 6: val_accuracy improved from 0.87912 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - accuracy: 0.8829 - loss: 0.4980 - val_accuracy: 0.8901 - val_loss: 0.3764\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8693 - loss: 0.4404\n",
            "Epoch 7: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.8696 - loss: 0.4398 - val_accuracy: 0.8901 - val_loss: 0.4052\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8842 - loss: 0.4323\n",
            "Epoch 8: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8843 - loss: 0.4324 - val_accuracy: 0.8901 - val_loss: 0.4788\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8730 - loss: 0.5912\n",
            "Epoch 9: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8735 - loss: 0.5880 - val_accuracy: 0.8864 - val_loss: 0.3266\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8959 - loss: 0.3216\n",
            "Epoch 10: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8957 - loss: 0.3219 - val_accuracy: 0.8864 - val_loss: 0.2942\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8965 - loss: 0.2825\n",
            "Epoch 11: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.8964 - loss: 0.2830 - val_accuracy: 0.8864 - val_loss: 0.2855\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8957 - loss: 0.2677\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.8954 - loss: 0.2686 - val_accuracy: 0.8901 - val_loss: 0.2781\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8977 - loss: 0.2645\n",
            "Epoch 13: val_accuracy improved from 0.89011 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.8975 - loss: 0.2652 - val_accuracy: 0.8938 - val_loss: 0.2757\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8856 - loss: 0.3057\n",
            "Epoch 14: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.8859 - loss: 0.3051 - val_accuracy: 0.8938 - val_loss: 0.2713\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8869 - loss: 0.2911\n",
            "Epoch 15: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8872 - loss: 0.2906 - val_accuracy: 0.8938 - val_loss: 0.2682\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8997 - loss: 0.2825\n",
            "Epoch 16: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8997 - loss: 0.2822 - val_accuracy: 0.8938 - val_loss: 0.2648\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9047 - loss: 0.2779\n",
            "Epoch 17: val_accuracy improved from 0.89377 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.9046 - loss: 0.2777 - val_accuracy: 0.9048 - val_loss: 0.2616\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9036 - loss: 0.2383\n",
            "Epoch 18: val_accuracy improved from 0.90476 to 0.90842, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9034 - loss: 0.2391 - val_accuracy: 0.9084 - val_loss: 0.2574\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9020 - loss: 0.2575\n",
            "Epoch 19: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9019 - loss: 0.2577 - val_accuracy: 0.9048 - val_loss: 0.2531\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8947 - loss: 0.2594\n",
            "Epoch 20: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8948 - loss: 0.2595 - val_accuracy: 0.9084 - val_loss: 0.2490\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_2.keras\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_72\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_72\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_20… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_19… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_20… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_19… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_72\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_72\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_20… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_19… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_20… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_19… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7701 - loss: 1.7345\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.7724 - loss: 1.7175 - val_accuracy: 0.8864 - val_loss: 0.3186\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8939 - loss: 0.3057\n",
            "Epoch 2: val_accuracy improved from 0.88645 to 0.89744, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8937 - loss: 0.3055 - val_accuracy: 0.8974 - val_loss: 0.2960\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9129 - loss: 0.2621\n",
            "Epoch 3: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9125 - loss: 0.2627 - val_accuracy: 0.8974 - val_loss: 0.2627\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8989 - loss: 0.2539\n",
            "Epoch 4: val_accuracy improved from 0.89744 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.8986 - loss: 0.2543 - val_accuracy: 0.9048 - val_loss: 0.2496\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9063 - loss: 0.2432\n",
            "Epoch 5: val_accuracy improved from 0.90476 to 0.90842, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.9058 - loss: 0.2451 - val_accuracy: 0.9084 - val_loss: 0.4129\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8851 - loss: 0.4187\n",
            "Epoch 6: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.8853 - loss: 0.4165 - val_accuracy: 0.8462 - val_loss: 0.4378\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8188 - loss: 0.5351\n",
            "Epoch 7: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.8193 - loss: 0.5342 - val_accuracy: 0.8864 - val_loss: 0.5745\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9038 - loss: 0.3984\n",
            "Epoch 8: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9036 - loss: 0.3992 - val_accuracy: 0.8864 - val_loss: 0.2636\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8913 - loss: 0.3014\n",
            "Epoch 9: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.8914 - loss: 0.3008 - val_accuracy: 0.9048 - val_loss: 0.2455\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8797 - loss: 0.2819\n",
            "Epoch 10: val_accuracy improved from 0.90842 to 0.91575, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - accuracy: 0.8803 - loss: 0.2808 - val_accuracy: 0.9158 - val_loss: 0.2328\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9090 - loss: 0.2199\n",
            "Epoch 11: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.9090 - loss: 0.2202 - val_accuracy: 0.9121 - val_loss: 0.2254\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9101 - loss: 0.2447\n",
            "Epoch 12: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.9102 - loss: 0.2442 - val_accuracy: 0.9121 - val_loss: 0.2229\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8932 - loss: 0.2906\n",
            "Epoch 13: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.8934 - loss: 0.2905 - val_accuracy: 0.9011 - val_loss: 0.2416\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9088 - loss: 0.2412\n",
            "Epoch 14: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.9087 - loss: 0.2415 - val_accuracy: 0.9121 - val_loss: 0.2260\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9099 - loss: 0.2383\n",
            "Epoch 15: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.9101 - loss: 0.2381 - val_accuracy: 0.9011 - val_loss: 0.2280\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9115 - loss: 0.2224\n",
            "Epoch 16: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.9118 - loss: 0.2220 - val_accuracy: 0.9121 - val_loss: 0.2201\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9141 - loss: 0.2271\n",
            "Epoch 17: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.9141 - loss: 0.2269 - val_accuracy: 0.9011 - val_loss: 0.2379\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8998 - loss: 0.2483\n",
            "Epoch 18: val_accuracy improved from 0.91575 to 0.92308, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.9002 - loss: 0.2474 - val_accuracy: 0.9231 - val_loss: 0.2126\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9276 - loss: 0.1883\n",
            "Epoch 19: val_accuracy did not improve from 0.92308\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9273 - loss: 0.1891 - val_accuracy: 0.9121 - val_loss: 0.2351\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9153 - loss: 0.2142\n",
            "Epoch 20: val_accuracy did not improve from 0.92308\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9152 - loss: 0.2143 - val_accuracy: 0.9158 - val_loss: 0.2310\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
            "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_3.keras\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_73\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_73\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_22… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_21… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_22… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_21… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_73\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_73\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_22… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_21… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_22… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_21… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7960 - loss: 1.7125\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step - accuracy: 0.7977 - loss: 1.6972 - val_accuracy: 0.8864 - val_loss: 0.5392\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8837 - loss: 0.4664\n",
            "Epoch 2: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8838 - loss: 0.4648 - val_accuracy: 0.8864 - val_loss: 0.2917\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8825 - loss: 0.3176\n",
            "Epoch 3: val_accuracy improved from 0.88645 to 0.89744, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.8827 - loss: 0.3169 - val_accuracy: 0.8974 - val_loss: 0.2610\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8901 - loss: 0.2900\n",
            "Epoch 4: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8904 - loss: 0.2892 - val_accuracy: 0.8901 - val_loss: 0.2768\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8022 - loss: 0.7395 \n",
            "Epoch 5: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7994 - loss: 0.7511 - val_accuracy: 0.8864 - val_loss: 0.5904\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8718 - loss: 0.6163\n",
            "Epoch 6: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.8721 - loss: 0.6137 - val_accuracy: 0.8901 - val_loss: 0.3518\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8897 - loss: 0.3439 \n",
            "Epoch 7: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8897 - loss: 0.3435 - val_accuracy: 0.8901 - val_loss: 0.2984\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8997 - loss: 0.2985\n",
            "Epoch 8: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.8996 - loss: 0.2982 - val_accuracy: 0.8938 - val_loss: 0.2719\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8924 - loss: 0.2977\n",
            "Epoch 9: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.8926 - loss: 0.2968 - val_accuracy: 0.8938 - val_loss: 0.2657\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8865 - loss: 0.2974\n",
            "Epoch 10: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8868 - loss: 0.2968 - val_accuracy: 0.8974 - val_loss: 0.2644\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9014 - loss: 0.2592\n",
            "Epoch 11: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.9013 - loss: 0.2593 - val_accuracy: 0.8938 - val_loss: 0.2551\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8980 - loss: 0.2564\n",
            "Epoch 12: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.8982 - loss: 0.2560 - val_accuracy: 0.8938 - val_loss: 0.2461\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9139 - loss: 0.2284\n",
            "Epoch 13: val_accuracy improved from 0.89744 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.9137 - loss: 0.2286 - val_accuracy: 0.9048 - val_loss: 0.2422\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9098 - loss: 0.2080\n",
            "Epoch 14: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.9097 - loss: 0.2087 - val_accuracy: 0.8974 - val_loss: 0.2380\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8998 - loss: 0.2489\n",
            "Epoch 15: val_accuracy improved from 0.90476 to 0.90842, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9000 - loss: 0.2484 - val_accuracy: 0.9084 - val_loss: 0.2545\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8583 - loss: 0.4004\n",
            "Epoch 16: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.8566 - loss: 0.4063 - val_accuracy: 0.8864 - val_loss: 0.3224\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9069 - loss: 0.3278\n",
            "Epoch 17: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.9065 - loss: 0.3288 - val_accuracy: 0.8901 - val_loss: 0.3142\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8886 - loss: 0.3041\n",
            "Epoch 18: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8884 - loss: 0.3044 - val_accuracy: 0.8901 - val_loss: 0.2821\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9007 - loss: 0.2715\n",
            "Epoch 19: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - accuracy: 0.9003 - loss: 0.2723 - val_accuracy: 0.8974 - val_loss: 0.2770\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8888 - loss: 0.2828\n",
            "Epoch 20: val_accuracy did not improve from 0.90842\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.8886 - loss: 0.2834 - val_accuracy: 0.9011 - val_loss: 0.2757\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_4.keras\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_74\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_74\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_24    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_24… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_23… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_24    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_24… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_23… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_74\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_74\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">797</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">791</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050</span> │ reshape_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,040</span> │ conv1d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">391</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,030</span> │ conv1d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_24    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,830</span> │ max_pooling1d_24… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_23… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ conv1d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,840</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m797\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m450\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m791\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │      \u001b[38;5;34m1,050\u001b[0m │ reshape_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m396\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m12,040\u001b[0m │ conv1d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m391\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │     \u001b[38;5;34m15,030\u001b[0m │ conv1d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_24    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │      \u001b[38;5;34m4,830\u001b[0m │ max_pooling1d_24… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_23… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ conv1d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m195\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │     \u001b[38;5;34m21,840\u001b[0m │ multiply_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │     \u001b[38;5;34m29,040\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m610\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,890</span> (331.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,890\u001b[0m (331.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7996 - loss: 1.7702\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.8012 - loss: 1.7549 - val_accuracy: 0.8864 - val_loss: 0.5624\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8768 - loss: 0.6115\n",
            "Epoch 2: val_accuracy improved from 0.88645 to 0.89744, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.8770 - loss: 0.6099 - val_accuracy: 0.8974 - val_loss: 0.4387\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8910 - loss: 0.5095\n",
            "Epoch 3: val_accuracy did not improve from 0.89744\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.8911 - loss: 0.5076 - val_accuracy: 0.8974 - val_loss: 0.2874\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.8819 - loss: 0.3357\n",
            "Epoch 4: val_accuracy improved from 0.89744 to 0.90110, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - accuracy: 0.8821 - loss: 0.3354 - val_accuracy: 0.9011 - val_loss: 0.2663\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8825 - loss: 0.3193\n",
            "Epoch 5: val_accuracy improved from 0.90110 to 0.91575, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.8828 - loss: 0.3182 - val_accuracy: 0.9158 - val_loss: 0.2564\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8950 - loss: 0.2758\n",
            "Epoch 6: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.8948 - loss: 0.2769 - val_accuracy: 0.8974 - val_loss: 0.6770\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8803 - loss: 0.8056\n",
            "Epoch 7: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.8806 - loss: 0.8026 - val_accuracy: 0.8901 - val_loss: 0.4307\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8909 - loss: 0.5139\n",
            "Epoch 8: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.8908 - loss: 0.5137 - val_accuracy: 0.8938 - val_loss: 0.3475\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8882 - loss: 0.3621\n",
            "Epoch 9: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.8883 - loss: 0.3614 - val_accuracy: 0.8864 - val_loss: 0.3689\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.8801 - loss: 0.3468\n",
            "Epoch 10: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 0.8804 - loss: 0.3453 - val_accuracy: 0.9011 - val_loss: 0.2558\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8970 - loss: 0.2648\n",
            "Epoch 11: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.8970 - loss: 0.2647 - val_accuracy: 0.9048 - val_loss: 0.2393\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9032 - loss: 0.2456\n",
            "Epoch 12: val_accuracy did not improve from 0.91575\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9032 - loss: 0.2456 - val_accuracy: 0.9048 - val_loss: 0.2291\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9091 - loss: 0.2347\n",
            "Epoch 13: val_accuracy improved from 0.91575 to 0.91941, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - accuracy: 0.9090 - loss: 0.2349 - val_accuracy: 0.9194 - val_loss: 0.2269\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9127 - loss: 0.2261\n",
            "Epoch 14: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9126 - loss: 0.2264 - val_accuracy: 0.9048 - val_loss: 0.2266\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.9126 - loss: 0.2173\n",
            "Epoch 15: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9123 - loss: 0.2178 - val_accuracy: 0.9048 - val_loss: 0.2815\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.8926 - loss: 0.2653\n",
            "Epoch 16: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.8930 - loss: 0.2644 - val_accuracy: 0.9011 - val_loss: 0.2189\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9034 - loss: 0.2209\n",
            "Epoch 17: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9033 - loss: 0.2212 - val_accuracy: 0.9048 - val_loss: 0.2225\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.8849 - loss: 0.2546\n",
            "Epoch 18: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.8852 - loss: 0.2541 - val_accuracy: 0.9084 - val_loss: 0.2127\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8951 - loss: 0.2594\n",
            "Epoch 19: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.8954 - loss: 0.2587 - val_accuracy: 0.9048 - val_loss: 0.2819\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8987 - loss: 0.2346\n",
            "Epoch 20: val_accuracy did not improve from 0.91941\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - accuracy: 0.8987 - loss: 0.2345 - val_accuracy: 0.9121 - val_loss: 0.2153\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM/1D_CNN_LSTM_best_model_5.keras\n"
          ]
        }
      ],
      "source": [
        "class CNN_LSTM_1D():\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "        self.model.summary()\n",
        "\n",
        "    def build_model(self):\n",
        "        from keras.layers import Reshape, multiply, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Input\n",
        "        from keras.models import Model\n",
        "\n",
        "        input_seq = Input(shape=(1600,))\n",
        "        X = Reshape((1600, 1))(input_seq)\n",
        "\n",
        "        ec1_layer1 = Conv1D(50, 20, strides=2, activation='relu')(X)\n",
        "        ec1_layer2 = Conv1D(30, 10, strides=2, activation='relu')(ec1_layer1)\n",
        "        ec1_outputs = MaxPooling1D(pool_size=2)(ec1_layer2)\n",
        "\n",
        "        ec2_layer1 = Conv1D(50, 8, strides=2, activation='relu')(X)\n",
        "        ec2_layer2 = Conv1D(40, 6, strides=2, activation='relu')(ec2_layer1)\n",
        "        ec2_layer3 = MaxPooling1D(pool_size=2)(ec2_layer2)\n",
        "        ec2_layer4 = Conv1D(30, 4, strides=1, activation='relu')(ec2_layer3)\n",
        "        ec2_outputs = ec2_layer4\n",
        "\n",
        "        encoder = multiply([ec1_outputs, ec2_outputs])\n",
        "\n",
        "        x = LSTM(60, return_sequences=True)(encoder)\n",
        "        x = LSTM(60)(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "        model = Model(input_seq, output)\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "# Create directory for CNN + LSTM results\n",
        "os.makedirs(foldername_cnn_lstm, exist_ok=True)\n",
        "\n",
        "# Split the data\n",
        "X_train, y_train, X_test, y_test = time_series_stratified_split(X=X, y=y_positional, train_ratio=0.8)\n",
        "\n",
        "y_train_classes = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Metric storage\n",
        "accuracy_1D_cnn_lstm, precision_1D_cnn_lstm, recall_1D_cnn_lstm, f1_1D_cnn_lstm, log_loss_1D_cnn_lstm, balanced_accuracy_1D_cnn_lstm = [], [], [], [], [], []\n",
        "accuracy_1D_test_cnn_lstm, precision_1D_test_cnn_lstm, recall_1D_test_cnn_lstm, f1_1D_test_cnn_lstm, log_loss_1D_test_cnn_lstm, balanced_accuracy_1D_test_cnn_lstm = [], [], [], [], [], []\n",
        "\n",
        "# ------------------ Training Loop ------------------\n",
        "# for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train_classes)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    checkpoint_filepath = os.path.join(foldername_cnn_lstm, f\"1D_CNN_LSTM_best_model_{fold + 1}.keras\")\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "                                 save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    model = CNN_LSTM_1D()\n",
        "    model.model.fit(\n",
        "        X_train[train_idx], y_train[train_idx],\n",
        "        validation_data=(X_train[val_idx], y_train[val_idx]),\n",
        "        epochs=20,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "\n",
        "    best_model = load_model(checkpoint_filepath)\n",
        "\n",
        "    # Train fold subset evaluation\n",
        "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "\n",
        "    accuracy_1D_cnn_lstm.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "    precision_1D_cnn_lstm.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    recall_1D_cnn_lstm.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    f1_1D_cnn_lstm.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    log_loss_1D_cnn_lstm.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "    balanced_accuracy_1D_cnn_lstm.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "\n",
        "\n",
        "    # Save confusion matrix for train\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'1D CNN + LSTM Train Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm, f\"1D_CNN_LSTM_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Fixed test set evaluation\n",
        "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "    y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    accuracy_1D_test_cnn_lstm.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "    precision_1D_test_cnn_lstm.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    recall_1D_test_cnn_lstm.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    f1_1D_test_cnn_lstm.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    log_loss_1D_test_cnn_lstm.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "    balanced_accuracy_1D_test_cnn_lstm.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "\n",
        "    # Save confusion matrix for test\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "    plt.title(f'1D CNN + LSTM Test Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm, f\"1D_CNN_LSTM_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Best model saved at: {checkpoint_filepath}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1D CNN+LSTM Metrics:\n",
            "Train Accuracy: [0.905, 0.897, 0.923, 0.918, 0.909]\n",
            "Test Accuracy: [0.895, 0.895, 0.927, 0.922, 0.916]\n",
            "Precision: [0.88, 0.875, 0.916, 0.916, 0.904]\n",
            "Recall: [0.895, 0.895, 0.927, 0.922, 0.916]\n",
            "F1 Score: [0.882, 0.879, 0.916, 0.915, 0.901]\n",
            "Log Loss: [0.235, 0.272, 0.209, 0.242, 0.256]\n",
            "Balanced Accuracy: [0.28, 0.28, 0.5, 0.46, 0.42]\n"
          ]
        }
      ],
      "source": [
        "print(\"1D CNN+LSTM Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_1D_cnn_lstm}\")\n",
        "print(f\"Test Accuracy: {accuracy_1D_test_cnn_lstm}\")\n",
        "print(f\"Precision: {precision_1D_test_cnn_lstm}\")\n",
        "print(f\"Recall: {recall_1D_test_cnn_lstm}\")\n",
        "print(f\"F1 Score: {f1_1D_test_cnn_lstm}\")\n",
        "print(f\"Log Loss: {log_loss_1D_test_cnn_lstm}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_1D_test_cnn_lstm}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1D CNN + LSTM + ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_75\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_75\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_25    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_26    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_25… │\n",
              "│                     │                   │            │ max_pooling1d_26… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_27    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_27… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_44 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_25    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_26    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_25… │\n",
              "│                     │                   │            │ max_pooling1d_26… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_27    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_27… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_75\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_75\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_25    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_26    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_25… │\n",
              "│                     │                   │            │ max_pooling1d_26… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_27    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_27… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_44 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_25    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_26    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_25… │\n",
              "│                     │                   │            │ max_pooling1d_26… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_27    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_27… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.2547 - loss: 2.3346\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87226, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 239ms/step - accuracy: 0.2614 - loss: 2.3303 - val_accuracy: 0.8723 - val_loss: 2.1038\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8627 - loss: 1.7486\n",
            "Epoch 2: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 188ms/step - accuracy: 0.8633 - loss: 1.7448 - val_accuracy: 0.8723 - val_loss: 1.6590\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9001 - loss: 1.1288\n",
            "Epoch 3: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.9000 - loss: 1.1250 - val_accuracy: 0.8723 - val_loss: 1.0882\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8965 - loss: 0.6783\n",
            "Epoch 4: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.8964 - loss: 0.6773 - val_accuracy: 0.8723 - val_loss: 0.8731\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9101 - loss: 0.5555\n",
            "Epoch 5: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - accuracy: 0.9099 - loss: 0.5553 - val_accuracy: 0.8723 - val_loss: 0.8134\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.8935 - loss: 0.5265\n",
            "Epoch 6: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.8937 - loss: 0.5260 - val_accuracy: 0.8723 - val_loss: 0.7791\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9017 - loss: 0.4747\n",
            "Epoch 7: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 336ms/step - accuracy: 0.9017 - loss: 0.4750 - val_accuracy: 0.8723 - val_loss: 0.7344\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9206 - loss: 0.4610\n",
            "Epoch 8: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9204 - loss: 0.4611 - val_accuracy: 0.8723 - val_loss: 0.7014\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9206 - loss: 0.4243\n",
            "Epoch 9: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 260ms/step - accuracy: 0.9203 - loss: 0.4251 - val_accuracy: 0.8723 - val_loss: 0.6384\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9093 - loss: 0.4416\n",
            "Epoch 10: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 301ms/step - accuracy: 0.9093 - loss: 0.4417 - val_accuracy: 0.8723 - val_loss: 0.5633\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9217 - loss: 0.4196\n",
            "Epoch 11: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9215 - loss: 0.4201 - val_accuracy: 0.8723 - val_loss: 0.5019\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9183 - loss: 0.4146\n",
            "Epoch 12: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.9181 - loss: 0.4149 - val_accuracy: 0.8723 - val_loss: 0.4751\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.9209 - loss: 0.4053\n",
            "Epoch 13: val_accuracy improved from 0.87226 to 0.88686, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 386ms/step - accuracy: 0.9207 - loss: 0.4058 - val_accuracy: 0.8869 - val_loss: 0.4558\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9246 - loss: 0.4058\n",
            "Epoch 14: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9245 - loss: 0.4060 - val_accuracy: 0.8869 - val_loss: 0.4469\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9316 - loss: 0.3939\n",
            "Epoch 15: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9313 - loss: 0.3943 - val_accuracy: 0.8869 - val_loss: 0.4423\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9390 - loss: 0.3861\n",
            "Epoch 16: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.9386 - loss: 0.3865 - val_accuracy: 0.8869 - val_loss: 0.4319\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9239 - loss: 0.3794\n",
            "Epoch 17: val_accuracy did not improve from 0.88686\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - accuracy: 0.9239 - loss: 0.3798 - val_accuracy: 0.8869 - val_loss: 0.4231\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.9271 - loss: 0.3943\n",
            "Epoch 18: val_accuracy improved from 0.88686 to 0.90146, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.9270 - loss: 0.3941 - val_accuracy: 0.9015 - val_loss: 0.4105\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9296 - loss: 0.3595\n",
            "Epoch 19: val_accuracy improved from 0.90146 to 0.91606, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 327ms/step - accuracy: 0.9296 - loss: 0.3599 - val_accuracy: 0.9161 - val_loss: 0.3961\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9304 - loss: 0.3625\n",
            "Epoch 20: val_accuracy improved from 0.91606 to 0.92336, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9302 - loss: 0.3629 - val_accuracy: 0.9234 - val_loss: 0.3883\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9281 - loss: 0.3705\n",
            "Epoch 21: val_accuracy improved from 0.92336 to 0.94161, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9282 - loss: 0.3702 - val_accuracy: 0.9416 - val_loss: 0.3582\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9222 - loss: 0.3509\n",
            "Epoch 22: val_accuracy did not improve from 0.94161\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.9220 - loss: 0.3515 - val_accuracy: 0.9307 - val_loss: 0.3638\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9224 - loss: 0.3869\n",
            "Epoch 23: val_accuracy did not improve from 0.94161\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9227 - loss: 0.3860 - val_accuracy: 0.9416 - val_loss: 0.3406\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9175 - loss: 0.3669\n",
            "Epoch 24: val_accuracy did not improve from 0.94161\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9179 - loss: 0.3663 - val_accuracy: 0.9416 - val_loss: 0.3347\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9331 - loss: 0.3388\n",
            "Epoch 25: val_accuracy did not improve from 0.94161\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9331 - loss: 0.3387 - val_accuracy: 0.9416 - val_loss: 0.3278\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9355 - loss: 0.3412\n",
            "Epoch 26: val_accuracy improved from 0.94161 to 0.94526, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 308ms/step - accuracy: 0.9356 - loss: 0.3409 - val_accuracy: 0.9453 - val_loss: 0.3207\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9378 - loss: 0.3125\n",
            "Epoch 27: val_accuracy improved from 0.94526 to 0.94891, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 244ms/step - accuracy: 0.9378 - loss: 0.3125 - val_accuracy: 0.9489 - val_loss: 0.3141\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9241 - loss: 0.3426\n",
            "Epoch 28: val_accuracy did not improve from 0.94891\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9244 - loss: 0.3420 - val_accuracy: 0.9380 - val_loss: 0.3090\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9437 - loss: 0.2964\n",
            "Epoch 29: val_accuracy did not improve from 0.94891\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9436 - loss: 0.2967 - val_accuracy: 0.9270 - val_loss: 0.3318\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9426 - loss: 0.2987\n",
            "Epoch 30: val_accuracy improved from 0.94891 to 0.95620, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.9424 - loss: 0.2988 - val_accuracy: 0.9562 - val_loss: 0.2931\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9285 - loss: 0.3202\n",
            "Epoch 31: val_accuracy did not improve from 0.95620\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.9287 - loss: 0.3198 - val_accuracy: 0.9380 - val_loss: 0.2948\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9425 - loss: 0.2963\n",
            "Epoch 32: val_accuracy did not improve from 0.95620\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - accuracy: 0.9425 - loss: 0.2961 - val_accuracy: 0.9453 - val_loss: 0.2854\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9343 - loss: 0.3015\n",
            "Epoch 33: val_accuracy did not improve from 0.95620\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - accuracy: 0.9344 - loss: 0.3012 - val_accuracy: 0.9234 - val_loss: 0.3206\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9319 - loss: 0.2954\n",
            "Epoch 34: val_accuracy improved from 0.95620 to 0.96350, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 255ms/step - accuracy: 0.9320 - loss: 0.2951 - val_accuracy: 0.9635 - val_loss: 0.2708\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9420 - loss: 0.2707\n",
            "Epoch 35: val_accuracy did not improve from 0.96350\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 305ms/step - accuracy: 0.9420 - loss: 0.2708 - val_accuracy: 0.9562 - val_loss: 0.2694\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9364 - loss: 0.2879\n",
            "Epoch 36: val_accuracy improved from 0.96350 to 0.96715, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.9367 - loss: 0.2873 - val_accuracy: 0.9672 - val_loss: 0.2530\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9356 - loss: 0.2844\n",
            "Epoch 37: val_accuracy did not improve from 0.96715\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 271ms/step - accuracy: 0.9359 - loss: 0.2838 - val_accuracy: 0.9672 - val_loss: 0.2467\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9514 - loss: 0.2466\n",
            "Epoch 38: val_accuracy did not improve from 0.96715\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9515 - loss: 0.2467 - val_accuracy: 0.9562 - val_loss: 0.2489\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9506 - loss: 0.2590\n",
            "Epoch 39: val_accuracy did not improve from 0.96715\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9506 - loss: 0.2591 - val_accuracy: 0.9635 - val_loss: 0.2677\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9406 - loss: 0.2660\n",
            "Epoch 40: val_accuracy improved from 0.96715 to 0.98540, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 316ms/step - accuracy: 0.9409 - loss: 0.2655 - val_accuracy: 0.9854 - val_loss: 0.2371\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9693 - loss: 0.2555\n",
            "Epoch 41: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 267ms/step - accuracy: 0.9692 - loss: 0.2551 - val_accuracy: 0.9562 - val_loss: 0.2426\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9578 - loss: 0.2327\n",
            "Epoch 42: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.9577 - loss: 0.2328 - val_accuracy: 0.9818 - val_loss: 0.2226\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9394 - loss: 0.2514\n",
            "Epoch 43: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.9396 - loss: 0.2512 - val_accuracy: 0.9562 - val_loss: 0.2422\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9563 - loss: 0.2336\n",
            "Epoch 44: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 363ms/step - accuracy: 0.9561 - loss: 0.2338 - val_accuracy: 0.9124 - val_loss: 0.3067\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9458 - loss: 0.2566\n",
            "Epoch 45: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.9457 - loss: 0.2565 - val_accuracy: 0.9416 - val_loss: 0.2441\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9408 - loss: 0.2612\n",
            "Epoch 46: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9410 - loss: 0.2608 - val_accuracy: 0.9380 - val_loss: 0.2391\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9423 - loss: 0.2393\n",
            "Epoch 47: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9423 - loss: 0.2391 - val_accuracy: 0.9416 - val_loss: 0.2386\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9512 - loss: 0.2295\n",
            "Epoch 48: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9511 - loss: 0.2295 - val_accuracy: 0.9635 - val_loss: 0.2243\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9444 - loss: 0.2387\n",
            "Epoch 49: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9445 - loss: 0.2385 - val_accuracy: 0.9672 - val_loss: 0.2179\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9512 - loss: 0.2195\n",
            "Epoch 50: val_accuracy did not improve from 0.98540\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9512 - loss: 0.2196 - val_accuracy: 0.9562 - val_loss: 0.2420\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_76\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_76\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_28    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_29    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_28… │\n",
              "│                     │                   │            │ max_pooling1d_29… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_30    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_30… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_28    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_29    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_28… │\n",
              "│                     │                   │            │ max_pooling1d_29… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_30    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_30… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_76\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_76\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_28    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_29    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_28… │\n",
              "│                     │                   │            │ max_pooling1d_29… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_30    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_30… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_45 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_28    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_29    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_28… │\n",
              "│                     │                   │            │ max_pooling1d_29… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_30    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_30… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_3[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5201 - loss: 2.1348\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.5243 - loss: 2.1307 - val_accuracy: 0.8864 - val_loss: 2.1683\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8299 - loss: 1.5517\n",
            "Epoch 2: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.8309 - loss: 1.5485 - val_accuracy: 0.8791 - val_loss: 1.8145\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8815 - loss: 1.1007\n",
            "Epoch 3: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - accuracy: 0.8818 - loss: 1.0982 - val_accuracy: 0.8755 - val_loss: 1.3698\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8714 - loss: 0.8457\n",
            "Epoch 4: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 229ms/step - accuracy: 0.8720 - loss: 0.8431 - val_accuracy: 0.8755 - val_loss: 1.1359\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8828 - loss: 0.6566\n",
            "Epoch 5: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.8832 - loss: 0.6555 - val_accuracy: 0.8755 - val_loss: 0.9538\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9033 - loss: 0.5502\n",
            "Epoch 6: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9033 - loss: 0.5502 - val_accuracy: 0.8755 - val_loss: 0.8363\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9144 - loss: 0.5099\n",
            "Epoch 7: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9145 - loss: 0.5099 - val_accuracy: 0.8755 - val_loss: 0.7540\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9162 - loss: 0.4841\n",
            "Epoch 8: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9162 - loss: 0.4840 - val_accuracy: 0.8755 - val_loss: 0.6609\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8979 - loss: 0.4993\n",
            "Epoch 9: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.8983 - loss: 0.4984 - val_accuracy: 0.8755 - val_loss: 0.5582\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9195 - loss: 0.4498\n",
            "Epoch 10: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.9193 - loss: 0.4498 - val_accuracy: 0.8755 - val_loss: 0.5071\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9352 - loss: 0.4245\n",
            "Epoch 11: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9349 - loss: 0.4249 - val_accuracy: 0.8755 - val_loss: 0.4839\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9427 - loss: 0.4046\n",
            "Epoch 12: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 243ms/step - accuracy: 0.9424 - loss: 0.4052 - val_accuracy: 0.8755 - val_loss: 0.4689\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9221 - loss: 0.4262\n",
            "Epoch 13: val_accuracy did not improve from 0.88645\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9222 - loss: 0.4260 - val_accuracy: 0.8791 - val_loss: 0.4539\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9112 - loss: 0.4224\n",
            "Epoch 14: val_accuracy improved from 0.88645 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9116 - loss: 0.4220 - val_accuracy: 0.8938 - val_loss: 0.4403\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9513 - loss: 0.3833\n",
            "Epoch 15: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9508 - loss: 0.3837 - val_accuracy: 0.8938 - val_loss: 0.4329\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9333 - loss: 0.3873\n",
            "Epoch 16: val_accuracy improved from 0.89377 to 0.90110, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 243ms/step - accuracy: 0.9334 - loss: 0.3874 - val_accuracy: 0.9011 - val_loss: 0.4180\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9271 - loss: 0.3673\n",
            "Epoch 17: val_accuracy improved from 0.90110 to 0.93040, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.9273 - loss: 0.3677 - val_accuracy: 0.9304 - val_loss: 0.4000\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9539 - loss: 0.3497\n",
            "Epoch 18: val_accuracy did not improve from 0.93040\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - accuracy: 0.9538 - loss: 0.3503 - val_accuracy: 0.9231 - val_loss: 0.3911\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9404 - loss: 0.3785\n",
            "Epoch 19: val_accuracy did not improve from 0.93040\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9405 - loss: 0.3780 - val_accuracy: 0.9231 - val_loss: 0.3802\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9616 - loss: 0.3201\n",
            "Epoch 20: val_accuracy improved from 0.93040 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9613 - loss: 0.3211 - val_accuracy: 0.9560 - val_loss: 0.3620\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9447 - loss: 0.3751\n",
            "Epoch 21: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.9448 - loss: 0.3743 - val_accuracy: 0.9524 - val_loss: 0.3511\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9429 - loss: 0.3462\n",
            "Epoch 22: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9430 - loss: 0.3459 - val_accuracy: 0.9560 - val_loss: 0.3307\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9458 - loss: 0.3710\n",
            "Epoch 23: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9462 - loss: 0.3699 - val_accuracy: 0.9560 - val_loss: 0.3239\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9626 - loss: 0.3006\n",
            "Epoch 24: val_accuracy improved from 0.95604 to 0.98168, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9626 - loss: 0.3010 - val_accuracy: 0.9817 - val_loss: 0.3083\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9661 - loss: 0.3030\n",
            "Epoch 25: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9660 - loss: 0.3031 - val_accuracy: 0.9597 - val_loss: 0.3139\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9546 - loss: 0.3086\n",
            "Epoch 26: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9547 - loss: 0.3084 - val_accuracy: 0.9451 - val_loss: 0.3102\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9713 - loss: 0.2897\n",
            "Epoch 27: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9712 - loss: 0.2896 - val_accuracy: 0.9670 - val_loss: 0.2970\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9573 - loss: 0.2866\n",
            "Epoch 28: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9573 - loss: 0.2867 - val_accuracy: 0.9414 - val_loss: 0.3405\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9590 - loss: 0.2832\n",
            "Epoch 29: val_accuracy did not improve from 0.98168\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9589 - loss: 0.2835 - val_accuracy: 0.9560 - val_loss: 0.3194\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9656 - loss: 0.2868\n",
            "Epoch 30: val_accuracy improved from 0.98168 to 0.99267, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.9658 - loss: 0.2862 - val_accuracy: 0.9927 - val_loss: 0.2442\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9807 - loss: 0.2607\n",
            "Epoch 31: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9806 - loss: 0.2603 - val_accuracy: 0.9707 - val_loss: 0.2749\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9718 - loss: 0.2378\n",
            "Epoch 32: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9719 - loss: 0.2379 - val_accuracy: 0.9853 - val_loss: 0.2295\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9739 - loss: 0.2336\n",
            "Epoch 33: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9740 - loss: 0.2337 - val_accuracy: 0.9707 - val_loss: 0.2292\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9798 - loss: 0.2175\n",
            "Epoch 34: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.9798 - loss: 0.2177 - val_accuracy: 0.9744 - val_loss: 0.2230\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.9793 - loss: 0.2136\n",
            "Epoch 35: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 359ms/step - accuracy: 0.9793 - loss: 0.2137 - val_accuracy: 0.9853 - val_loss: 0.2100\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9879 - loss: 0.1963\n",
            "Epoch 36: val_accuracy improved from 0.99267 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 272ms/step - accuracy: 0.9876 - loss: 0.1968 - val_accuracy: 1.0000 - val_loss: 0.1902\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9793 - loss: 0.2155\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9794 - loss: 0.2153 - val_accuracy: 0.9853 - val_loss: 0.2032\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9808 - loss: 0.2022\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 244ms/step - accuracy: 0.9808 - loss: 0.2023 - val_accuracy: 0.9927 - val_loss: 0.1891\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9671 - loss: 0.2157\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9670 - loss: 0.2162 - val_accuracy: 0.9890 - val_loss: 0.1997\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9629 - loss: 0.2226\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.9630 - loss: 0.2225 - val_accuracy: 0.9560 - val_loss: 0.2858\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9757 - loss: 0.2145\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.9758 - loss: 0.2143 - val_accuracy: 0.9780 - val_loss: 0.2216\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9766 - loss: 0.2039\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9767 - loss: 0.2035 - val_accuracy: 0.9780 - val_loss: 0.2134\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9776 - loss: 0.2111\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9777 - loss: 0.2105 - val_accuracy: 0.9890 - val_loss: 0.1848\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9934 - loss: 0.1679\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9932 - loss: 0.1680 - val_accuracy: 0.9853 - val_loss: 0.1728\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9615 - loss: 0.2232\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9610 - loss: 0.2244 - val_accuracy: 0.9231 - val_loss: 0.3226\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9461 - loss: 0.2614\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.9462 - loss: 0.2613 - val_accuracy: 0.9487 - val_loss: 0.2742\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.9684 - loss: 0.2412\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 428ms/step - accuracy: 0.9682 - loss: 0.2412 - val_accuracy: 0.9524 - val_loss: 0.2343\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9633 - loss: 0.2280\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 290ms/step - accuracy: 0.9635 - loss: 0.2275 - val_accuracy: 0.9707 - val_loss: 0.2108\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9619 - loss: 0.2052\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.9620 - loss: 0.2052 - val_accuracy: 0.9707 - val_loss: 0.2019\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9647 - loss: 0.2090\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.9649 - loss: 0.2088 - val_accuracy: 0.9707 - val_loss: 0.1863\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_77\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_77\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_31    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_32    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_31… │\n",
              "│                     │                   │            │ max_pooling1d_32… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_33    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_33… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_54 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_31    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_32    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_31… │\n",
              "│                     │                   │            │ max_pooling1d_32… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_33    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_33… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_77\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_77\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_31    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_32    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_31… │\n",
              "│                     │                   │            │ max_pooling1d_32… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_33    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_33… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_53 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_54 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_52 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_31    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_32    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_31… │\n",
              "│                     │                   │            │ max_pooling1d_32… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_33    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_33… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_4[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5365 - loss: 2.2110\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01099, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 199ms/step - accuracy: 0.5413 - loss: 2.2069 - val_accuracy: 0.0110 - val_loss: 2.4240\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8723 - loss: 1.6331\n",
            "Epoch 2: val_accuracy improved from 0.01099 to 0.88278, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.8725 - loss: 1.6302 - val_accuracy: 0.8828 - val_loss: 2.2143\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9139 - loss: 1.1542\n",
            "Epoch 3: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.9132 - loss: 1.1523 - val_accuracy: 0.8791 - val_loss: 1.9184\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.8911 - loss: 0.8314\n",
            "Epoch 4: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - accuracy: 0.8911 - loss: 0.8302 - val_accuracy: 0.8755 - val_loss: 1.6816\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8965 - loss: 0.6539\n",
            "Epoch 5: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.8965 - loss: 0.6532 - val_accuracy: 0.8755 - val_loss: 1.5602\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8803 - loss: 0.6050\n",
            "Epoch 6: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.8809 - loss: 0.6034 - val_accuracy: 0.8755 - val_loss: 1.4476\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9051 - loss: 0.5437\n",
            "Epoch 7: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - accuracy: 0.9053 - loss: 0.5425 - val_accuracy: 0.8755 - val_loss: 1.3632\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8930 - loss: 0.5010\n",
            "Epoch 8: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.8932 - loss: 0.5003 - val_accuracy: 0.8755 - val_loss: 1.3046\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9112 - loss: 0.4464\n",
            "Epoch 9: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9110 - loss: 0.4465 - val_accuracy: 0.8755 - val_loss: 1.0022\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9227 - loss: 0.4423\n",
            "Epoch 10: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9226 - loss: 0.4422 - val_accuracy: 0.8755 - val_loss: 1.1104\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9079 - loss: 0.4224\n",
            "Epoch 11: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 278ms/step - accuracy: 0.9079 - loss: 0.4224 - val_accuracy: 0.8755 - val_loss: 1.0476\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9231 - loss: 0.4070\n",
            "Epoch 12: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9229 - loss: 0.4073 - val_accuracy: 0.8828 - val_loss: 0.8812\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9304 - loss: 0.3823\n",
            "Epoch 13: val_accuracy improved from 0.88278 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - accuracy: 0.9300 - loss: 0.3830 - val_accuracy: 0.8901 - val_loss: 0.6450\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9209 - loss: 0.3766\n",
            "Epoch 14: val_accuracy improved from 0.89011 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - accuracy: 0.9207 - loss: 0.3772 - val_accuracy: 0.8938 - val_loss: 0.5463\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9067 - loss: 0.4111\n",
            "Epoch 15: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9070 - loss: 0.4106 - val_accuracy: 0.8901 - val_loss: 0.4797\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9369 - loss: 0.3789\n",
            "Epoch 16: val_accuracy improved from 0.89377 to 0.89744, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.9369 - loss: 0.3788 - val_accuracy: 0.8974 - val_loss: 0.4334\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9180 - loss: 0.3936\n",
            "Epoch 17: val_accuracy improved from 0.89744 to 0.91209, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9181 - loss: 0.3930 - val_accuracy: 0.9121 - val_loss: 0.3930\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9205 - loss: 0.3612\n",
            "Epoch 18: val_accuracy did not improve from 0.91209\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9206 - loss: 0.3614 - val_accuracy: 0.9121 - val_loss: 0.3806\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9495 - loss: 0.3280\n",
            "Epoch 19: val_accuracy improved from 0.91209 to 0.93773, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 267ms/step - accuracy: 0.9492 - loss: 0.3288 - val_accuracy: 0.9377 - val_loss: 0.3538\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9377 - loss: 0.3620\n",
            "Epoch 20: val_accuracy improved from 0.93773 to 0.94872, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9377 - loss: 0.3618 - val_accuracy: 0.9487 - val_loss: 0.3432\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9473 - loss: 0.3386\n",
            "Epoch 21: val_accuracy improved from 0.94872 to 0.95238, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9472 - loss: 0.3387 - val_accuracy: 0.9524 - val_loss: 0.3341\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9480 - loss: 0.3514\n",
            "Epoch 22: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - accuracy: 0.9480 - loss: 0.3509 - val_accuracy: 0.9524 - val_loss: 0.3272\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9462 - loss: 0.3296\n",
            "Epoch 23: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - accuracy: 0.9461 - loss: 0.3297 - val_accuracy: 0.9524 - val_loss: 0.3229\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.9499 - loss: 0.3190\n",
            "Epoch 24: val_accuracy improved from 0.95238 to 0.95971, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9499 - loss: 0.3190 - val_accuracy: 0.9597 - val_loss: 0.3155\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9510 - loss: 0.2972\n",
            "Epoch 25: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 296ms/step - accuracy: 0.9510 - loss: 0.2976 - val_accuracy: 0.9524 - val_loss: 0.3075\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9454 - loss: 0.3223\n",
            "Epoch 26: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9455 - loss: 0.3217 - val_accuracy: 0.9524 - val_loss: 0.3034\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9471 - loss: 0.2905\n",
            "Epoch 27: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9471 - loss: 0.2906 - val_accuracy: 0.9524 - val_loss: 0.3023\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9658 - loss: 0.2770\n",
            "Epoch 28: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.9656 - loss: 0.2773 - val_accuracy: 0.9524 - val_loss: 0.2878\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9500 - loss: 0.2911\n",
            "Epoch 29: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9501 - loss: 0.2909 - val_accuracy: 0.9524 - val_loss: 0.2861\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9719 - loss: 0.2630\n",
            "Epoch 30: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 342ms/step - accuracy: 0.9717 - loss: 0.2632 - val_accuracy: 0.9597 - val_loss: 0.2787\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9613 - loss: 0.2647\n",
            "Epoch 31: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9613 - loss: 0.2648 - val_accuracy: 0.9597 - val_loss: 0.2781\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9536 - loss: 0.2877\n",
            "Epoch 32: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 346ms/step - accuracy: 0.9537 - loss: 0.2870 - val_accuracy: 0.9487 - val_loss: 0.2793\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9653 - loss: 0.2450\n",
            "Epoch 33: val_accuracy improved from 0.95971 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 239ms/step - accuracy: 0.9651 - loss: 0.2453 - val_accuracy: 0.9707 - val_loss: 0.2513\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9738 - loss: 0.2325\n",
            "Epoch 34: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9736 - loss: 0.2330 - val_accuracy: 0.9451 - val_loss: 0.2835\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.9714 - loss: 0.2444\n",
            "Epoch 35: val_accuracy improved from 0.97070 to 0.98535, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 462ms/step - accuracy: 0.9714 - loss: 0.2443 - val_accuracy: 0.9853 - val_loss: 0.2433\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9702 - loss: 0.2215\n",
            "Epoch 36: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9700 - loss: 0.2220 - val_accuracy: 0.9853 - val_loss: 0.2370\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9682 - loss: 0.2337\n",
            "Epoch 37: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 316ms/step - accuracy: 0.9681 - loss: 0.2338 - val_accuracy: 0.9744 - val_loss: 0.2449\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9644 - loss: 0.2339\n",
            "Epoch 38: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9645 - loss: 0.2338 - val_accuracy: 0.9707 - val_loss: 0.2325\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.9617 - loss: 0.2440\n",
            "Epoch 39: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.9618 - loss: 0.2436 - val_accuracy: 0.9707 - val_loss: 0.2280\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9846 - loss: 0.2035\n",
            "Epoch 40: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9845 - loss: 0.2039 - val_accuracy: 0.9560 - val_loss: 0.2320\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9744 - loss: 0.2095\n",
            "Epoch 41: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 244ms/step - accuracy: 0.9743 - loss: 0.2097 - val_accuracy: 0.9597 - val_loss: 0.2226\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9738 - loss: 0.2025\n",
            "Epoch 42: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9738 - loss: 0.2026 - val_accuracy: 0.9560 - val_loss: 0.2213\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.9729 - loss: 0.1945\n",
            "Epoch 43: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 329ms/step - accuracy: 0.9729 - loss: 0.1948 - val_accuracy: 0.9560 - val_loss: 0.2329\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9721 - loss: 0.1910\n",
            "Epoch 44: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 329ms/step - accuracy: 0.9719 - loss: 0.1914 - val_accuracy: 0.9597 - val_loss: 0.2055\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9698 - loss: 0.2016\n",
            "Epoch 45: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9698 - loss: 0.2016 - val_accuracy: 0.9634 - val_loss: 0.2071\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.9590 - loss: 0.2219\n",
            "Epoch 46: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 528ms/step - accuracy: 0.9592 - loss: 0.2213 - val_accuracy: 0.9853 - val_loss: 0.1938\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9774 - loss: 0.1965\n",
            "Epoch 47: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 255ms/step - accuracy: 0.9772 - loss: 0.1964 - val_accuracy: 0.9707 - val_loss: 0.2138\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.9644 - loss: 0.1903\n",
            "Epoch 48: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.9645 - loss: 0.1904 - val_accuracy: 0.9634 - val_loss: 0.2170\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9663 - loss: 0.1939\n",
            "Epoch 49: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9663 - loss: 0.1940 - val_accuracy: 0.9597 - val_loss: 0.2323\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9703 - loss: 0.1844\n",
            "Epoch 50: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9702 - loss: 0.1848 - val_accuracy: 0.9158 - val_loss: 0.3224\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_78\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_78\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_34    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_35    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_34… │\n",
              "│                     │                   │            │ max_pooling1d_35… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_36    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_36… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_8 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_55 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_58 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_56 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_59 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_57 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_34    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_35    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_34… │\n",
              "│                     │                   │            │ max_pooling1d_35… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_36    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_36… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_6[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_78\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_78\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_34    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_35    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_34… │\n",
              "│                     │                   │            │ max_pooling1d_35… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_36    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_36… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_8 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_55 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_58 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_56 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_59 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_57 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_34    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_35    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_34… │\n",
              "│                     │                   │            │ max_pooling1d_35… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_36    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_36… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_6[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4058 - loss: 2.2912\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88278, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 211ms/step - accuracy: 0.4126 - loss: 2.2860 - val_accuracy: 0.8828 - val_loss: 1.8774\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8902 - loss: 1.5466\n",
            "Epoch 2: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - accuracy: 0.8901 - loss: 1.5436 - val_accuracy: 0.8755 - val_loss: 1.3642\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8871 - loss: 1.0511\n",
            "Epoch 3: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - accuracy: 0.8872 - loss: 1.0493 - val_accuracy: 0.8755 - val_loss: 0.9658\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8944 - loss: 0.7312\n",
            "Epoch 4: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.8942 - loss: 0.7306 - val_accuracy: 0.8755 - val_loss: 0.7963\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8998 - loss: 0.5791\n",
            "Epoch 5: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.8995 - loss: 0.5795 - val_accuracy: 0.8755 - val_loss: 0.7470\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.8924 - loss: 0.5297\n",
            "Epoch 6: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - accuracy: 0.8923 - loss: 0.5296 - val_accuracy: 0.8755 - val_loss: 0.7268\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8956 - loss: 0.4872\n",
            "Epoch 7: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.8956 - loss: 0.4874 - val_accuracy: 0.8755 - val_loss: 0.6960\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9052 - loss: 0.4531\n",
            "Epoch 8: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 324ms/step - accuracy: 0.9050 - loss: 0.4536 - val_accuracy: 0.8755 - val_loss: 0.6422\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8840 - loss: 0.4841\n",
            "Epoch 9: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.8843 - loss: 0.4834 - val_accuracy: 0.8755 - val_loss: 0.5738\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.8888 - loss: 0.4665\n",
            "Epoch 10: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - accuracy: 0.8890 - loss: 0.4660 - val_accuracy: 0.8755 - val_loss: 0.5141\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9111 - loss: 0.4400\n",
            "Epoch 11: val_accuracy did not improve from 0.88278\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9110 - loss: 0.4400 - val_accuracy: 0.8755 - val_loss: 0.5280\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9247 - loss: 0.3943\n",
            "Epoch 12: val_accuracy improved from 0.88278 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 272ms/step - accuracy: 0.9242 - loss: 0.3952 - val_accuracy: 0.8901 - val_loss: 0.5615\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.9135 - loss: 0.4275\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 365ms/step - accuracy: 0.9133 - loss: 0.4273 - val_accuracy: 0.8901 - val_loss: 0.5881\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9008 - loss: 0.4310\n",
            "Epoch 14: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 269ms/step - accuracy: 0.9009 - loss: 0.4306 - val_accuracy: 0.8901 - val_loss: 0.5496\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9102 - loss: 0.4077\n",
            "Epoch 15: val_accuracy improved from 0.89011 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9102 - loss: 0.4077 - val_accuracy: 0.8938 - val_loss: 0.5330\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.8957 - loss: 0.4259\n",
            "Epoch 16: val_accuracy improved from 0.89377 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 327ms/step - accuracy: 0.8961 - loss: 0.4253 - val_accuracy: 0.9048 - val_loss: 0.4494\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.9049 - loss: 0.4234\n",
            "Epoch 17: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9050 - loss: 0.4228 - val_accuracy: 0.9048 - val_loss: 0.4024\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9209 - loss: 0.4336\n",
            "Epoch 18: val_accuracy improved from 0.90476 to 0.90842, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9211 - loss: 0.4324 - val_accuracy: 0.9084 - val_loss: 0.3944\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9278 - loss: 0.3974\n",
            "Epoch 19: val_accuracy improved from 0.90842 to 0.93407, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - accuracy: 0.9278 - loss: 0.3969 - val_accuracy: 0.9341 - val_loss: 0.3834\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9233 - loss: 0.3916\n",
            "Epoch 20: val_accuracy did not improve from 0.93407\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 321ms/step - accuracy: 0.9232 - loss: 0.3913 - val_accuracy: 0.9304 - val_loss: 0.3800\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9337 - loss: 0.3588\n",
            "Epoch 21: val_accuracy improved from 0.93407 to 0.93773, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.9335 - loss: 0.3591 - val_accuracy: 0.9377 - val_loss: 0.3687\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9301 - loss: 0.3774\n",
            "Epoch 22: val_accuracy improved from 0.93773 to 0.95238, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9302 - loss: 0.3770 - val_accuracy: 0.9524 - val_loss: 0.3540\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9452 - loss: 0.3401\n",
            "Epoch 23: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.9449 - loss: 0.3404 - val_accuracy: 0.9451 - val_loss: 0.3503\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9311 - loss: 0.3846\n",
            "Epoch 24: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9313 - loss: 0.3835 - val_accuracy: 0.9451 - val_loss: 0.3416\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9324 - loss: 0.3439\n",
            "Epoch 25: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 284ms/step - accuracy: 0.9326 - loss: 0.3437 - val_accuracy: 0.9451 - val_loss: 0.3270\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9297 - loss: 0.3263\n",
            "Epoch 26: val_accuracy improved from 0.95238 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9295 - loss: 0.3266 - val_accuracy: 0.9560 - val_loss: 0.3231\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9294 - loss: 0.3476\n",
            "Epoch 27: val_accuracy improved from 0.95604 to 0.95971, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9295 - loss: 0.3471 - val_accuracy: 0.9597 - val_loss: 0.3155\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9202 - loss: 0.3544\n",
            "Epoch 28: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.9206 - loss: 0.3534 - val_accuracy: 0.9487 - val_loss: 0.3052\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9487 - loss: 0.3025\n",
            "Epoch 29: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 229ms/step - accuracy: 0.9486 - loss: 0.3026 - val_accuracy: 0.9597 - val_loss: 0.2969\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9525 - loss: 0.2861\n",
            "Epoch 30: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9523 - loss: 0.2865 - val_accuracy: 0.9597 - val_loss: 0.2912\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9564 - loss: 0.2855\n",
            "Epoch 31: val_accuracy improved from 0.95971 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.9563 - loss: 0.2858 - val_accuracy: 0.9707 - val_loss: 0.2823\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9413 - loss: 0.3054\n",
            "Epoch 32: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9414 - loss: 0.3049 - val_accuracy: 0.9707 - val_loss: 0.2717\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9466 - loss: 0.2948\n",
            "Epoch 33: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9467 - loss: 0.2945 - val_accuracy: 0.9670 - val_loss: 0.2803\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9387 - loss: 0.3074\n",
            "Epoch 34: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9389 - loss: 0.3066 - val_accuracy: 0.9670 - val_loss: 0.2611\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9458 - loss: 0.2812\n",
            "Epoch 35: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.9459 - loss: 0.2807 - val_accuracy: 0.9670 - val_loss: 0.2560\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9612 - loss: 0.2550\n",
            "Epoch 36: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9612 - loss: 0.2551 - val_accuracy: 0.9707 - val_loss: 0.2406\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9630 - loss: 0.2315\n",
            "Epoch 37: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.9629 - loss: 0.2319 - val_accuracy: 0.9707 - val_loss: 0.2377\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9608 - loss: 0.2381\n",
            "Epoch 38: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9608 - loss: 0.2382 - val_accuracy: 0.9634 - val_loss: 0.2370\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9594 - loss: 0.2343\n",
            "Epoch 39: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.9593 - loss: 0.2344 - val_accuracy: 0.9707 - val_loss: 0.2210\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9655 - loss: 0.2423\n",
            "Epoch 40: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 241ms/step - accuracy: 0.9656 - loss: 0.2418 - val_accuracy: 0.9670 - val_loss: 0.2176\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9677 - loss: 0.2249\n",
            "Epoch 41: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.9676 - loss: 0.2250 - val_accuracy: 0.9560 - val_loss: 0.2495\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9539 - loss: 0.2354\n",
            "Epoch 42: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9541 - loss: 0.2351 - val_accuracy: 0.9707 - val_loss: 0.2313\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9612 - loss: 0.2238\n",
            "Epoch 43: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9613 - loss: 0.2234 - val_accuracy: 0.9634 - val_loss: 0.2177\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9715 - loss: 0.2109\n",
            "Epoch 44: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 226ms/step - accuracy: 0.9714 - loss: 0.2107 - val_accuracy: 0.9597 - val_loss: 0.2083\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9749 - loss: 0.1912\n",
            "Epoch 45: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.9747 - loss: 0.1914 - val_accuracy: 0.9597 - val_loss: 0.1987\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9600 - loss: 0.2029\n",
            "Epoch 46: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9599 - loss: 0.2028 - val_accuracy: 0.9707 - val_loss: 0.1843\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9608 - loss: 0.1979\n",
            "Epoch 47: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.9609 - loss: 0.1978 - val_accuracy: 0.9707 - val_loss: 0.1798\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9657 - loss: 0.1902\n",
            "Epoch 48: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 222ms/step - accuracy: 0.9658 - loss: 0.1902 - val_accuracy: 0.9634 - val_loss: 0.1910\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9629 - loss: 0.1854\n",
            "Epoch 49: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 272ms/step - accuracy: 0.9632 - loss: 0.1852 - val_accuracy: 0.9597 - val_loss: 0.2168\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9655 - loss: 0.2002\n",
            "Epoch 50: val_accuracy did not improve from 0.97070\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9655 - loss: 0.2000 - val_accuracy: 0.9634 - val_loss: 0.1845\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_79\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_79\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_37    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_38    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_37… │\n",
              "│                     │                   │            │ max_pooling1d_38… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_39    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_39… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_9 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_60 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_63 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_61 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_64 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_62 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_37    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_38    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_37… │\n",
              "│                     │                   │            │ max_pooling1d_38… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_39    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_39… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_9[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_79\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_79\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_37    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_38    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_37… │\n",
              "│                     │                   │            │ max_pooling1d_38… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_39    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_39… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_9 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_60 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_63 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m224\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_61 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m2,576\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_64 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,552\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_62 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m32\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_37    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_38    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_37… │\n",
              "│                     │                   │            │ max_pooling1d_38… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_39    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_39… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,224\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m16,640\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_8[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_9[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,754</span> (217.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,754\u001b[0m (217.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,562</span> (217.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,562\u001b[0m (217.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1402 - loss: 2.2473\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 180ms/step - accuracy: 0.1450 - loss: 2.2433 - val_accuracy: 0.8755 - val_loss: 2.1305\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8304 - loss: 1.6391\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.8311 - loss: 1.6361 - val_accuracy: 0.8755 - val_loss: 1.6842\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8925 - loss: 1.1604\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8924 - loss: 1.1582 - val_accuracy: 0.8755 - val_loss: 1.2399\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.8788 - loss: 0.8734\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.8790 - loss: 0.8719 - val_accuracy: 0.8755 - val_loss: 0.9396\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8837 - loss: 0.7411\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 227ms/step - accuracy: 0.8839 - loss: 0.7395 - val_accuracy: 0.8755 - val_loss: 0.8291\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8935 - loss: 0.5950\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.8937 - loss: 0.5945 - val_accuracy: 0.8755 - val_loss: 0.7982\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9017 - loss: 0.5535\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.9018 - loss: 0.5530 - val_accuracy: 0.8755 - val_loss: 0.7988\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8965 - loss: 0.5252\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - accuracy: 0.8968 - loss: 0.5244 - val_accuracy: 0.8755 - val_loss: 0.8064\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8979 - loss: 0.4877\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 224ms/step - accuracy: 0.8981 - loss: 0.4872 - val_accuracy: 0.8755 - val_loss: 0.7957\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9201 - loss: 0.4617\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.9201 - loss: 0.4614 - val_accuracy: 0.8755 - val_loss: 0.7384\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9164 - loss: 0.4333\n",
            "Epoch 11: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.9165 - loss: 0.4335 - val_accuracy: 0.8755 - val_loss: 0.6501\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9310 - loss: 0.4138\n",
            "Epoch 12: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 231ms/step - accuracy: 0.9306 - loss: 0.4141 - val_accuracy: 0.8755 - val_loss: 0.5238\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9302 - loss: 0.4067\n",
            "Epoch 13: val_accuracy improved from 0.87546 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.9301 - loss: 0.4070 - val_accuracy: 0.8901 - val_loss: 0.4502\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9355 - loss: 0.3729\n",
            "Epoch 14: val_accuracy improved from 0.89011 to 0.90110, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.9352 - loss: 0.3738 - val_accuracy: 0.9011 - val_loss: 0.4157\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9382 - loss: 0.3916\n",
            "Epoch 15: val_accuracy improved from 0.90110 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9382 - loss: 0.3915 - val_accuracy: 0.9048 - val_loss: 0.4002\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9320 - loss: 0.3846\n",
            "Epoch 16: val_accuracy improved from 0.90476 to 0.91575, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9320 - loss: 0.3845 - val_accuracy: 0.9158 - val_loss: 0.3827\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9311 - loss: 0.3805\n",
            "Epoch 17: val_accuracy improved from 0.91575 to 0.91941, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.9312 - loss: 0.3803 - val_accuracy: 0.9194 - val_loss: 0.3794\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9382 - loss: 0.3595\n",
            "Epoch 18: val_accuracy improved from 0.91941 to 0.93773, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - accuracy: 0.9380 - loss: 0.3597 - val_accuracy: 0.9377 - val_loss: 0.3614\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9346 - loss: 0.3453\n",
            "Epoch 19: val_accuracy did not improve from 0.93773\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.9346 - loss: 0.3455 - val_accuracy: 0.9341 - val_loss: 0.3501\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9221 - loss: 0.3806\n",
            "Epoch 20: val_accuracy improved from 0.93773 to 0.94872, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9223 - loss: 0.3796 - val_accuracy: 0.9487 - val_loss: 0.3320\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9378 - loss: 0.3328\n",
            "Epoch 21: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.9377 - loss: 0.3329 - val_accuracy: 0.9414 - val_loss: 0.3264\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9325 - loss: 0.3339\n",
            "Epoch 22: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9326 - loss: 0.3336 - val_accuracy: 0.9341 - val_loss: 0.3186\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9402 - loss: 0.3323\n",
            "Epoch 23: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 229ms/step - accuracy: 0.9404 - loss: 0.3317 - val_accuracy: 0.9341 - val_loss: 0.3170\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9493 - loss: 0.2766\n",
            "Epoch 24: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9490 - loss: 0.2776 - val_accuracy: 0.9414 - val_loss: 0.2997\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9408 - loss: 0.3007\n",
            "Epoch 25: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9409 - loss: 0.3009 - val_accuracy: 0.9451 - val_loss: 0.3109\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9355 - loss: 0.3014\n",
            "Epoch 26: val_accuracy did not improve from 0.94872\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9357 - loss: 0.3012 - val_accuracy: 0.9414 - val_loss: 0.2938\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9516 - loss: 0.2901\n",
            "Epoch 27: val_accuracy improved from 0.94872 to 0.95238, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.9515 - loss: 0.2900 - val_accuracy: 0.9524 - val_loss: 0.2816\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9516 - loss: 0.2718\n",
            "Epoch 28: val_accuracy improved from 0.95238 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.9516 - loss: 0.2718 - val_accuracy: 0.9560 - val_loss: 0.2712\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9416 - loss: 0.2899\n",
            "Epoch 29: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9420 - loss: 0.2892 - val_accuracy: 0.9560 - val_loss: 0.2631\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9524 - loss: 0.2710\n",
            "Epoch 30: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9526 - loss: 0.2708 - val_accuracy: 0.9560 - val_loss: 0.2555\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9635 - loss: 0.2609\n",
            "Epoch 31: val_accuracy improved from 0.95604 to 0.96703, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9636 - loss: 0.2604 - val_accuracy: 0.9670 - val_loss: 0.2509\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.9694 - loss: 0.2448\n",
            "Epoch 32: val_accuracy improved from 0.96703 to 0.97070, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 436ms/step - accuracy: 0.9694 - loss: 0.2447 - val_accuracy: 0.9707 - val_loss: 0.2429\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9700 - loss: 0.2321\n",
            "Epoch 33: val_accuracy improved from 0.97070 to 0.97802, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 0.9700 - loss: 0.2321 - val_accuracy: 0.9780 - val_loss: 0.2391\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9739 - loss: 0.2271\n",
            "Epoch 34: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9737 - loss: 0.2272 - val_accuracy: 0.9670 - val_loss: 0.2296\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.9564 - loss: 0.2264\n",
            "Epoch 35: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 243ms/step - accuracy: 0.9565 - loss: 0.2263 - val_accuracy: 0.9780 - val_loss: 0.2154\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9770 - loss: 0.2147\n",
            "Epoch 36: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9768 - loss: 0.2146 - val_accuracy: 0.9634 - val_loss: 0.2254\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9796 - loss: 0.2142\n",
            "Epoch 37: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9794 - loss: 0.2141 - val_accuracy: 0.9780 - val_loss: 0.2033\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9706 - loss: 0.2115\n",
            "Epoch 38: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 261ms/step - accuracy: 0.9707 - loss: 0.2114 - val_accuracy: 0.9634 - val_loss: 0.2154\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9667 - loss: 0.2229\n",
            "Epoch 39: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9665 - loss: 0.2228 - val_accuracy: 0.9524 - val_loss: 0.2546\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9675 - loss: 0.2209\n",
            "Epoch 40: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.9675 - loss: 0.2209 - val_accuracy: 0.9451 - val_loss: 0.2546\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9638 - loss: 0.2107\n",
            "Epoch 41: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9636 - loss: 0.2112 - val_accuracy: 0.9048 - val_loss: 0.3297\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9522 - loss: 0.2371\n",
            "Epoch 42: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 243ms/step - accuracy: 0.9525 - loss: 0.2368 - val_accuracy: 0.9267 - val_loss: 0.2886\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9684 - loss: 0.2000\n",
            "Epoch 43: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - accuracy: 0.9684 - loss: 0.2002 - val_accuracy: 0.9670 - val_loss: 0.2087\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.9749 - loss: 0.1967\n",
            "Epoch 44: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9750 - loss: 0.1965 - val_accuracy: 0.9451 - val_loss: 0.2411\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9817 - loss: 0.1815\n",
            "Epoch 45: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 332ms/step - accuracy: 0.9815 - loss: 0.1816 - val_accuracy: 0.9487 - val_loss: 0.2266\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9759 - loss: 0.1815\n",
            "Epoch 46: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 318ms/step - accuracy: 0.9759 - loss: 0.1814 - val_accuracy: 0.9560 - val_loss: 0.2039\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9865 - loss: 0.1705\n",
            "Epoch 47: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9865 - loss: 0.1704 - val_accuracy: 0.9487 - val_loss: 0.2295\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9776 - loss: 0.1762\n",
            "Epoch 48: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 297ms/step - accuracy: 0.9777 - loss: 0.1759 - val_accuracy: 0.9670 - val_loss: 0.1732\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9819 - loss: 0.1696\n",
            "Epoch 49: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9820 - loss: 0.1694 - val_accuracy: 0.9597 - val_loss: 0.1868\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9807 - loss: 0.1656\n",
            "Epoch 50: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9808 - loss: 0.1655 - val_accuracy: 0.9670 - val_loss: 0.1666\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/1D_CNN_LSTM_Attention_best_model_5.keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "## Model 2\n",
        "from keras import layers, Model, Input\n",
        "from keras.layers import (\n",
        "    Conv1D, MaxPooling1D, Dropout, Dense, LSTM, Bidirectional,\n",
        "    BatchNormalization, LayerNormalization, MultiHeadAttention,\n",
        "    Reshape, Concatenate, Add, Activation\n",
        ")\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "class CNN_1D_LSTM_Attention():\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "        self.model.summary()\n",
        "\n",
        "    def build_model(self):\n",
        "        input_seq = Input(shape=(1600,))\n",
        "        X = Reshape((1600, 1))(input_seq)\n",
        "\n",
        "        # CNN Branch 1\n",
        "        branch1 = Conv1D(32, 10, strides=2, padding='same')(X)  # (800, 32)\n",
        "        branch1 = BatchNormalization()(branch1)\n",
        "        branch1 = Activation('relu')(branch1)\n",
        "        branch1 = Conv1D(16, 5, strides=2, padding='same')(branch1)  # (400, 16)\n",
        "        branch1 = BatchNormalization()(branch1)\n",
        "        branch1 = Activation('relu')(branch1)\n",
        "        branch1 = MaxPooling1D(pool_size=2)(branch1)  # (200, 16)\n",
        "\n",
        "        # Residual shortcut\n",
        "        shortcut1 = Conv1D(16, 1, strides=4, padding='same')(X)  # (400, 16)\n",
        "        shortcut1 = MaxPooling1D(pool_size=2)(shortcut1)  # (200, 16)\n",
        "        branch1 = Add()([branch1, shortcut1])  # (200, 16)\n",
        "\n",
        "        # CNN Branch 2\n",
        "        branch2 = Conv1D(32, 6, strides=2, padding='same')(X)  # (800, 32)\n",
        "        branch2 = BatchNormalization()(branch2)\n",
        "        branch2 = Activation('relu')(branch2)\n",
        "        branch2 = Conv1D(16, 3, strides=2, padding='same')(branch2)  # (400, 16)\n",
        "        branch2 = BatchNormalization()(branch2)\n",
        "        branch2 = Activation('relu')(branch2)\n",
        "        branch2 = MaxPooling1D(pool_size=2)(branch2)  # (200, 16)\n",
        "\n",
        "        # Merge branches\n",
        "        combined = Concatenate(axis=-1)([branch1, branch2])  # (200, 32)\n",
        "        combined = LayerNormalization()(combined)\n",
        "\n",
        "        # Multi-head attention\n",
        "        attn_out = MultiHeadAttention(num_heads=4, key_dim=8)(combined, combined)\n",
        "        attn_out = LayerNormalization()(attn_out)\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        x = Bidirectional(LSTM(32, return_sequences=True))(attn_out)\n",
        "        x = Bidirectional(LSTM(32))(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        output = Dense(10, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "        # Final model\n",
        "        model = Model(input_seq, output)\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "        self.callbacks = [lr_scheduler]\n",
        "\n",
        "        return model\n",
        "\n",
        "os.makedirs(foldername_cnn_lstm_attn, exist_ok=True)\n",
        "\n",
        "# For K-Fold\n",
        "y_train_classes = np.argmax(y_train, axis=1)\n",
        "k_splits = 5\n",
        "kfold = StratifiedKFold(n_splits=k_splits, shuffle=False)\n",
        "\n",
        "# Metric storage\n",
        "accuracy_1D_cnn_lstm_attn, precision_1D_cnn_lstm_attn, recall_1D_cnn_lstm_attn, f1_1D_cnn_lstm_attn, log_loss_1D_cnn_lstm_attn, balanced_accuracy_1D_cnn_lstm_attn = [], [], [], [], [], []\n",
        "accuracy_1D_test_cnn_lstm_attn, precision_1D_test_cnn_lstm_attn, recall_1D_test_cnn_lstm_attn, f1_1D_test_cnn_lstm_attn, log_loss_1D_test_cnn_lstm_attn, balanced_accuracy_1D_test_cnn_lstm_attn = [], [], [], [], [], []\n",
        "\n",
        "# ------------------ Training Loop ------------------\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    checkpoint_filepath = os.path.join(foldername_cnn_lstm_attn, f\"1D_CNN_LSTM_Attention_best_model_{fold + 1}.keras\")\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "                                 save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    model = CNN_1D_LSTM_Attention()\n",
        "    model.model.fit(\n",
        "        X_train[train_idx], y_train[train_idx],\n",
        "        validation_data=(X_train[val_idx], y_train[val_idx]),\n",
        "        epochs=50,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "    best_model = load_model(checkpoint_filepath)\n",
        "\n",
        "    # Train fold subset evaluation\n",
        "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "\n",
        "    accuracy_1D_cnn_lstm_attn.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "    precision_1D_cnn_lstm_attn.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    recall_1D_cnn_lstm_attn.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    f1_1D_cnn_lstm_attn.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    log_loss_1D_cnn_lstm_attn.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "    balanced_accuracy_1D_cnn_lstm_attn.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "\n",
        "\n",
        "    # Save confusion matrix for train\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'1D CNN + LSTM + Attention Train Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm_attn, f\"1D_CNN_LSTM_Attention_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Fixed test set evaluation\n",
        "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "    y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    accuracy_1D_test_cnn_lstm_attn.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "    precision_1D_test_cnn_lstm_attn.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    recall_1D_test_cnn_lstm_attn.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    f1_1D_test_cnn_lstm_attn.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    log_loss_1D_test_cnn_lstm_attn.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "    balanced_accuracy_1D_test_cnn_lstm_attn.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "\n",
        "    # Save confusion matrix for test\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "    plt.title(f'1D CNN + LSTM + Attention Test Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm_attn, f\"1D_CNN_LSTM_Attention_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Best model saved at: {checkpoint_filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1D CNN+LSTM+ATTENTION Metrics:\n",
            "Train Accuracy: [0.968, 0.991, 0.983, 0.965, 0.979]\n",
            "Test Accuracy: [0.953, 0.985, 0.98, 0.936, 0.971]\n",
            "Precision: [0.93, 0.989, 0.972, 0.938, 0.969]\n",
            "Recall: [0.953, 0.985, 0.98, 0.936, 0.971]\n",
            "F1 Score: [0.939, 0.985, 0.975, 0.932, 0.964]\n",
            "Log Loss: [0.15, 0.111, 0.138, 0.186, 0.137]\n",
            "Balanced Accuracy: [0.68, 0.9, 0.86, 0.56, 0.8]\n"
          ]
        }
      ],
      "source": [
        "print(\"1D CNN+LSTM+ATTENTION Metrics:\")\n",
        "print(f\"Train Accuracy: {accuracy_1D_cnn_lstm_attn}\")\n",
        "print(f\"Test Accuracy: {accuracy_1D_test_cnn_lstm_attn}\")\n",
        "print(f\"Precision: {precision_1D_test_cnn_lstm_attn}\")\n",
        "print(f\"Recall: {recall_1D_test_cnn_lstm_attn}\")\n",
        "print(f\"F1 Score: {f1_1D_test_cnn_lstm_attn}\")\n",
        "print(f\"Log Loss: {log_loss_1D_test_cnn_lstm_attn}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_1D_test_cnn_lstm_attn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_80\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_80\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_40    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_41    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_40… │\n",
              "│                     │                   │            │ max_pooling1d_41… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_42    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_42… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_11… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_65 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_68 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_66 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_69 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_67 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_40    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_41    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_40… │\n",
              "│                     │                   │            │ max_pooling1d_41… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_42    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_42… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_10… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_11… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_80\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_80\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_40    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_41    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_40… │\n",
              "│                     │                   │            │ max_pooling1d_41… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_42    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_42… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_10… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_11… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_65 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_68 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_66 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_69 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_67 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_40    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_41    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_40… │\n",
              "│                     │                   │            │ max_pooling1d_41… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_42    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_42… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_10… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_11… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.4937 - loss: 2.1391\n",
            "Epoch 1: val_accuracy improved from -inf to 0.06204, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 341ms/step - accuracy: 0.4995 - loss: 2.1338 - val_accuracy: 0.0620 - val_loss: 2.2727\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.9212 - loss: 1.4087\n",
            "Epoch 2: val_accuracy improved from 0.06204 to 0.87226, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 253ms/step - accuracy: 0.9204 - loss: 1.4064 - val_accuracy: 0.8723 - val_loss: 2.0367\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9002 - loss: 1.0069\n",
            "Epoch 3: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.9001 - loss: 1.0049 - val_accuracy: 0.8723 - val_loss: 1.8763\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.8914 - loss: 0.7772\n",
            "Epoch 4: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 337ms/step - accuracy: 0.8917 - loss: 0.7750 - val_accuracy: 0.8723 - val_loss: 1.6400\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.9092 - loss: 0.5816\n",
            "Epoch 5: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 376ms/step - accuracy: 0.9092 - loss: 0.5813 - val_accuracy: 0.8723 - val_loss: 1.4316\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9244 - loss: 0.4989\n",
            "Epoch 6: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9241 - loss: 0.4993 - val_accuracy: 0.8723 - val_loss: 1.4091\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9177 - loss: 0.4789\n",
            "Epoch 7: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.9179 - loss: 0.4790 - val_accuracy: 0.8723 - val_loss: 1.5568\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9217 - loss: 0.4889\n",
            "Epoch 8: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.9220 - loss: 0.4880 - val_accuracy: 0.8723 - val_loss: 1.6499\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9357 - loss: 0.4373\n",
            "Epoch 9: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9357 - loss: 0.4371 - val_accuracy: 0.8723 - val_loss: 1.6439\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9457 - loss: 0.4353\n",
            "Epoch 10: val_accuracy did not improve from 0.87226\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9458 - loss: 0.4347 - val_accuracy: 0.8723 - val_loss: 1.5343\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9415 - loss: 0.4322\n",
            "Epoch 11: val_accuracy improved from 0.87226 to 0.88321, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9418 - loss: 0.4313 - val_accuracy: 0.8832 - val_loss: 1.4390\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9622 - loss: 0.3667\n",
            "Epoch 12: val_accuracy did not improve from 0.88321\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9620 - loss: 0.3672 - val_accuracy: 0.8832 - val_loss: 1.2021\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9560 - loss: 0.3759\n",
            "Epoch 13: val_accuracy improved from 0.88321 to 0.88686, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9559 - loss: 0.3759 - val_accuracy: 0.8869 - val_loss: 1.0531\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9631 - loss: 0.3506\n",
            "Epoch 14: val_accuracy improved from 0.88686 to 0.89781, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9631 - loss: 0.3507 - val_accuracy: 0.8978 - val_loss: 0.9622\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9581 - loss: 0.3467\n",
            "Epoch 15: val_accuracy did not improve from 0.89781\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9583 - loss: 0.3465 - val_accuracy: 0.8978 - val_loss: 0.7272\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9652 - loss: 0.3191\n",
            "Epoch 16: val_accuracy did not improve from 0.89781\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.9652 - loss: 0.3192 - val_accuracy: 0.8978 - val_loss: 0.5319\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9589 - loss: 0.3308\n",
            "Epoch 17: val_accuracy improved from 0.89781 to 0.90876, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.9591 - loss: 0.3303 - val_accuracy: 0.9088 - val_loss: 0.3856\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.9761 - loss: 0.3148\n",
            "Epoch 18: val_accuracy improved from 0.90876 to 0.93431, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 539ms/step - accuracy: 0.9760 - loss: 0.3144 - val_accuracy: 0.9343 - val_loss: 0.3533\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.2780\n",
            "Epoch 19: val_accuracy improved from 0.93431 to 0.95620, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.2783 - val_accuracy: 0.9562 - val_loss: 0.3070\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.9789 - loss: 0.2879\n",
            "Epoch 20: val_accuracy improved from 0.95620 to 0.96715, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 490ms/step - accuracy: 0.9789 - loss: 0.2877 - val_accuracy: 0.9672 - val_loss: 0.2710\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.9837 - loss: 0.2816\n",
            "Epoch 21: val_accuracy improved from 0.96715 to 0.99270, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 491ms/step - accuracy: 0.9837 - loss: 0.2811 - val_accuracy: 0.9927 - val_loss: 0.2597\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9808 - loss: 0.2522\n",
            "Epoch 22: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 383ms/step - accuracy: 0.9809 - loss: 0.2523 - val_accuracy: 0.9854 - val_loss: 0.2592\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.9850 - loss: 0.2509\n",
            "Epoch 23: val_accuracy did not improve from 0.99270\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 371ms/step - accuracy: 0.9850 - loss: 0.2508 - val_accuracy: 0.9708 - val_loss: 0.2504\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9815 - loss: 0.2458\n",
            "Epoch 24: val_accuracy improved from 0.99270 to 0.99635, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.9816 - loss: 0.2458 - val_accuracy: 0.9964 - val_loss: 0.2263\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9794 - loss: 0.2512\n",
            "Epoch 25: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 345ms/step - accuracy: 0.9794 - loss: 0.2509 - val_accuracy: 0.9854 - val_loss: 0.2436\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9841 - loss: 0.2462\n",
            "Epoch 26: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9840 - loss: 0.2461 - val_accuracy: 0.9818 - val_loss: 0.2398\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9734 - loss: 0.2390\n",
            "Epoch 27: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.9736 - loss: 0.2388 - val_accuracy: 0.9854 - val_loss: 0.2249\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9877 - loss: 0.2280\n",
            "Epoch 28: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step - accuracy: 0.9877 - loss: 0.2277 - val_accuracy: 0.9854 - val_loss: 0.2062\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9924 - loss: 0.2017\n",
            "Epoch 29: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9924 - loss: 0.2018 - val_accuracy: 0.9891 - val_loss: 0.1912\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9844 - loss: 0.2144\n",
            "Epoch 30: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9843 - loss: 0.2144 - val_accuracy: 0.9745 - val_loss: 0.2334\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.9698 - loss: 0.2339\n",
            "Epoch 31: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 391ms/step - accuracy: 0.9700 - loss: 0.2335 - val_accuracy: 0.9562 - val_loss: 0.2380\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9892 - loss: 0.2008\n",
            "Epoch 32: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 325ms/step - accuracy: 0.9891 - loss: 0.2010 - val_accuracy: 0.9818 - val_loss: 0.2042\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.9785 - loss: 0.1975\n",
            "Epoch 33: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 363ms/step - accuracy: 0.9787 - loss: 0.1975 - val_accuracy: 0.9745 - val_loss: 0.2093\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9929 - loss: 0.1887\n",
            "Epoch 34: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9928 - loss: 0.1886 - val_accuracy: 0.9818 - val_loss: 0.1873\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9758 - loss: 0.2159\n",
            "Epoch 35: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.9759 - loss: 0.2158 - val_accuracy: 0.9854 - val_loss: 0.1862\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9835 - loss: 0.1901\n",
            "Epoch 36: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 300ms/step - accuracy: 0.9836 - loss: 0.1902 - val_accuracy: 0.9781 - val_loss: 0.1871\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9845 - loss: 0.1803\n",
            "Epoch 37: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 324ms/step - accuracy: 0.9844 - loss: 0.1806 - val_accuracy: 0.9672 - val_loss: 0.1939\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9650 - loss: 0.2191\n",
            "Epoch 38: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 323ms/step - accuracy: 0.9654 - loss: 0.2184 - val_accuracy: 0.9453 - val_loss: 0.2458\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9873 - loss: 0.1779\n",
            "Epoch 39: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9874 - loss: 0.1778 - val_accuracy: 0.9526 - val_loss: 0.2241\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9916 - loss: 0.1665\n",
            "Epoch 40: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.9916 - loss: 0.1665 - val_accuracy: 0.9854 - val_loss: 0.1660\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9935 - loss: 0.1690\n",
            "Epoch 41: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 344ms/step - accuracy: 0.9935 - loss: 0.1690 - val_accuracy: 0.9927 - val_loss: 0.1496\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9948 - loss: 0.1585\n",
            "Epoch 42: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 324ms/step - accuracy: 0.9947 - loss: 0.1586 - val_accuracy: 0.9781 - val_loss: 0.1739\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9901 - loss: 0.1619\n",
            "Epoch 43: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9901 - loss: 0.1618 - val_accuracy: 0.9854 - val_loss: 0.1506\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9894 - loss: 0.1628\n",
            "Epoch 44: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 334ms/step - accuracy: 0.9893 - loss: 0.1631 - val_accuracy: 0.9854 - val_loss: 0.1636\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9814 - loss: 0.1771\n",
            "Epoch 45: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 356ms/step - accuracy: 0.9815 - loss: 0.1769 - val_accuracy: 0.9453 - val_loss: 0.2392\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.9895 - loss: 0.1563\n",
            "Epoch 46: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 645ms/step - accuracy: 0.9894 - loss: 0.1566 - val_accuracy: 0.9891 - val_loss: 0.1478\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.9975 - loss: 0.1426\n",
            "Epoch 47: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 485ms/step - accuracy: 0.9974 - loss: 0.1427 - val_accuracy: 0.9927 - val_loss: 0.1437\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9976 - loss: 0.1378\n",
            "Epoch 48: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 376ms/step - accuracy: 0.9975 - loss: 0.1379 - val_accuracy: 0.9891 - val_loss: 0.1374\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.9967 - loss: 0.1312\n",
            "Epoch 49: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 455ms/step - accuracy: 0.9967 - loss: 0.1313 - val_accuracy: 0.9927 - val_loss: 0.1320\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.9986 - loss: 0.1203\n",
            "Epoch 50: val_accuracy did not improve from 0.99635\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 494ms/step - accuracy: 0.9986 - loss: 0.1205 - val_accuracy: 0.9891 - val_loss: 0.1356\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 115ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_1.keras\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_81\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_81\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_43    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_44    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_43… │\n",
              "│                     │                   │            │ max_pooling1d_44… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_45    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_45… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_12… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_13… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_70 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_73 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_71 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_74 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_72 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_43    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_44    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_43… │\n",
              "│                     │                   │            │ max_pooling1d_44… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_45    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_45… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_12… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_13… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_81\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_81\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_43    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_44    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_43… │\n",
              "│                     │                   │            │ max_pooling1d_44… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_45    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_45… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_12… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_13… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_70 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_73 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_71 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_74 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_72 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_43    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_44    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_43… │\n",
              "│                     │                   │            │ max_pooling1d_44… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_45    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_45… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_12… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_13… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6442 - loss: 2.0283\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 449ms/step - accuracy: 0.6487 - loss: 2.0213 - val_accuracy: 0.8755 - val_loss: 1.9630\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.8685 - loss: 1.2167\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 263ms/step - accuracy: 0.8690 - loss: 1.2126 - val_accuracy: 0.8755 - val_loss: 1.1181\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.8941 - loss: 0.7372\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.8943 - loss: 0.7359 - val_accuracy: 0.8755 - val_loss: 0.7764\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9236 - loss: 0.5564\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9233 - loss: 0.5559 - val_accuracy: 0.8755 - val_loss: 0.7170\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9228 - loss: 0.4822\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 334ms/step - accuracy: 0.9226 - loss: 0.4823 - val_accuracy: 0.8755 - val_loss: 0.7014\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9326 - loss: 0.4393\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9322 - loss: 0.4397 - val_accuracy: 0.8755 - val_loss: 0.6999\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9202 - loss: 0.4453\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9203 - loss: 0.4453 - val_accuracy: 0.8755 - val_loss: 0.6602\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.9308 - loss: 0.4381\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 421ms/step - accuracy: 0.9307 - loss: 0.4378 - val_accuracy: 0.8755 - val_loss: 0.6006\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9318 - loss: 0.4262\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.9318 - loss: 0.4260 - val_accuracy: 0.8755 - val_loss: 0.5683\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.9265 - loss: 0.3950\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 873ms/step - accuracy: 0.9266 - loss: 0.3954 - val_accuracy: 0.8755 - val_loss: 0.5155\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9240 - loss: 0.3981\n",
            "Epoch 11: val_accuracy improved from 0.87546 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 548ms/step - accuracy: 0.9242 - loss: 0.3983 - val_accuracy: 0.8901 - val_loss: 0.4579\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.9392 - loss: 0.3893\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 652ms/step - accuracy: 0.9393 - loss: 0.3892 - val_accuracy: 0.8901 - val_loss: 0.4690\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897ms/step - accuracy: 0.9448 - loss: 0.3844\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 928ms/step - accuracy: 0.9448 - loss: 0.3841 - val_accuracy: 0.8901 - val_loss: 0.4662\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954ms/step - accuracy: 0.9137 - loss: 0.4154\n",
            "Epoch 14: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 994ms/step - accuracy: 0.9144 - loss: 0.4141 - val_accuracy: 0.8901 - val_loss: 0.4603\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.9572 - loss: 0.3475\n",
            "Epoch 15: val_accuracy improved from 0.89011 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 419ms/step - accuracy: 0.9571 - loss: 0.3477 - val_accuracy: 0.8938 - val_loss: 0.4371\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.9524 - loss: 0.3335\n",
            "Epoch 16: val_accuracy improved from 0.89377 to 0.89744, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 475ms/step - accuracy: 0.9522 - loss: 0.3339 - val_accuracy: 0.8974 - val_loss: 0.4165\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9521 - loss: 0.3465\n",
            "Epoch 17: val_accuracy improved from 0.89744 to 0.92308, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 329ms/step - accuracy: 0.9523 - loss: 0.3462 - val_accuracy: 0.9231 - val_loss: 0.3686\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9556 - loss: 0.3419\n",
            "Epoch 18: val_accuracy improved from 0.92308 to 0.93040, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 323ms/step - accuracy: 0.9556 - loss: 0.3416 - val_accuracy: 0.9304 - val_loss: 0.3600\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9593 - loss: 0.3279\n",
            "Epoch 19: val_accuracy improved from 0.93040 to 0.95971, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.9593 - loss: 0.3275 - val_accuracy: 0.9597 - val_loss: 0.3282\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9582 - loss: 0.3227\n",
            "Epoch 20: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 339ms/step - accuracy: 0.9583 - loss: 0.3222 - val_accuracy: 0.9414 - val_loss: 0.3166\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9650 - loss: 0.2850\n",
            "Epoch 21: val_accuracy did not improve from 0.95971\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9651 - loss: 0.2852 - val_accuracy: 0.9487 - val_loss: 0.3148\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9788 - loss: 0.2809\n",
            "Epoch 22: val_accuracy improved from 0.95971 to 0.98535, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 343ms/step - accuracy: 0.9787 - loss: 0.2810 - val_accuracy: 0.9853 - val_loss: 0.2898\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9720 - loss: 0.2736\n",
            "Epoch 23: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 330ms/step - accuracy: 0.9719 - loss: 0.2737 - val_accuracy: 0.9744 - val_loss: 0.2915\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9587 - loss: 0.3112\n",
            "Epoch 24: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 317ms/step - accuracy: 0.9589 - loss: 0.3104 - val_accuracy: 0.9744 - val_loss: 0.2809\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9783 - loss: 0.2386\n",
            "Epoch 25: val_accuracy improved from 0.98535 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 294ms/step - accuracy: 0.9782 - loss: 0.2394 - val_accuracy: 0.9890 - val_loss: 0.2460\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9830 - loss: 0.2509\n",
            "Epoch 26: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9830 - loss: 0.2508 - val_accuracy: 0.9853 - val_loss: 0.2428\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9805 - loss: 0.2432\n",
            "Epoch 27: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9806 - loss: 0.2430 - val_accuracy: 0.9780 - val_loss: 0.2342\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9721 - loss: 0.2486\n",
            "Epoch 28: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9722 - loss: 0.2483 - val_accuracy: 0.9744 - val_loss: 0.2434\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9759 - loss: 0.2322\n",
            "Epoch 29: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - accuracy: 0.9759 - loss: 0.2322 - val_accuracy: 0.9817 - val_loss: 0.2125\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9825 - loss: 0.2160\n",
            "Epoch 30: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - accuracy: 0.9824 - loss: 0.2161 - val_accuracy: 0.9414 - val_loss: 0.2775\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9811 - loss: 0.2352\n",
            "Epoch 31: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9809 - loss: 0.2351 - val_accuracy: 0.9853 - val_loss: 0.2025\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9867 - loss: 0.2162\n",
            "Epoch 32: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9866 - loss: 0.2159 - val_accuracy: 0.9304 - val_loss: 0.3319\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9422 - loss: 0.2867\n",
            "Epoch 33: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9421 - loss: 0.2866 - val_accuracy: 0.9121 - val_loss: 0.3539\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9577 - loss: 0.2683\n",
            "Epoch 34: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.9577 - loss: 0.2681 - val_accuracy: 0.9597 - val_loss: 0.2409\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9643 - loss: 0.2206\n",
            "Epoch 35: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 294ms/step - accuracy: 0.9644 - loss: 0.2205 - val_accuracy: 0.9817 - val_loss: 0.2038\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9756 - loss: 0.1999\n",
            "Epoch 36: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9757 - loss: 0.1999 - val_accuracy: 0.9744 - val_loss: 0.1892\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9660 - loss: 0.2106\n",
            "Epoch 37: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9661 - loss: 0.2102 - val_accuracy: 0.9634 - val_loss: 0.2017\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9680 - loss: 0.1990\n",
            "Epoch 38: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 348ms/step - accuracy: 0.9682 - loss: 0.1990 - val_accuracy: 0.9744 - val_loss: 0.1849\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.9876 - loss: 0.1776\n",
            "Epoch 39: val_accuracy improved from 0.98901 to 0.99267, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.9875 - loss: 0.1779 - val_accuracy: 0.9927 - val_loss: 0.1750\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9691 - loss: 0.1966\n",
            "Epoch 40: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.9693 - loss: 0.1963 - val_accuracy: 0.9634 - val_loss: 0.1915\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9855 - loss: 0.1698\n",
            "Epoch 41: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9854 - loss: 0.1698 - val_accuracy: 0.9817 - val_loss: 0.1734\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9829 - loss: 0.1673\n",
            "Epoch 42: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9829 - loss: 0.1676 - val_accuracy: 0.9597 - val_loss: 0.1848\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9822 - loss: 0.1905\n",
            "Epoch 43: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9822 - loss: 0.1902 - val_accuracy: 0.9304 - val_loss: 0.2830\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9729 - loss: 0.1949\n",
            "Epoch 44: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 269ms/step - accuracy: 0.9729 - loss: 0.1952 - val_accuracy: 0.9597 - val_loss: 0.2896\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9702 - loss: 0.2094\n",
            "Epoch 45: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 276ms/step - accuracy: 0.9705 - loss: 0.2087 - val_accuracy: 0.9744 - val_loss: 0.1748\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9836 - loss: 0.1673\n",
            "Epoch 46: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9836 - loss: 0.1674 - val_accuracy: 0.9853 - val_loss: 0.1550\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9798 - loss: 0.1671\n",
            "Epoch 47: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 278ms/step - accuracy: 0.9799 - loss: 0.1670 - val_accuracy: 0.9634 - val_loss: 0.1654\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9852 - loss: 0.1495\n",
            "Epoch 48: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9852 - loss: 0.1497 - val_accuracy: 0.9744 - val_loss: 0.1675\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9844 - loss: 0.1658\n",
            "Epoch 49: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - accuracy: 0.9844 - loss: 0.1657 - val_accuracy: 0.9707 - val_loss: 0.1633\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9830 - loss: 0.1479\n",
            "Epoch 50: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 278ms/step - accuracy: 0.9830 - loss: 0.1480 - val_accuracy: 0.9780 - val_loss: 0.1480\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_2.keras\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_82\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_82\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_46    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_47    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_46… │\n",
              "│                     │                   │            │ max_pooling1d_47… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_48    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_48… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_14… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_15… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_78 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_76 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_28[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_79 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_77 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_46    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_47    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_46… │\n",
              "│                     │                   │            │ max_pooling1d_47… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_48    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_31[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_48… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_14… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_15… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_82\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_82\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_46    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_47    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_46… │\n",
              "│                     │                   │            │ max_pooling1d_47… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_48    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_48… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_14… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_15… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_78 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_28       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_76 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_28[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_30       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_79 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_30[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_29       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_77 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_46    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_47    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_31       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_46… │\n",
              "│                     │                   │            │ max_pooling1d_47… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_48    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_31[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_48… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_14… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_15… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7402 - loss: 1.8689\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 231ms/step - accuracy: 0.7428 - loss: 1.8612 - val_accuracy: 0.8755 - val_loss: 1.6658\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8882 - loss: 1.0384\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - accuracy: 0.8884 - loss: 1.0352 - val_accuracy: 0.8755 - val_loss: 1.0672\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8770 - loss: 0.7128\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.8775 - loss: 0.7111 - val_accuracy: 0.8755 - val_loss: 0.8226\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9179 - loss: 0.5210\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 275ms/step - accuracy: 0.9173 - loss: 0.5217 - val_accuracy: 0.8755 - val_loss: 0.7736\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.8791 - loss: 0.5391\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 276ms/step - accuracy: 0.8796 - loss: 0.5381 - val_accuracy: 0.8755 - val_loss: 0.7627\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9112 - loss: 0.4580\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9110 - loss: 0.4584 - val_accuracy: 0.8755 - val_loss: 0.7382\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9086 - loss: 0.4616\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9088 - loss: 0.4612 - val_accuracy: 0.8755 - val_loss: 0.7201\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9062 - loss: 0.4573\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9066 - loss: 0.4566 - val_accuracy: 0.8755 - val_loss: 0.6740\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9326 - loss: 0.4130\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9326 - loss: 0.4130 - val_accuracy: 0.8755 - val_loss: 0.5942\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9135 - loss: 0.4357\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9138 - loss: 0.4352 - val_accuracy: 0.8755 - val_loss: 0.5154\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9423 - loss: 0.3912\n",
            "Epoch 11: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9421 - loss: 0.3914 - val_accuracy: 0.8755 - val_loss: 0.4768\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9184 - loss: 0.4239\n",
            "Epoch 12: val_accuracy improved from 0.87546 to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9184 - loss: 0.4234 - val_accuracy: 0.8791 - val_loss: 0.4535\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9405 - loss: 0.3807\n",
            "Epoch 13: val_accuracy improved from 0.87912 to 0.88645, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9405 - loss: 0.3809 - val_accuracy: 0.8864 - val_loss: 0.4479\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9487 - loss: 0.3607\n",
            "Epoch 14: val_accuracy improved from 0.88645 to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9486 - loss: 0.3610 - val_accuracy: 0.8901 - val_loss: 0.4389\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9507 - loss: 0.3785\n",
            "Epoch 15: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9507 - loss: 0.3779 - val_accuracy: 0.8901 - val_loss: 0.4317\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.9473 - loss: 0.3501\n",
            "Epoch 16: val_accuracy improved from 0.89011 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 343ms/step - accuracy: 0.9474 - loss: 0.3500 - val_accuracy: 0.9048 - val_loss: 0.3979\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9373 - loss: 0.3479\n",
            "Epoch 17: val_accuracy improved from 0.90476 to 0.91209, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.9375 - loss: 0.3475 - val_accuracy: 0.9121 - val_loss: 0.3773\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9514 - loss: 0.3207\n",
            "Epoch 18: val_accuracy improved from 0.91209 to 0.93773, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9515 - loss: 0.3207 - val_accuracy: 0.9377 - val_loss: 0.3380\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9551 - loss: 0.3363\n",
            "Epoch 19: val_accuracy improved from 0.93773 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.9552 - loss: 0.3356 - val_accuracy: 0.9560 - val_loss: 0.3051\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9571 - loss: 0.3128\n",
            "Epoch 20: val_accuracy did not improve from 0.95604\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9570 - loss: 0.3128 - val_accuracy: 0.9341 - val_loss: 0.3161\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9560 - loss: 0.2950\n",
            "Epoch 21: val_accuracy improved from 0.95604 to 0.97436, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9562 - loss: 0.2949 - val_accuracy: 0.9744 - val_loss: 0.2916\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.9678 - loss: 0.2810\n",
            "Epoch 22: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 409ms/step - accuracy: 0.9678 - loss: 0.2809 - val_accuracy: 0.9744 - val_loss: 0.2789\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9630 - loss: 0.2781\n",
            "Epoch 23: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.9630 - loss: 0.2783 - val_accuracy: 0.9634 - val_loss: 0.2894\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9648 - loss: 0.2766\n",
            "Epoch 24: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - accuracy: 0.9648 - loss: 0.2764 - val_accuracy: 0.9560 - val_loss: 0.2851\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9743 - loss: 0.2755\n",
            "Epoch 25: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9744 - loss: 0.2750 - val_accuracy: 0.9560 - val_loss: 0.2682\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9761 - loss: 0.2426\n",
            "Epoch 26: val_accuracy did not improve from 0.97436\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.9761 - loss: 0.2425 - val_accuracy: 0.9597 - val_loss: 0.2479\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9834 - loss: 0.2271\n",
            "Epoch 27: val_accuracy improved from 0.97436 to 0.98535, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.9833 - loss: 0.2272 - val_accuracy: 0.9853 - val_loss: 0.2227\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9810 - loss: 0.2216\n",
            "Epoch 28: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9810 - loss: 0.2218 - val_accuracy: 0.9744 - val_loss: 0.2252\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9796 - loss: 0.2178\n",
            "Epoch 29: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9796 - loss: 0.2182 - val_accuracy: 0.9487 - val_loss: 0.2472\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9725 - loss: 0.2284\n",
            "Epoch 30: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9726 - loss: 0.2284 - val_accuracy: 0.9524 - val_loss: 0.2985\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9892 - loss: 0.2062\n",
            "Epoch 31: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9892 - loss: 0.2064 - val_accuracy: 0.9817 - val_loss: 0.2263\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9880 - loss: 0.2121\n",
            "Epoch 32: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9880 - loss: 0.2121 - val_accuracy: 0.9707 - val_loss: 0.2094\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9861 - loss: 0.2036\n",
            "Epoch 33: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9863 - loss: 0.2033 - val_accuracy: 0.9670 - val_loss: 0.2195\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9918 - loss: 0.1901\n",
            "Epoch 34: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 300ms/step - accuracy: 0.9916 - loss: 0.1903 - val_accuracy: 0.9560 - val_loss: 0.2248\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9852 - loss: 0.1985\n",
            "Epoch 35: val_accuracy improved from 0.98535 to 0.99267, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9852 - loss: 0.1983 - val_accuracy: 0.9927 - val_loss: 0.1757\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9897 - loss: 0.1907\n",
            "Epoch 36: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9896 - loss: 0.1908 - val_accuracy: 0.9853 - val_loss: 0.1783\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9923 - loss: 0.1766\n",
            "Epoch 37: val_accuracy did not improve from 0.99267\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9924 - loss: 0.1767 - val_accuracy: 0.9744 - val_loss: 0.1868\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9880 - loss: 0.1711\n",
            "Epoch 38: val_accuracy improved from 0.99267 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9880 - loss: 0.1712 - val_accuracy: 1.0000 - val_loss: 0.1612\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9985 - loss: 0.1617\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9985 - loss: 0.1616 - val_accuracy: 0.9744 - val_loss: 0.1876\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9962 - loss: 0.1512\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9962 - loss: 0.1515 - val_accuracy: 0.9524 - val_loss: 0.2502\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9925 - loss: 0.1550\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.9925 - loss: 0.1552 - val_accuracy: 0.9817 - val_loss: 0.1887\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9923 - loss: 0.1577\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9923 - loss: 0.1576 - val_accuracy: 0.9634 - val_loss: 0.1895\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9871 - loss: 0.1647\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9871 - loss: 0.1649 - val_accuracy: 1.0000 - val_loss: 0.1602\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9787 - loss: 0.1724\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9789 - loss: 0.1722 - val_accuracy: 0.9634 - val_loss: 0.1815\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9976 - loss: 0.1440\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 354ms/step - accuracy: 0.9975 - loss: 0.1441 - val_accuracy: 0.9963 - val_loss: 0.1404\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.9794 - loss: 0.1698\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 372ms/step - accuracy: 0.9796 - loss: 0.1696 - val_accuracy: 0.9597 - val_loss: 0.2191\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9952 - loss: 0.1460\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9952 - loss: 0.1458 - val_accuracy: 0.9817 - val_loss: 0.1540\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9938 - loss: 0.1425\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.9938 - loss: 0.1424 - val_accuracy: 0.9780 - val_loss: 0.1538\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9977 - loss: 0.1297\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.9977 - loss: 0.1297 - val_accuracy: 0.9927 - val_loss: 0.1317\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9974 - loss: 0.1311\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.9973 - loss: 0.1311 - val_accuracy: 0.9890 - val_loss: 0.1403\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_3.keras\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_83\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_83\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_34       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_49    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_50    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_49… │\n",
              "│                     │                   │            │ max_pooling1d_50… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_51    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_51… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_16… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_17… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_80 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_83 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_81 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_32[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_34       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_84 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_34[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_82 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_49    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_50    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_49… │\n",
              "│                     │                   │            │ max_pooling1d_50… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_51    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_51… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_16… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_17… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_83\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_83\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_34       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_49    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_50    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_49… │\n",
              "│                     │                   │            │ max_pooling1d_50… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_51    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_51… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_16… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_17… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_80 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_83 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_32       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_81 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_32[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_34       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_84 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_34[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_82 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_49    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_50    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_35       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_49… │\n",
              "│                     │                   │            │ max_pooling1d_50… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_51    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_35[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_51… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_16… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_17… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.5391 - loss: 2.1186\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89011, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 243ms/step - accuracy: 0.5444 - loss: 2.1130 - val_accuracy: 0.8901 - val_loss: 1.9729\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8998 - loss: 1.4235\n",
            "Epoch 2: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.8996 - loss: 1.4209 - val_accuracy: 0.8755 - val_loss: 1.4614\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9073 - loss: 1.0002\n",
            "Epoch 3: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.9069 - loss: 0.9990 - val_accuracy: 0.8755 - val_loss: 1.1065\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.8950 - loss: 0.7697\n",
            "Epoch 4: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.8952 - loss: 0.7685 - val_accuracy: 0.8755 - val_loss: 0.8762\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9059 - loss: 0.6131\n",
            "Epoch 5: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 366ms/step - accuracy: 0.9059 - loss: 0.6123 - val_accuracy: 0.8755 - val_loss: 0.7765\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9158 - loss: 0.5219\n",
            "Epoch 6: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 338ms/step - accuracy: 0.9159 - loss: 0.5217 - val_accuracy: 0.8755 - val_loss: 0.7323\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9160 - loss: 0.5054\n",
            "Epoch 7: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.9162 - loss: 0.5049 - val_accuracy: 0.8755 - val_loss: 0.6672\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9135 - loss: 0.4478\n",
            "Epoch 8: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 338ms/step - accuracy: 0.9135 - loss: 0.4481 - val_accuracy: 0.8755 - val_loss: 0.6374\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9293 - loss: 0.4230\n",
            "Epoch 9: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 376ms/step - accuracy: 0.9290 - loss: 0.4235 - val_accuracy: 0.8755 - val_loss: 0.5947\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9310 - loss: 0.4285\n",
            "Epoch 10: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9310 - loss: 0.4284 - val_accuracy: 0.8755 - val_loss: 0.5287\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9259 - loss: 0.4280\n",
            "Epoch 11: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - accuracy: 0.9259 - loss: 0.4277 - val_accuracy: 0.8755 - val_loss: 0.5020\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9385 - loss: 0.3905\n",
            "Epoch 12: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 294ms/step - accuracy: 0.9384 - loss: 0.3909 - val_accuracy: 0.8755 - val_loss: 0.4918\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9423 - loss: 0.3955\n",
            "Epoch 13: val_accuracy did not improve from 0.89011\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.9421 - loss: 0.3954 - val_accuracy: 0.8755 - val_loss: 0.4718\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9400 - loss: 0.4125\n",
            "Epoch 14: val_accuracy improved from 0.89011 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 340ms/step - accuracy: 0.9402 - loss: 0.4117 - val_accuracy: 0.8938 - val_loss: 0.4528\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9458 - loss: 0.3644\n",
            "Epoch 15: val_accuracy improved from 0.89377 to 0.90476, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9458 - loss: 0.3647 - val_accuracy: 0.9048 - val_loss: 0.4308\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9516 - loss: 0.3733\n",
            "Epoch 16: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9516 - loss: 0.3729 - val_accuracy: 0.9048 - val_loss: 0.3932\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9532 - loss: 0.3590\n",
            "Epoch 17: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.9533 - loss: 0.3588 - val_accuracy: 0.9048 - val_loss: 0.3991\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9573 - loss: 0.3207\n",
            "Epoch 18: val_accuracy did not improve from 0.90476\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9572 - loss: 0.3214 - val_accuracy: 0.9048 - val_loss: 0.3691\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9511 - loss: 0.3563\n",
            "Epoch 19: val_accuracy improved from 0.90476 to 0.91209, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9515 - loss: 0.3556 - val_accuracy: 0.9121 - val_loss: 0.3512\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9725 - loss: 0.3190\n",
            "Epoch 20: val_accuracy improved from 0.91209 to 0.96703, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 299ms/step - accuracy: 0.9725 - loss: 0.3189 - val_accuracy: 0.9670 - val_loss: 0.3140\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9572 - loss: 0.3080\n",
            "Epoch 21: val_accuracy improved from 0.96703 to 0.97802, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 298ms/step - accuracy: 0.9571 - loss: 0.3085 - val_accuracy: 0.9780 - val_loss: 0.2932\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9578 - loss: 0.3161\n",
            "Epoch 22: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9580 - loss: 0.3158 - val_accuracy: 0.9707 - val_loss: 0.2859\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.9780 - loss: 0.2803\n",
            "Epoch 23: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 364ms/step - accuracy: 0.9779 - loss: 0.2805 - val_accuracy: 0.9487 - val_loss: 0.3033\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9692 - loss: 0.2905\n",
            "Epoch 24: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - accuracy: 0.9692 - loss: 0.2904 - val_accuracy: 0.9597 - val_loss: 0.2832\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9741 - loss: 0.2674\n",
            "Epoch 25: val_accuracy improved from 0.97802 to 0.98535, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 327ms/step - accuracy: 0.9741 - loss: 0.2674 - val_accuracy: 0.9853 - val_loss: 0.2573\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9847 - loss: 0.2566\n",
            "Epoch 26: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 301ms/step - accuracy: 0.9847 - loss: 0.2567 - val_accuracy: 0.9744 - val_loss: 0.2493\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9758 - loss: 0.2549\n",
            "Epoch 27: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.9759 - loss: 0.2547 - val_accuracy: 0.9853 - val_loss: 0.2365\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9781 - loss: 0.2484\n",
            "Epoch 28: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.9781 - loss: 0.2482 - val_accuracy: 0.9780 - val_loss: 0.2323\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9801 - loss: 0.2423\n",
            "Epoch 29: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.9801 - loss: 0.2422 - val_accuracy: 0.9707 - val_loss: 0.2210\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9745 - loss: 0.2416\n",
            "Epoch 30: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9744 - loss: 0.2414 - val_accuracy: 0.9560 - val_loss: 0.2460\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9694 - loss: 0.2373\n",
            "Epoch 31: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9694 - loss: 0.2373 - val_accuracy: 0.9744 - val_loss: 0.2194\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.9795 - loss: 0.2430\n",
            "Epoch 32: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 331ms/step - accuracy: 0.9795 - loss: 0.2430 - val_accuracy: 0.9707 - val_loss: 0.2746\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9624 - loss: 0.2425\n",
            "Epoch 33: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 334ms/step - accuracy: 0.9623 - loss: 0.2430 - val_accuracy: 0.9670 - val_loss: 0.2569\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9650 - loss: 0.2352\n",
            "Epoch 34: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9653 - loss: 0.2348 - val_accuracy: 0.9707 - val_loss: 0.2181\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9812 - loss: 0.1993\n",
            "Epoch 35: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9813 - loss: 0.1994 - val_accuracy: 0.9744 - val_loss: 0.1991\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9825 - loss: 0.1939\n",
            "Epoch 36: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9825 - loss: 0.1939 - val_accuracy: 0.9853 - val_loss: 0.1834\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9788 - loss: 0.1967\n",
            "Epoch 37: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9786 - loss: 0.1972 - val_accuracy: 0.9634 - val_loss: 0.2630\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9642 - loss: 0.2308\n",
            "Epoch 38: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.9642 - loss: 0.2311 - val_accuracy: 0.9451 - val_loss: 0.2632\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9677 - loss: 0.2277\n",
            "Epoch 39: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 299ms/step - accuracy: 0.9679 - loss: 0.2275 - val_accuracy: 0.9707 - val_loss: 0.1965\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9827 - loss: 0.1994\n",
            "Epoch 40: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 321ms/step - accuracy: 0.9827 - loss: 0.1992 - val_accuracy: 0.9817 - val_loss: 0.1841\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9805 - loss: 0.1811\n",
            "Epoch 41: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 319ms/step - accuracy: 0.9805 - loss: 0.1811 - val_accuracy: 0.9744 - val_loss: 0.1820\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9874 - loss: 0.1654\n",
            "Epoch 42: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.9873 - loss: 0.1656 - val_accuracy: 0.9744 - val_loss: 0.1726\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9875 - loss: 0.1593\n",
            "Epoch 43: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 352ms/step - accuracy: 0.9873 - loss: 0.1595 - val_accuracy: 0.9853 - val_loss: 0.1561\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9875 - loss: 0.1642\n",
            "Epoch 44: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 327ms/step - accuracy: 0.9874 - loss: 0.1644 - val_accuracy: 0.9707 - val_loss: 0.1760\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9844 - loss: 0.1679\n",
            "Epoch 45: val_accuracy did not improve from 0.98535\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.9845 - loss: 0.1678 - val_accuracy: 0.9853 - val_loss: 0.1615\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9882 - loss: 0.1571\n",
            "Epoch 46: val_accuracy improved from 0.98535 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 318ms/step - accuracy: 0.9881 - loss: 0.1571 - val_accuracy: 0.9890 - val_loss: 0.1569\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9850 - loss: 0.1560\n",
            "Epoch 47: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.9851 - loss: 0.1558 - val_accuracy: 0.9853 - val_loss: 0.1426\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9914 - loss: 0.1404\n",
            "Epoch 48: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9914 - loss: 0.1406 - val_accuracy: 0.9853 - val_loss: 0.1390\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9801 - loss: 0.1525\n",
            "Epoch 49: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9802 - loss: 0.1522 - val_accuracy: 0.9853 - val_loss: 0.1406\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9818 - loss: 0.1538\n",
            "Epoch 50: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 351ms/step - accuracy: 0.9819 - loss: 0.1537 - val_accuracy: 0.9853 - val_loss: 0.1389\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_4.keras\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_84\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_84\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_52    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_53    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_52… │\n",
              "│                     │                   │            │ max_pooling1d_53… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_54… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_18… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_19… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_85 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_88 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_86 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_36[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_89 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_38[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_87 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_52    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_37[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_53    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_52… │\n",
              "│                     │                   │            │ max_pooling1d_53… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_39[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_54… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_18… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_19… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_84\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_84\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ activation_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ activation_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ reshape_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_52    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_53    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_52… │\n",
              "│                     │                   │            │ max_pooling1d_53… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_54… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,480</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ bidirectional_18… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ bidirectional_19… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_85 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m704\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_88 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m448\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_36       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_86 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m20,544\u001b[0m │ activation_36[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_38       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_89 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ activation_38[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_37       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_87 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ reshape_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv1d_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_52    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_37[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_53    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_39       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_52… │\n",
              "│                     │                   │            │ max_pooling1d_53… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_39[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_54… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m12,480\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │        \u001b[38;5;34m192\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m33,024\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ bidirectional_18… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ bidirectional_19… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,426</span> (407.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,426\u001b[0m (407.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,978</span> (406.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,978\u001b[0m (406.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7521 - loss: 2.0894\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87546, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 277ms/step - accuracy: 0.7547 - loss: 2.0844 - val_accuracy: 0.8755 - val_loss: 1.9331\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9017 - loss: 1.4389\n",
            "Epoch 2: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9016 - loss: 1.4355 - val_accuracy: 0.8755 - val_loss: 1.4744\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8872 - loss: 0.9636\n",
            "Epoch 3: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - accuracy: 0.8878 - loss: 0.9601 - val_accuracy: 0.8755 - val_loss: 1.0383\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9064 - loss: 0.6703\n",
            "Epoch 4: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9065 - loss: 0.6692 - val_accuracy: 0.8755 - val_loss: 0.8075\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9126 - loss: 0.5487\n",
            "Epoch 5: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 0.9127 - loss: 0.5482 - val_accuracy: 0.8755 - val_loss: 0.7221\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.9090 - loss: 0.5164\n",
            "Epoch 6: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 330ms/step - accuracy: 0.9094 - loss: 0.5153 - val_accuracy: 0.8755 - val_loss: 0.6889\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9195 - loss: 0.4477\n",
            "Epoch 7: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 331ms/step - accuracy: 0.9196 - loss: 0.4478 - val_accuracy: 0.8755 - val_loss: 0.6664\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9220 - loss: 0.4407\n",
            "Epoch 8: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 384ms/step - accuracy: 0.9220 - loss: 0.4405 - val_accuracy: 0.8755 - val_loss: 0.6321\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9370 - loss: 0.4116\n",
            "Epoch 9: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9369 - loss: 0.4116 - val_accuracy: 0.8755 - val_loss: 0.6046\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9245 - loss: 0.4091\n",
            "Epoch 10: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 291ms/step - accuracy: 0.9248 - loss: 0.4088 - val_accuracy: 0.8755 - val_loss: 0.5983\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9310 - loss: 0.4049\n",
            "Epoch 11: val_accuracy did not improve from 0.87546\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.9312 - loss: 0.4046 - val_accuracy: 0.8755 - val_loss: 0.5004\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9567 - loss: 0.3597\n",
            "Epoch 12: val_accuracy improved from 0.87546 to 0.87912, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.9565 - loss: 0.3602 - val_accuracy: 0.8791 - val_loss: 0.4841\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9409 - loss: 0.3725\n",
            "Epoch 13: val_accuracy improved from 0.87912 to 0.89377, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9408 - loss: 0.3722 - val_accuracy: 0.8938 - val_loss: 0.4589\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9616 - loss: 0.3568\n",
            "Epoch 14: val_accuracy did not improve from 0.89377\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.9612 - loss: 0.3568 - val_accuracy: 0.8938 - val_loss: 0.4449\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9594 - loss: 0.3343\n",
            "Epoch 15: val_accuracy improved from 0.89377 to 0.90110, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.9593 - loss: 0.3345 - val_accuracy: 0.9011 - val_loss: 0.4153\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9617 - loss: 0.3385\n",
            "Epoch 16: val_accuracy improved from 0.90110 to 0.92674, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9617 - loss: 0.3386 - val_accuracy: 0.9267 - val_loss: 0.3737\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9678 - loss: 0.3271\n",
            "Epoch 17: val_accuracy did not improve from 0.92674\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.9675 - loss: 0.3272 - val_accuracy: 0.9231 - val_loss: 0.3754\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9533 - loss: 0.3282\n",
            "Epoch 18: val_accuracy improved from 0.92674 to 0.94139, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.9536 - loss: 0.3279 - val_accuracy: 0.9414 - val_loss: 0.3527\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9701 - loss: 0.3027\n",
            "Epoch 19: val_accuracy did not improve from 0.94139\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 311ms/step - accuracy: 0.9699 - loss: 0.3027 - val_accuracy: 0.9414 - val_loss: 0.3157\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9654 - loss: 0.3126\n",
            "Epoch 20: val_accuracy improved from 0.94139 to 0.95238, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.9653 - loss: 0.3122 - val_accuracy: 0.9524 - val_loss: 0.3020\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9472 - loss: 0.3099\n",
            "Epoch 21: val_accuracy improved from 0.95238 to 0.95604, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 316ms/step - accuracy: 0.9474 - loss: 0.3095 - val_accuracy: 0.9560 - val_loss: 0.2926\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9545 - loss: 0.3067\n",
            "Epoch 22: val_accuracy improved from 0.95604 to 0.96337, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 320ms/step - accuracy: 0.9547 - loss: 0.3060 - val_accuracy: 0.9634 - val_loss: 0.2690\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.9661 - loss: 0.2710\n",
            "Epoch 23: val_accuracy improved from 0.96337 to 0.97802, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 0.9662 - loss: 0.2710 - val_accuracy: 0.9780 - val_loss: 0.2603\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9765 - loss: 0.2720\n",
            "Epoch 24: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9765 - loss: 0.2718 - val_accuracy: 0.9744 - val_loss: 0.2433\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9635 - loss: 0.2643\n",
            "Epoch 25: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 275ms/step - accuracy: 0.9636 - loss: 0.2641 - val_accuracy: 0.9487 - val_loss: 0.2895\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9599 - loss: 0.2786\n",
            "Epoch 26: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9598 - loss: 0.2786 - val_accuracy: 0.9597 - val_loss: 0.2796\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9692 - loss: 0.2571\n",
            "Epoch 27: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 298ms/step - accuracy: 0.9691 - loss: 0.2572 - val_accuracy: 0.9707 - val_loss: 0.2469\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9650 - loss: 0.2440\n",
            "Epoch 28: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9651 - loss: 0.2440 - val_accuracy: 0.9780 - val_loss: 0.2338\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9800 - loss: 0.2295\n",
            "Epoch 29: val_accuracy did not improve from 0.97802\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9800 - loss: 0.2294 - val_accuracy: 0.9707 - val_loss: 0.2245\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9877 - loss: 0.2041\n",
            "Epoch 30: val_accuracy improved from 0.97802 to 0.98901, saving model to /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9876 - loss: 0.2046 - val_accuracy: 0.9890 - val_loss: 0.2043\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9786 - loss: 0.2138\n",
            "Epoch 31: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.9786 - loss: 0.2138 - val_accuracy: 0.9817 - val_loss: 0.2006\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9765 - loss: 0.2167\n",
            "Epoch 32: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9766 - loss: 0.2167 - val_accuracy: 0.9670 - val_loss: 0.2192\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9728 - loss: 0.2163\n",
            "Epoch 33: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 276ms/step - accuracy: 0.9729 - loss: 0.2163 - val_accuracy: 0.9817 - val_loss: 0.1953\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9837 - loss: 0.1994\n",
            "Epoch 34: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.9837 - loss: 0.1993 - val_accuracy: 0.9817 - val_loss: 0.1851\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9862 - loss: 0.1948\n",
            "Epoch 35: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9861 - loss: 0.1948 - val_accuracy: 0.9890 - val_loss: 0.1763\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9843 - loss: 0.1896\n",
            "Epoch 36: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 299ms/step - accuracy: 0.9843 - loss: 0.1896 - val_accuracy: 0.9817 - val_loss: 0.1741\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9786 - loss: 0.1942\n",
            "Epoch 37: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9789 - loss: 0.1939 - val_accuracy: 0.9817 - val_loss: 0.1685\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.9810 - loss: 0.1809\n",
            "Epoch 38: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - accuracy: 0.9809 - loss: 0.1811 - val_accuracy: 0.9634 - val_loss: 0.1953\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9708 - loss: 0.1974\n",
            "Epoch 39: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9706 - loss: 0.1976 - val_accuracy: 0.9670 - val_loss: 0.2087\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9680 - loss: 0.2089\n",
            "Epoch 40: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 321ms/step - accuracy: 0.9681 - loss: 0.2086 - val_accuracy: 0.9597 - val_loss: 0.1991\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9749 - loss: 0.1908\n",
            "Epoch 41: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9747 - loss: 0.1909 - val_accuracy: 0.9487 - val_loss: 0.2334\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9795 - loss: 0.1786\n",
            "Epoch 42: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - accuracy: 0.9795 - loss: 0.1787 - val_accuracy: 0.9634 - val_loss: 0.2133\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9895 - loss: 0.1630\n",
            "Epoch 43: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 296ms/step - accuracy: 0.9893 - loss: 0.1631 - val_accuracy: 0.9670 - val_loss: 0.1934\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9662 - loss: 0.2252\n",
            "Epoch 44: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.9657 - loss: 0.2263 - val_accuracy: 0.9011 - val_loss: 0.3428\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9550 - loss: 0.2471\n",
            "Epoch 45: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9550 - loss: 0.2468 - val_accuracy: 0.9451 - val_loss: 0.2391\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9654 - loss: 0.2050\n",
            "Epoch 46: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9656 - loss: 0.2045 - val_accuracy: 0.9670 - val_loss: 0.1974\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9896 - loss: 0.1567\n",
            "Epoch 47: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9896 - loss: 0.1568 - val_accuracy: 0.9597 - val_loss: 0.1801\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9857 - loss: 0.1605\n",
            "Epoch 48: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9855 - loss: 0.1607 - val_accuracy: 0.9487 - val_loss: 0.1978\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9741 - loss: 0.1705\n",
            "Epoch 49: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9742 - loss: 0.1703 - val_accuracy: 0.9744 - val_loss: 0.1638\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9721 - loss: 0.1757\n",
            "Epoch 50: val_accuracy did not improve from 0.98901\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 285ms/step - accuracy: 0.9723 - loss: 0.1753 - val_accuracy: 0.9817 - val_loss: 0.1429\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
            "Best model saved at: /Users/user/Downloads/Code_Final_Version/Imbalanced_Final_Results/IR_50_1_Ratio/1D_CNN_LSTM_Attention/modified_1D_CNN_LSTM_Attention_best_model_5.keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "## Model 2\n",
        "from keras import layers, Model, Input\n",
        "from keras.layers import (\n",
        "    Conv1D, MaxPooling1D, Dropout, Dense, LSTM, Bidirectional,\n",
        "    BatchNormalization, LayerNormalization, MultiHeadAttention,\n",
        "    Reshape, Concatenate, Add, Activation\n",
        ")\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "class CNN_1D_LSTM_Attn_Modified():\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "        self.model.summary()\n",
        "\n",
        "    def build_model(self):\n",
        "        input_seq = Input(shape=(1600,))\n",
        "        X = Reshape((1600, 1))(input_seq)\n",
        "\n",
        "        # CNN Branch 1\n",
        "        branch1 = Conv1D(64, 10, strides=2, padding='same')(X)  # (800, 32)\n",
        "        branch1 = BatchNormalization()(branch1)\n",
        "        branch1 = Activation('relu')(branch1)\n",
        "        branch1 = Conv1D(64, 5, strides=2, padding='same')(branch1)  # (400, 16)\n",
        "        branch1 = BatchNormalization()(branch1)\n",
        "        branch1 = Activation('relu')(branch1)\n",
        "        branch1 = MaxPooling1D(pool_size=2)(branch1)  # (200, 16)\n",
        "\n",
        "        # Residual shortcut\n",
        "        shortcut1 = Conv1D(64, 1, strides=4, padding='same')(X)  # (400, 16)\n",
        "        shortcut1 = MaxPooling1D(pool_size=2)(shortcut1)  # (200, 16)\n",
        "        branch1 = Add()([branch1, shortcut1])  # (200, 16)\n",
        "\n",
        "        # CNN Branch 2\n",
        "        branch2 = Conv1D(64, 6, strides=2, padding='same')(X)  # (800, 32)\n",
        "        branch2 = BatchNormalization()(branch2)\n",
        "        branch2 = Activation('relu')(branch2)\n",
        "        branch2 = Conv1D(32, 3, strides=2, padding='same')(branch2)  # (400, 16)\n",
        "        branch2 = BatchNormalization()(branch2)\n",
        "        branch2 = Activation('relu')(branch2)\n",
        "        branch2 = MaxPooling1D(pool_size=2)(branch2)  # (200, 16)\n",
        "\n",
        "        # Merge branches\n",
        "        combined = Concatenate(axis=-1)([branch1, branch2])  # (200, 32)\n",
        "        combined = LayerNormalization()(combined)\n",
        "\n",
        "        # Multi-head attention\n",
        "        attn_out = MultiHeadAttention(num_heads=4, key_dim=8)(combined, combined)\n",
        "        attn_out = LayerNormalization()(attn_out)\n",
        "\n",
        "        # Bidirectional LSTM\n",
        "        x = Bidirectional(LSTM(32, return_sequences=True))(attn_out)\n",
        "        x = Bidirectional(LSTM(32))(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        output = Dense(10, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
        "\n",
        "        # Final model\n",
        "        model = Model(input_seq, output)\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        # # Learning rate scheduler\n",
        "        # lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "        # self.callbacks = [lr_scheduler]\n",
        "\n",
        "        return model\n",
        "\n",
        "os.makedirs(foldername_cnn_lstm_attn, exist_ok=True)\n",
        "\n",
        "# For K-Fold\n",
        "y_train_classes = np.argmax(y_train, axis=1)\n",
        "k_splits = 5\n",
        "kfold = StratifiedKFold(n_splits=k_splits, shuffle=False)\n",
        "\n",
        "# Metric storage\n",
        "mod_accuracy_1D, mod_precision_1D, mod_recall_1D, mod_f1_1D, mod_log_loss_1D, mod_balanced_accuracy_1D = [], [], [], [], [], []\n",
        "mod_accuracy_1D_test, mod_precision_1D_test, mod_recall_1D_test, mod_f1_1D_test, mod_log_loss_1D_test, mod_balanced_accuracy_1D_test = [], [], [], [], [], []\n",
        "\n",
        "# ------------------ Training Loop ------------------\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    checkpoint_filepath = os.path.join(foldername_cnn_lstm_attn, f\"modified_1D_CNN_LSTM_Attention_best_model_{fold + 1}.keras\")\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "                                 save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    model = CNN_1D_LSTM_Attn_Modified()\n",
        "    model.model.fit(\n",
        "        X_train[train_idx], y_train[train_idx],\n",
        "        validation_data=(X_train[val_idx], y_train[val_idx]),\n",
        "        epochs=50,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "    best_model = load_model(checkpoint_filepath)\n",
        "\n",
        "    # Train fold subset evaluation\n",
        "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "\n",
        "    mod_accuracy_1D.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "    mod_precision_1D.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    mod_recall_1D.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    mod_f1_1D.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "    mod_log_loss_1D.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "    mod_balanced_accuracy_1D.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "\n",
        "\n",
        "    # Save confusion matrix for train\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Modified_1D CNN + LSTM + Attention Train Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm_attn, f\"Modified_1D_CNN_LSTM_Attention_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Fixed test set evaluation\n",
        "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "    y_true_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    mod_accuracy_1D_test.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "    mod_precision_1D_test.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    mod_recall_1D_test.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    mod_f1_1D_test.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "    mod_log_loss_1D_test.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "    mod_balanced_accuracy_1D_test.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "\n",
        "    # Save confusion matrix for test\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "    plt.title(f'Modified_1D CNN + LSTM + Attention Test Confusion Matrix - Fold {fold + 1}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(foldername_cnn_lstm_attn, f\"Modified_1D_CNN_LSTM_Attention_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Best model saved at: {checkpoint_filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modified 1D CNN+LSTM+ATTENTION Training Metrics:\n",
            "Train Accuracy: [0.999, 0.987, 0.998, 0.991, 0.982]\n",
            "Test Accuracy: [0.974, 0.965, 0.983, 0.971, 0.974]\n",
            "Precision: [0.973, 0.968, 0.989, 0.971, 0.967]\n",
            "Recall: [0.974, 0.965, 0.983, 0.971, 0.974]\n",
            "F1 Score: [0.969, 0.959, 0.98, 0.969, 0.969]\n",
            "Log Loss: [0.117, 0.121, 0.091, 0.099, 0.109]\n",
            "Balanced Accuracy: [0.82, 0.76, 0.88, 0.8, 0.82]\n"
          ]
        }
      ],
      "source": [
        "print(\"Modified 1D CNN+LSTM+ATTENTION Metrics:\")\n",
        "print(f\"Train Accuracy: {mod_accuracy_1D}\")\n",
        "print(f\"Test Accuracy: {mod_accuracy_1D_test}\")\n",
        "print(f\"Precision: {mod_precision_1D_test}\")\n",
        "print(f\"Recall: {mod_recall_1D_test}\")\n",
        "print(f\"F1 Score: {mod_f1_1D_test}\")\n",
        "print(f\"Log Loss: {mod_log_loss_1D_test}\")\n",
        "print(f\"Balanced Accuracy: {mod_balanced_accuracy_1D_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Log Loss</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1D CNN</td>\n",
              "      <td>0.9668</td>\n",
              "      <td>0.9540</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9540</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.1854</td>\n",
              "      <td>0.684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1D CNN + Attention</td>\n",
              "      <td>0.9998</td>\n",
              "      <td>0.9894</td>\n",
              "      <td>0.9902</td>\n",
              "      <td>0.9894</td>\n",
              "      <td>0.9882</td>\n",
              "      <td>0.0308</td>\n",
              "      <td>0.928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1D CNN + LSTM</td>\n",
              "      <td>0.9104</td>\n",
              "      <td>0.9110</td>\n",
              "      <td>0.8982</td>\n",
              "      <td>0.9110</td>\n",
              "      <td>0.8986</td>\n",
              "      <td>0.2428</td>\n",
              "      <td>0.388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1D CNN + LSTM + Attention</td>\n",
              "      <td>0.9772</td>\n",
              "      <td>0.9650</td>\n",
              "      <td>0.9596</td>\n",
              "      <td>0.9650</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Modified 1D CNN + LSTM + Attention</td>\n",
              "      <td>0.9914</td>\n",
              "      <td>0.9734</td>\n",
              "      <td>0.9736</td>\n",
              "      <td>0.9734</td>\n",
              "      <td>0.9692</td>\n",
              "      <td>0.1074</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Model  Train Accuracy  Test Accuracy  \\\n",
              "0                              1D CNN          0.9668         0.9540   \n",
              "1                  1D CNN + Attention          0.9998         0.9894   \n",
              "2                       1D CNN + LSTM          0.9104         0.9110   \n",
              "3           1D CNN + LSTM + Attention          0.9772         0.9650   \n",
              "4  Modified 1D CNN + LSTM + Attention          0.9914         0.9734   \n",
              "\n",
              "   Precision  Recall  F1 Score  Log Loss  Balanced Accuracy  \n",
              "0     0.9500  0.9540    0.9470    0.1854              0.684  \n",
              "1     0.9902  0.9894    0.9882    0.0308              0.928  \n",
              "2     0.8982  0.9110    0.8986    0.2428              0.388  \n",
              "3     0.9596  0.9650    0.9590    0.1444              0.760  \n",
              "4     0.9736  0.9734    0.9692    0.1074              0.816  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric_df = pd.DataFrame({\n",
        "    'Model': ['1D CNN', '1D CNN + Attention', '1D CNN + LSTM', '1D CNN + LSTM + Attention', 'Modified 1D CNN + LSTM + Attention'],\n",
        "    'Train Accuracy': [np.mean(accuracy_1D_cnn), np.mean(accuracy_1D_cnn_attn), np.mean(accuracy_1D_cnn_lstm), np.mean(accuracy_1D_cnn_lstm_attn), np.mean(mod_accuracy_1D)],\n",
        "    'Test Accuracy': [np.mean(accuracy_1D_test_cnn), np.mean(accuracy_1D_test_cnn_attn), np.mean(accuracy_1D_test_cnn_lstm), np.mean(accuracy_1D_test_cnn_lstm_attn), np.mean(mod_accuracy_1D_test)],\n",
        "    'Precision': [np.mean(precision_1D_test_cnn), np.mean(precision_1D_test_cnn_attn), np.mean(precision_1D_test_cnn_lstm), np.mean(precision_1D_test_cnn_lstm_attn), np.mean(mod_precision_1D_test)],\n",
        "    'Recall': [np.mean(recall_1D_test_cnn), np.mean(recall_1D_test_cnn_attn), np.mean(recall_1D_test_cnn_lstm), np.mean(recall_1D_test_cnn_lstm_attn), np.mean(mod_recall_1D_test)],\n",
        "    'F1 Score': [np.mean(f1_1D_test_cnn), np.mean(f1_1D_test_cnn_attn), np.mean(f1_1D_test_cnn_lstm), np.mean(f1_1D_test_cnn_lstm_attn), np.mean(mod_f1_1D_test)],\n",
        "    'Log Loss': [np.mean(log_loss_1D_test_cnn), np.mean(log_loss_1D_test_cnn_attn), np.mean(log_loss_1D_test_cnn_lstm), np.mean(log_loss_1D_test_cnn_lstm_attn), np.mean(mod_log_loss_1D_test)],\n",
        "    'Balanced Accuracy': [np.mean(balanced_accuracy_1D_test_cnn), np.mean(balanced_accuracy_1D_test_cnn_attn), np.mean(balanced_accuracy_1D_test_cnn_lstm), np.mean(balanced_accuracy_1D_test_cnn_lstm_attn), np.mean(mod_balanced_accuracy_1D_test)]\n",
        "})\n",
        "metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved to CWRU_IR_50_1_model_metrics.csv\n",
            "Training completed and metrics saved.\n",
            "All models have been trained and evaluated successfully.\n"
          ]
        }
      ],
      "source": [
        "metric_df.to_csv(os.path.join(os.getcwd(), 'CWRU_IR_50_1_model_metrics.csv'), index=False)\n",
        "print(\"Metrics saved to CWRU_IR_50_1_model_metrics.csv\")\n",
        "print(\"Training completed and metrics saved.\")\n",
        "print(\"All models have been trained and evaluated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(metric_df.set_index('Model').T, annot=True, cmap='YlOrRd', fmt='.3f', cbar_kws={'label': 'Value'})\n",
        "plt.title('Heatmap of Average Metrics by Model')\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Metric')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1082.38x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Melt the DataFrame for easier plotting with seaborn\n",
        "metric_df_melted = metric_df.melt(id_vars='Model', var_name='Metric', value_name='Value')\n",
        "\n",
        "# Create a grouped bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.catplot(x='Model', y='Value', hue='Metric', kind='bar', data=metric_df_melted, height=6, aspect=1.5, palette='muted')\n",
        "plt.title('Average Performance Metrics Across Models')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.ylim(0, 1.1)  # Adjust based on your data range (e.g., log loss might need scaling)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                Model                       Train Accuracy  \\\n",
            "0                              1D CNN  [0.951, 0.976, 0.983, 0.956, 0.968]   \n",
            "1                  1D CNN + Attention          [1.0, 1.0, 1.0, 0.999, 1.0]   \n",
            "2                       1D CNN + LSTM  [0.905, 0.897, 0.923, 0.918, 0.909]   \n",
            "3           1D CNN + LSTM + Attention  [0.968, 0.991, 0.983, 0.965, 0.979]   \n",
            "4  Modified 1D CNN + LSTM + Attention  [0.999, 0.987, 0.998, 0.991, 0.982]   \n",
            "\n",
            "                         Test Accuracy                            Precision  \\\n",
            "0  [0.939, 0.965, 0.962, 0.948, 0.956]  [0.937, 0.961, 0.959, 0.937, 0.956]   \n",
            "1     [1.0, 0.98, 0.994, 0.985, 0.988]    [1.0, 0.973, 0.996, 0.991, 0.991]   \n",
            "2  [0.895, 0.895, 0.927, 0.922, 0.916]   [0.88, 0.875, 0.916, 0.916, 0.904]   \n",
            "3   [0.953, 0.985, 0.98, 0.936, 0.971]   [0.93, 0.989, 0.972, 0.938, 0.969]   \n",
            "4  [0.974, 0.965, 0.983, 0.971, 0.974]  [0.973, 0.968, 0.989, 0.971, 0.967]   \n",
            "\n",
            "                                Recall                             F1 Score  \\\n",
            "0  [0.939, 0.965, 0.962, 0.948, 0.956]   [0.931, 0.96, 0.956, 0.936, 0.952]   \n",
            "1     [1.0, 0.98, 0.994, 0.985, 0.988]    [1.0, 0.975, 0.994, 0.983, 0.989]   \n",
            "2  [0.895, 0.895, 0.927, 0.922, 0.916]   [0.882, 0.879, 0.91, 0.915, 0.901]   \n",
            "3   [0.953, 0.985, 0.98, 0.936, 0.971]  [0.939, 0.985, 0.975, 0.932, 0.964]   \n",
            "4  [0.974, 0.965, 0.983, 0.971, 0.974]   [0.969, 0.959, 0.98, 0.969, 0.969]   \n",
            "\n",
            "                              Log Loss              Balanced Accuracy  \n",
            "0  [0.291, 0.171, 0.094, 0.186, 0.185]  [0.58, 0.76, 0.74, 0.64, 0.7]  \n",
            "1   [0.007, 0.06, 0.024, 0.038, 0.025]   [1.0, 0.86, 0.96, 0.9, 0.92]  \n",
            "2  [0.235, 0.272, 0.209, 0.242, 0.256]  [0.28, 0.28, 0.5, 0.46, 0.42]  \n",
            "3   [0.15, 0.111, 0.138, 0.186, 0.137]   [0.68, 0.9, 0.86, 0.56, 0.8]  \n",
            "4  [0.117, 0.121, 0.091, 0.099, 0.109]  [0.82, 0.76, 0.88, 0.8, 0.82]  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the updated data\n",
        "data = {\n",
        "    'Model': [\n",
        "        '1D CNN',\n",
        "        '1D CNN + Attention',\n",
        "        '1D CNN + LSTM',\n",
        "        '1D CNN + LSTM + Attention',\n",
        "        'Modified 1D CNN + LSTM + Attention'\n",
        "    ],\n",
        "    'Train Accuracy': [\n",
        "        [0.951, 0.976, 0.983, 0.956, 0.968],\n",
        "        [1.0, 1.0, 1.0, 0.999, 1.0],\n",
        "        [0.905, 0.897, 0.923, 0.918, 0.909],\n",
        "        [0.968, 0.991, 0.983, 0.965, 0.979],\n",
        "        [0.999, 0.987, 0.998, 0.991, 0.982]\n",
        "    ],\n",
        "    'Test Accuracy': [\n",
        "        [0.939, 0.965, 0.962, 0.948, 0.956],\n",
        "        [1.0, 0.98, 0.994, 0.985, 0.988],\n",
        "        [0.895, 0.895, 0.927, 0.922, 0.916],\n",
        "        [0.953, 0.985, 0.98, 0.936, 0.971],\n",
        "        [0.974, 0.965, 0.983, 0.971, 0.974]\n",
        "    ],\n",
        "    'Precision': [\n",
        "        [0.937, 0.961, 0.959, 0.937, 0.956],\n",
        "        [1.0, 0.973, 0.996, 0.991, 0.991],\n",
        "        [0.88, 0.875, 0.916, 0.916, 0.904],\n",
        "        [0.93, 0.989, 0.972, 0.938, 0.969],\n",
        "        [0.973, 0.968, 0.989, 0.971, 0.967]\n",
        "    ],\n",
        "    'Recall': [\n",
        "        [0.939, 0.965, 0.962, 0.948, 0.956],\n",
        "        [1.0, 0.98, 0.994, 0.985, 0.988],\n",
        "        [0.895, 0.895, 0.927, 0.922, 0.916],\n",
        "        [0.953, 0.985, 0.98, 0.936, 0.971],\n",
        "        [0.974, 0.965, 0.983, 0.971, 0.974]\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        [0.931, 0.96, 0.956, 0.936, 0.952],\n",
        "        [1.0, 0.975, 0.994, 0.983, 0.989],\n",
        "        [0.882, 0.879, 0.91, 0.915, 0.901],\n",
        "        [0.939, 0.985, 0.975, 0.932, 0.964],\n",
        "        [0.969, 0.959, 0.98, 0.969, 0.969]\n",
        "    ],\n",
        "    'Log Loss': [\n",
        "        [0.291, 0.171, 0.094, 0.186, 0.185],\n",
        "        [0.007, 0.06, 0.024, 0.038, 0.025],\n",
        "        [0.235, 0.272, 0.209, 0.242, 0.256],\n",
        "        [0.15, 0.111, 0.138, 0.186, 0.137],\n",
        "        [0.117, 0.121, 0.091, 0.099, 0.109]\n",
        "    ],\n",
        "    'Balanced Accuracy': [\n",
        "        [0.58, 0.76, 0.74, 0.64, 0.7],\n",
        "        [1.0, 0.86, 0.96, 0.9, 0.92],\n",
        "        [0.28, 0.28, 0.5, 0.46, 0.42],\n",
        "        [0.68, 0.9, 0.86, 0.56, 0.8],\n",
        "        [0.82, 0.76, 0.88, 0.8, 0.82]\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df)\n",
        "\n",
        "# Save to CSV (optional)\n",
        "df.to_csv('CWRU_IR_50_1_all_metrics.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Log Loss</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1D CNN</td>\n",
              "      <td>[0.951, 0.976, 0.983, 0.956, 0.968]</td>\n",
              "      <td>[0.939, 0.965, 0.962, 0.948, 0.956]</td>\n",
              "      <td>[0.937, 0.961, 0.959, 0.937, 0.956]</td>\n",
              "      <td>[0.939, 0.965, 0.962, 0.948, 0.956]</td>\n",
              "      <td>[0.931, 0.96, 0.956, 0.936, 0.952]</td>\n",
              "      <td>[0.291, 0.171, 0.094, 0.186, 0.185]</td>\n",
              "      <td>[0.58, 0.76, 0.74, 0.64, 0.7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1D CNN + Attention</td>\n",
              "      <td>[1.0, 1.0, 1.0, 0.999, 1.0]</td>\n",
              "      <td>[1.0, 0.98, 0.994, 0.985, 0.988]</td>\n",
              "      <td>[1.0, 0.973, 0.996, 0.991, 0.991]</td>\n",
              "      <td>[1.0, 0.98, 0.994, 0.985, 0.988]</td>\n",
              "      <td>[1.0, 0.975, 0.994, 0.983, 0.989]</td>\n",
              "      <td>[0.007, 0.06, 0.024, 0.038, 0.025]</td>\n",
              "      <td>[1.0, 0.86, 0.96, 0.9, 0.92]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1D CNN + LSTM</td>\n",
              "      <td>[0.905, 0.897, 0.923, 0.918, 0.909]</td>\n",
              "      <td>[0.895, 0.895, 0.927, 0.922, 0.916]</td>\n",
              "      <td>[0.88, 0.875, 0.916, 0.916, 0.904]</td>\n",
              "      <td>[0.895, 0.895, 0.927, 0.922, 0.916]</td>\n",
              "      <td>[0.882, 0.879, 0.91, 0.915, 0.901]</td>\n",
              "      <td>[0.235, 0.272, 0.209, 0.242, 0.256]</td>\n",
              "      <td>[0.28, 0.28, 0.5, 0.46, 0.42]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1D CNN + LSTM + Attention</td>\n",
              "      <td>[0.968, 0.991, 0.983, 0.965, 0.979]</td>\n",
              "      <td>[0.953, 0.985, 0.98, 0.936, 0.971]</td>\n",
              "      <td>[0.93, 0.989, 0.972, 0.938, 0.969]</td>\n",
              "      <td>[0.953, 0.985, 0.98, 0.936, 0.971]</td>\n",
              "      <td>[0.939, 0.985, 0.975, 0.932, 0.964]</td>\n",
              "      <td>[0.15, 0.111, 0.138, 0.186, 0.137]</td>\n",
              "      <td>[0.68, 0.9, 0.86, 0.56, 0.8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Modified 1D CNN + LSTM + Attention</td>\n",
              "      <td>[0.999, 0.987, 0.998, 0.991, 0.982]</td>\n",
              "      <td>[0.974, 0.965, 0.983, 0.971, 0.974]</td>\n",
              "      <td>[0.973, 0.968, 0.989, 0.971, 0.967]</td>\n",
              "      <td>[0.974, 0.965, 0.983, 0.971, 0.974]</td>\n",
              "      <td>[0.969, 0.959, 0.98, 0.969, 0.969]</td>\n",
              "      <td>[0.117, 0.121, 0.091, 0.099, 0.109]</td>\n",
              "      <td>[0.82, 0.76, 0.88, 0.8, 0.82]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Model                       Train Accuracy  \\\n",
              "0                              1D CNN  [0.951, 0.976, 0.983, 0.956, 0.968]   \n",
              "1                  1D CNN + Attention          [1.0, 1.0, 1.0, 0.999, 1.0]   \n",
              "2                       1D CNN + LSTM  [0.905, 0.897, 0.923, 0.918, 0.909]   \n",
              "3           1D CNN + LSTM + Attention  [0.968, 0.991, 0.983, 0.965, 0.979]   \n",
              "4  Modified 1D CNN + LSTM + Attention  [0.999, 0.987, 0.998, 0.991, 0.982]   \n",
              "\n",
              "                         Test Accuracy                            Precision  \\\n",
              "0  [0.939, 0.965, 0.962, 0.948, 0.956]  [0.937, 0.961, 0.959, 0.937, 0.956]   \n",
              "1     [1.0, 0.98, 0.994, 0.985, 0.988]    [1.0, 0.973, 0.996, 0.991, 0.991]   \n",
              "2  [0.895, 0.895, 0.927, 0.922, 0.916]   [0.88, 0.875, 0.916, 0.916, 0.904]   \n",
              "3   [0.953, 0.985, 0.98, 0.936, 0.971]   [0.93, 0.989, 0.972, 0.938, 0.969]   \n",
              "4  [0.974, 0.965, 0.983, 0.971, 0.974]  [0.973, 0.968, 0.989, 0.971, 0.967]   \n",
              "\n",
              "                                Recall                             F1 Score  \\\n",
              "0  [0.939, 0.965, 0.962, 0.948, 0.956]   [0.931, 0.96, 0.956, 0.936, 0.952]   \n",
              "1     [1.0, 0.98, 0.994, 0.985, 0.988]    [1.0, 0.975, 0.994, 0.983, 0.989]   \n",
              "2  [0.895, 0.895, 0.927, 0.922, 0.916]   [0.882, 0.879, 0.91, 0.915, 0.901]   \n",
              "3   [0.953, 0.985, 0.98, 0.936, 0.971]  [0.939, 0.985, 0.975, 0.932, 0.964]   \n",
              "4  [0.974, 0.965, 0.983, 0.971, 0.974]   [0.969, 0.959, 0.98, 0.969, 0.969]   \n",
              "\n",
              "                              Log Loss              Balanced Accuracy  \n",
              "0  [0.291, 0.171, 0.094, 0.186, 0.185]  [0.58, 0.76, 0.74, 0.64, 0.7]  \n",
              "1   [0.007, 0.06, 0.024, 0.038, 0.025]   [1.0, 0.86, 0.96, 0.9, 0.92]  \n",
              "2  [0.235, 0.272, 0.209, 0.242, 0.256]  [0.28, 0.28, 0.5, 0.46, 0.42]  \n",
              "3   [0.15, 0.111, 0.138, 0.186, 0.137]   [0.68, 0.9, 0.86, 0.56, 0.8]  \n",
              "4  [0.117, 0.121, 0.091, 0.099, 0.109]  [0.82, 0.76, 0.88, 0.8, 0.82]  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define fold-wise metrics\n",
        "folds = ['1', '2', '3', '4', '5', 'Avg']\n",
        "\n",
        "# 1D CNN\n",
        "cnn_train = [0.951, 0.976, 0.983, 0.956, 0.968]\n",
        "cnn_test = [0.939, 0.965, 0.962, 0.948, 0.956]\n",
        "cnn_bal = [0.58, 0.76, 0.74, 0.64, 0.7]\n",
        "cnn_train.append(np.mean(cnn_train))\n",
        "cnn_test.append(np.mean(cnn_test))\n",
        "cnn_bal.append(np.mean(cnn_bal))\n",
        "\n",
        "# 1D CNN + LSTM\n",
        "lstm_train = [0.905, 0.897, 0.923, 0.918, 0.909]\n",
        "lstm_test = [0.895, 0.895, 0.927, 0.922, 0.916]\n",
        "lstm_bal = [0.28, 0.28, 0.5, 0.46, 0.42]\n",
        "lstm_train.append(np.mean(lstm_train))\n",
        "lstm_test.append(np.mean(lstm_test))\n",
        "lstm_bal.append(np.mean(lstm_bal))\n",
        "\n",
        "# Plot\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(folds))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# 1D CNN\n",
        "plt.bar(x - bar_width, cnn_train, width=bar_width, label='1D CNN Train Acc', color='skyblue')\n",
        "plt.bar(x, cnn_test, width=bar_width, label='1D CNN Test Acc', color='lightgreen')\n",
        "plt.bar(x + bar_width, cnn_bal, width=bar_width, label='1D CNN Balanced Acc', color='salmon')\n",
        "\n",
        "# 1D CNN + LSTM (optional separate plot for clarity)\n",
        "# Uncomment this to plot them together:\n",
        "# plt.bar(x - bar_width, lstm_train, width=bar_width, label='CNN+LSTM Train Acc', color='blue')\n",
        "# plt.bar(x, lstm_test, width=bar_width, label='CNN+LSTM Test Acc', color='green')\n",
        "# plt.bar(x + bar_width, lstm_bal, width=bar_width, label='CNN+LSTM Balanced Acc', color='red')\n",
        "\n",
        "# Labels and Title\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('1D CNN Train, Test, and Balanced Accuracy per Fold - CWRU(2HP)')\n",
        "plt.xticks(ticks=x, labels=folds)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define fold-wise metrics\n",
        "folds = ['1', '2', '3', '4', '5', 'Avg']\n",
        "\n",
        "# 1D CNN\n",
        "cnn_train = [0.951, 0.976, 0.983, 0.956, 0.968]\n",
        "cnn_test = [0.939, 0.965, 0.962, 0.948, 0.956]\n",
        "cnn_bal = [0.58, 0.76, 0.74, 0.64, 0.7]\n",
        "cnn_train.append(np.mean(cnn_train))\n",
        "cnn_test.append(np.mean(cnn_test))\n",
        "cnn_bal.append(np.mean(cnn_bal))\n",
        "\n",
        "# 1D CNN + LSTM\n",
        "lstm_train = [0.905, 0.897, 0.923, 0.918, 0.909]\n",
        "lstm_test = [0.895, 0.895, 0.927, 0.922, 0.916]\n",
        "lstm_bal = [0.28, 0.28, 0.5, 0.46, 0.42]\n",
        "lstm_train.append(np.mean(lstm_train))\n",
        "lstm_test.append(np.mean(lstm_test))\n",
        "lstm_bal.append(np.mean(lstm_bal))\n",
        "\n",
        "# Plot\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(folds))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# 1D CNN\n",
        "# plt.bar(x - bar_width, cnn_train, width=bar_width, label='1D CNN Train Acc', color='skyblue')\n",
        "# plt.bar(x, cnn_test, width=bar_width, label='1D CNN Test Acc', color='lightgreen')\n",
        "# plt.bar(x + bar_width, cnn_bal, width=bar_width, label='1D CNN Balanced Acc', color='salmon')\n",
        "\n",
        "# 1D CNN + LSTM (optional separate plot for clarity)\n",
        "plt.bar(x - bar_width, lstm_train, width=bar_width, label='CNN+LSTM Train Acc', color='skyblue')\n",
        "plt.bar(x, lstm_test, width=bar_width, label='CNN+LSTM Test Acc', color='lightgreen')\n",
        "plt.bar(x + bar_width, lstm_bal, width=bar_width, label='CNN+LSTM Balanced Acc', color='salmon')\n",
        "\n",
        "# Labels and Title\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('1D CNN+LSTM Train, Test, and Balanced Accuracy per Fold - CWRU(2HP)')\n",
        "plt.xticks(ticks=x, labels=folds)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### old code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_1 = load_model(os.path.join(foldername_cnn, \"best_model_1.keras\"))\n",
        "# model_2 = load_model(os.path.join(foldername_cnn, \"best_model_2.keras\"))\n",
        "# model_3 = load_model(os.path.join(foldername_cnn, \"best_model_3.keras\"))\n",
        "# model_4 = load_model(os.path.join(foldername_cnn, \"best_model_4.keras\"))\n",
        "# model_5 = load_model(os.path.join(foldername_cnn, \"best_model_5.keras\"))\n",
        "# # Initialize lists to store accuracies and fold labels\n",
        "# from datetime import datetime\n",
        "# accuracies = []\n",
        "# balance_accuracies = []\n",
        "# fold_labels = [f\"Fold {i+1}\" for i in range(5)]\n",
        "# models = [model_1, model_2, model_3, model_4, model_5]\n",
        "\n",
        "# # Predict and calculate accuracy for each model\n",
        "# for model in models:\n",
        "#     y_pred_probs = model.predict(X_1D_test, verbose=0)\n",
        "#     y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "#     y_true = np.argmax(y_test, axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     balance_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "#     accuracies.append(acc)\n",
        "#     balance_accuracies.append(balance_acc)\n",
        "\n",
        "# # Plot bar chart\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, accuracies, color='salmon')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Test Accuracy')\n",
        "# plt.title('Test Accuracy for 1D_CNN (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # Plot balanced accuracy\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, balance_accuracies, color='lightblue')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Balanced Test Accuracy')\n",
        "# plt.title('Balanced Test Accuracy for 1D_CNN (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # # Add accuracy values on top of bars\n",
        "# # for i, acc in enumerate(accuracies):\n",
        "# #     plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='top')\n",
        "\n",
        "# # Save the plot\n",
        "# plots_dir = os.path.join(foldername_cnn, \"Plots\", \"1D_CNN\", \"2HP\")\n",
        "# os.makedirs(plots_dir, exist_ok=True)\n",
        "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# filepath = os.path.join(plots_dir, f\"test_accuracy_bar_chart_{timestamp}.png\")\n",
        "# # plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "# # plt.close()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_6 = load_model(os.path.join(foldername_cnn_lstm, \"1D_CNN_LSTM_best_model_1.keras\"))\n",
        "# model_7 = load_model(os.path.join(foldername_cnn_lstm, \"1D_CNN_LSTM_best_model_2.keras\"))\n",
        "# model_8 = load_model(os.path.join(foldername_cnn_lstm, \"1D_CNN_LSTM_best_model_3.keras\"))\n",
        "# model_9 = load_model(os.path.join(foldername_cnn_lstm, \"1D_CNN_LSTM_best_model_4.keras\"))\n",
        "# model_10 = load_model(os.path.join(foldername_cnn_lstm, \"1D_CNN_LSTM_best_model_5.keras\"))\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from datetime import datetime\n",
        "# import os\n",
        "\n",
        "# # Initialize lists to store accuracies and fold labels\n",
        "# accuracies = []\n",
        "# balance_accuracies = []\n",
        "# fold_labels = [f\"Fold {i+1}\" for i in range(5)]\n",
        "# models = [model_6, model_7, model_8, model_9, model_10]\n",
        "\n",
        "# # Predict and calculate accuracy for each model\n",
        "# for model in models:\n",
        "#     y_pred_probs = model.predict(X_1D_test, verbose=0)\n",
        "#     y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "#     y_true = np.argmax(y_test, axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     balance_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "#     accuracies.append(acc)\n",
        "#     balance_accuracies.append(balance_acc)\n",
        "\n",
        "# # Plot bar chart\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, accuracies, color='salmon')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Test Accuracy')\n",
        "# plt.title('Test Accuracy for 1D_CNN_LSTM (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # Plot balanced accuracy\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, balance_accuracies, color='lightblue')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Balanced Test Accuracy')\n",
        "# plt.title('Balanced Test Accuracy for 1D_CNN_LSTM (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # # Add accuracy values on top of bars\n",
        "# # for i, acc in enumerate(accuracies):\n",
        "# #     plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='top')\n",
        "\n",
        "# # Save the plot\n",
        "# plots_dir = os.path.join(foldername_cnn, \"Plots\", \"1D_CNN\", \"2HP\")\n",
        "# os.makedirs(plots_dir, exist_ok=True)\n",
        "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# filepath = os.path.join(plots_dir, f\"test_accuracy_bar_chart_{timestamp}.png\")\n",
        "# # plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "# # plt.close()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_11 = load_model(os.path.join(foldername_cnn_attn, \"1D_CNN_Attention_best_model_1.keras\"))\n",
        "# model_12 = load_model(os.path.join(foldername_cnn_attn, \"1D_CNN_Attention_best_model_2.keras\"))\n",
        "# model_13 = load_model(os.path.join(foldername_cnn_attn, \"1D_CNN_Attention_best_model_3.keras\"))\n",
        "# model_14 = load_model(os.path.join(foldername_cnn_attn, \"1D_CNN_Attention_best_model_4.keras\"))\n",
        "# model_15 = load_model(os.path.join(foldername_cnn_attn, \"1D_CNN_Attention_best_model_5.keras\"))\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from datetime import datetime\n",
        "# import os\n",
        "\n",
        "# # Initialize lists to store accuracies and fold labels\n",
        "# accuracies = []\n",
        "# balance_accuracies = []\n",
        "# fold_labels = [f\"Fold {i+1}\" for i in range(5)]\n",
        "# models = [model_11, model_12, model_13, model_14, model_15]\n",
        "\n",
        "# # Predict and calculate accuracy for each model\n",
        "# for model in models:\n",
        "#     y_pred_probs = model.predict(X_1D_test, verbose=0)\n",
        "#     y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "#     y_true = np.argmax(y_test, axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     balance_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "#     accuracies.append(acc)\n",
        "#     balance_accuracies.append(balance_acc)\n",
        "\n",
        "# # Plot bar chart\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, accuracies, color='salmon')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Test Accuracy')\n",
        "# plt.title('Test Accuracy for 1D_CNN_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # Plot balanced accuracy\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, balance_accuracies, color='lightblue')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Balanced Test Accuracy')\n",
        "# plt.title('Balanced Test Accuracy for 1D_CNN_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # # Add accuracy values on top of bars\n",
        "# # for i, acc in enumerate(accuracies):\n",
        "# #     plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='top')\n",
        "\n",
        "# # Save the plot\n",
        "# plots_dir = os.path.join(foldername_cnn, \"Plots\", \"1D_CNN\", \"2HP\")\n",
        "# os.makedirs(plots_dir, exist_ok=True)\n",
        "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# filepath = os.path.join(plots_dir, f\"test_accuracy_bar_chart_{timestamp}.png\")\n",
        "# # plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "# # plt.close()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_16 = load_model(os.path.join(foldername_cnn_lstm_attn, \"1D_CNN_LSTM_Attention_best_model_1.keras\"))\n",
        "# model_17 = load_model(os.path.join(foldername_cnn_lstm_attn, \"1D_CNN_LSTM_Attention_best_model_2.keras\"))\n",
        "# model_18 = load_model(os.path.join(foldername_cnn_lstm_attn, \"1D_CNN_LSTM_Attention_best_model_3.keras\"))\n",
        "# model_19 = load_model(os.path.join(foldername_cnn_lstm_attn, \"1D_CNN_LSTM_Attention_best_model_4.keras\"))\n",
        "# model_20 = load_model(os.path.join(foldername_cnn_lstm_attn, \"1D_CNN_LSTM_Attention_best_model_5.keras\"))\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from datetime import datetime\n",
        "# import os\n",
        "\n",
        "# # Initialize lists to store accuracies and fold labels\n",
        "# accuracies = []\n",
        "# balance_accuracies = []\n",
        "# fold_labels = [f\"Fold {i+1}\" for i in range(5)]\n",
        "# models = [model_16, model_17, model_18, model_19, model_20]\n",
        "\n",
        "# # Predict and calculate accuracy for each model\n",
        "# for model in models:\n",
        "#     y_pred_probs = model.predict(X_1D_test, verbose=0)\n",
        "#     y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "#     y_true = np.argmax(y_test, axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     balance_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "#     accuracies.append(acc)\n",
        "#     balance_accuracies.append(balance_acc)\n",
        "\n",
        "# # Plot bar chart\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, accuracies, color='salmon')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Test Accuracy')\n",
        "# plt.title('Test Accuracy for 1D_CNN_LSTM_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # Plot balanced accuracy\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, balance_accuracies, color='lightblue')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Balanced Test Accuracy')\n",
        "# plt.title('Balanced Test Accuracy for 1D_CNN_LSTM_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # # Add accuracy values on top of bars\n",
        "# # for i, acc in enumerate(accuracies):\n",
        "# #     plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='top')\n",
        "\n",
        "# # Save the plot\n",
        "# plots_dir = os.path.join(foldername_cnn, \"Plots\", \"1D_CNN\", \"2HP\")\n",
        "# os.makedirs(plots_dir, exist_ok=True)\n",
        "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# filepath = os.path.join(plots_dir, f\"test_accuracy_bar_chart_{timestamp}.png\")\n",
        "# # plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "# # plt.close()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_21 = load_model(os.path.join(foldername_cnn_lstm_attn, \"modified_1D_CNN_LSTM_Attention_best_model_1.keras\"))\n",
        "# model_22 = load_model(os.path.join(foldername_cnn_lstm_attn, \"modified_1D_CNN_LSTM_Attention_best_model_2.keras\"))\n",
        "# model_23 = load_model(os.path.join(foldername_cnn_lstm_attn, \"modified_1D_CNN_LSTM_Attention_best_model_3.keras\"))\n",
        "# model_24 = load_model(os.path.join(foldername_cnn_lstm_attn, \"modified_1D_CNN_LSTM_Attention_best_model_4.keras\"))\n",
        "# model_25 = load_model(os.path.join(foldername_cnn_lstm_attn, \"modified_1D_CNN_LSTM_Attention_best_model_5.keras\"))\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from datetime import datetime\n",
        "# import os\n",
        "\n",
        "# # Initialize lists to store accuracies and fold labels\n",
        "# accuracies = []\n",
        "# balance_accuracies = []\n",
        "# fold_labels = [f\"Fold {i+1}\" for i in range(5)]\n",
        "# models = [model_16, model_17, model_18, model_19, model_20]\n",
        "\n",
        "# # Predict and calculate accuracy for each model\n",
        "# for model in models:\n",
        "#     y_pred_probs = model.predict(X_1D_test, verbose=0)\n",
        "#     y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "#     y_true = np.argmax(y_test, axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     balance_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "#     accuracies.append(acc)\n",
        "#     balance_accuracies.append(balance_acc)\n",
        "\n",
        "# # Plot bar chart\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, accuracies, color='salmon')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Test Accuracy')\n",
        "# plt.title('Test Accuracy for modified 1D_CNN_LSTM_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # Plot balanced accuracy\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.bar(fold_labels, balance_accuracies, color='lightblue')\n",
        "# plt.xlabel('Fold')\n",
        "# plt.ylabel('Balanced Test Accuracy')\n",
        "# plt.title('Balanced Test Accuracy for modified 1D_CNN_LSTM_Attention (2HP) Across Folds')\n",
        "# plt.ylim(0, 1)\n",
        "# plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# # # Add accuracy values on top of bars\n",
        "# # for i, acc in enumerate(accuracies):\n",
        "# #     plt.text(i, acc + 0.01, f'{acc:.3f}', ha='center', va='top')\n",
        "\n",
        "# # Save the plot\n",
        "# plots_dir = os.path.join(foldername_cnn, \"Plots\", \"1D_CNN\", \"2HP\")\n",
        "# os.makedirs(plots_dir, exist_ok=True)\n",
        "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# filepath = os.path.join(plots_dir, f\"test_accuracy_bar_chart_{timestamp}.png\")\n",
        "# # plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "# # plt.close()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import seaborn as sns \n",
        "# from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "# import tensorflow as tf\n",
        "# from keras import layers, models, Input\n",
        "# from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "# from keras.models import load_model\n",
        "# from keras.regularizers import l2\n",
        "\n",
        "# import scipy.io \n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.metrics import (\n",
        "#     accuracy_score,\n",
        "#     precision_score,\n",
        "#     recall_score,\n",
        "#     f1_score,\n",
        "#     log_loss,\n",
        "#     classification_report,\n",
        "#     confusion_matrix,\n",
        "#     roc_auc_score,\n",
        "#     balanced_accuracy_score\n",
        "# )\n",
        "# from keras.layers import (\n",
        "#     MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D, Conv1D, MaxPooling1D, BatchNormalization,\n",
        "#     Reshape, multiply, LSTM, Bidirectional, Concatenate, Add, Activation\n",
        "# )\n",
        "\n",
        "# # Data loading\n",
        "# folder_path1 = os.path.join(os.getcwd(), 'CWRU_data', '2HP')\n",
        "# folder_path2 = os.path.join(os.getcwd(), 'CWRU_data', '3HP')\n",
        "\n",
        "# def load_cwru_data(folder_path = folder_path1):\n",
        "#     data_dict = {\n",
        "#         'Condition': [],\n",
        "#         'Fault Size (mm)': [],\n",
        "#         'Fault Label': [],\n",
        "#         'Signal': []\n",
        "#     }\n",
        "#     file_mappings_2HP = [\n",
        "#         ('99', 'Normal', 0, 0),\n",
        "#         ('124', 'RE (Rolling element)', 0.18, 1),\n",
        "#         ('111', 'IR (Inner ring)', 0.18, 2),\n",
        "#         ('137', 'OR (Outer ring)', 0.18, 3),\n",
        "#         ('191', 'RE (Rolling element)', 0.36, 4),\n",
        "#         ('176', 'IR (Inner ring)', 0.36, 5),\n",
        "#         ('203', 'OR (Outer ring)', 0.36, 6),\n",
        "#         ('228', 'RE (Rolling element)', 0.54, 7),\n",
        "#         ('215', 'IR (Inner ring)', 0.54, 8),\n",
        "#         ('240', 'OR (Outer ring)', 0.54, 9)\n",
        "#     ]\n",
        "#     for file_id, condition, fault_size, fault_label in file_mappings_2HP:\n",
        "#         file_path = os.path.join(folder_path, f'{file_id}.mat')\n",
        "#         if file_id == '99':\n",
        "#             signal = scipy.io.loadmat(file_path)[f'X0{file_id}_DE_time'].flatten()\n",
        "#         else:\n",
        "#             signal = scipy.io.loadmat(file_path)[f'X{file_id}_DE_time'].flatten()\n",
        "#         data_dict['Condition'].append(condition)\n",
        "#         data_dict['Fault Size (mm)'].append(fault_size)\n",
        "#         data_dict['Fault Label'].append(fault_label)\n",
        "#         data_dict['Signal'].append(signal)\n",
        "#     return pd.DataFrame(data_dict)\n",
        "\n",
        "# df = load_cwru_data(folder_path=folder_path1)\n",
        "\n",
        "# def preprocess_data_for_imbalance(df, start_point_dict, num_points_dict):\n",
        "#     processed_data = {\n",
        "#         'Condition': [],\n",
        "#         'Fault Size (mm)': [],\n",
        "#         'Fault Label': [],\n",
        "#         'Signal': []\n",
        "#     }\n",
        "#     for fault_label in df['Fault Label'].unique():\n",
        "#         subset = df[df['Fault Label'] == fault_label]\n",
        "#         if subset.empty:\n",
        "#             continue\n",
        "#         signal = subset.iloc[0]['Signal']\n",
        "#         condition = subset.iloc[0]['Condition']\n",
        "#         fault_size = subset.iloc[0]['Fault Size (mm)']\n",
        "#         start_point = start_point_dict.get(fault_label, 0)\n",
        "#         num_points = num_points_dict.get(fault_label, len(signal))\n",
        "#         if start_point >= len(signal):\n",
        "#             print(f\"Start point {start_point} is out of range for signal with length {len(signal)}. Skipping Fault Label {fault_label}.\")\n",
        "#             continue\n",
        "#         end_point = min(start_point + num_points, len(signal))\n",
        "#         signal_section = signal[start_point:end_point]\n",
        "#         processed_data['Condition'].append(condition)\n",
        "#         processed_data['Fault Size (mm)'].append(fault_size)\n",
        "#         processed_data['Fault Label'].append(fault_label)\n",
        "#         processed_data['Signal'].append(signal_section)\n",
        "#     return pd.DataFrame(processed_data)\n",
        "\n",
        "# start_point_dict_train = {label: 0 for label in range(10)}\n",
        "# num_points_dict_train = {0: 480000, **{label: 9600 for label in range(1, 10)}}\n",
        "# df_imbalance_train = preprocess_data_for_imbalance(df, start_point_dict_train, num_points_dict_train)\n",
        "\n",
        "# def sampling(data, interval_length, samples_per_block, ignore_points=0):\n",
        "#     adjusted_length = len(data) - 2 * ignore_points\n",
        "#     num_blocks = (\n",
        "#         round(adjusted_length / interval_length) - round(samples_per_block / interval_length) - 1\n",
        "#     )\n",
        "#     split_data = np.zeros([num_blocks, samples_per_block])\n",
        "#     for i in range(num_blocks):\n",
        "#         start_idx = ignore_points + i * interval_length\n",
        "#         split_data[i, :] = data[start_idx:(start_idx + samples_per_block)].T\n",
        "#     return split_data\n",
        "\n",
        "# def data_preparation(data, interval_length, samples_per_block):\n",
        "#     for count, signal in enumerate(data):\n",
        "#         split_data = sampling(signal, interval_length, samples_per_block)\n",
        "#         y = np.zeros([len(split_data), 10])\n",
        "#         y[:, count] = 1\n",
        "#         y_class = np.zeros([len(split_data), 1])\n",
        "#         y_class[:, 0] = count\n",
        "#         if count == 0:\n",
        "#             X = split_data\n",
        "#             y_positional = y\n",
        "#             y_label = y_class\n",
        "#         else:\n",
        "#             X = np.append(X, split_data, axis=0)\n",
        "#             y_positional = np.append(y_positional, y, axis=0)\n",
        "#             y_label = np.append(y_label, y_class, axis=0)\n",
        "#     return X, y_positional, y_label\n",
        "\n",
        "# def prepare_datasets(df_imbalance, interval_length, samples_per_block):\n",
        "#     signals = df_imbalance['Signal'].tolist()\n",
        "#     X, y_positional, y_class = data_preparation(signals, interval_length, samples_per_block)\n",
        "#     return X, y_positional, y_class\n",
        "\n",
        "# interval_length = 320\n",
        "# samples_per_block = 1600\n",
        "# X, y_positional, y_class = prepare_datasets(df_imbalance_train, interval_length, samples_per_block)\n",
        "\n",
        "# def time_series_stratified_split(X, y, train_ratio = 0.8):\n",
        "#     num_classes = y.shape[1]\n",
        "#     X_train, y_train, X_test, y_test = [], [], [], []\n",
        "#     for cls in range(num_classes):\n",
        "#         cls_indices = np.where(np.argmax(y, axis=1) == cls)[0]\n",
        "#         n_train = int(train_ratio * len(cls_indices))\n",
        "#         train_idx, test_idx = cls_indices[:n_train], cls_indices[n_train:]\n",
        "#         X_train.append(X[train_idx])\n",
        "#         y_train.append(y[train_idx])\n",
        "#         X_test.append(X[test_idx])\n",
        "#         y_test.append(y[test_idx])\n",
        "#     return (\n",
        "#         np.concatenate(X_train),\n",
        "#         np.concatenate(y_train),\n",
        "#         np.concatenate(X_test),\n",
        "#         np.concatenate(y_test)\n",
        "#     )\n",
        "\n",
        "# foldername_cnn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN\")\n",
        "# foldername_cnn_attn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_Attention\")\n",
        "# foldername_cnn_lstm = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_LSTM\")\n",
        "# foldername_cnn_lstm_attn = os.path.join(os.getcwd(), \"Imbalanced_Final_Results\", \"IR_50_1_Ratio\", \"1D_CNN_LSTM_Attention\")\n",
        "# os.makedirs(foldername_cnn, exist_ok=True)\n",
        "# os.makedirs(foldername_cnn_attn, exist_ok=True)\n",
        "# os.makedirs(foldername_cnn_lstm, exist_ok=True)\n",
        "# os.makedirs(foldername_cnn_lstm_attn, exist_ok=True)\n",
        "\n",
        "# X_train, y_train, X_test, y_test = time_series_stratified_split(X=X, y=y_positional, train_ratio=0.8)\n",
        "# X_1D_train = X_train.reshape([-1, samples_per_block, 1])\n",
        "# X_1D_test = X_test.reshape([-1, samples_per_block, 1])\n",
        "# input_shape = (samples_per_block, 1)\n",
        "# y_train_classes = np.argmax(y_train, axis=1)\n",
        "# k_splits = 5\n",
        "# kfold = StratifiedKFold(n_splits=k_splits, shuffle=False)\n",
        "\n",
        "# # 1D CNN Model\n",
        "# class CNN_1D():\n",
        "#     def __init__(self):\n",
        "#         self.model = self.CreateModel()\n",
        "#         self.model.summary()\n",
        "#     def CreateModel(self):\n",
        "#         model = models.Sequential([\n",
        "#             layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPool1D(pool_size=2),\n",
        "#             layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPool1D(pool_size=2),\n",
        "#             layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "#             layers.BatchNormalization(),\n",
        "#             layers.MaxPool1D(pool_size=2),\n",
        "#             layers.GlobalAveragePooling1D(),\n",
        "#             layers.Dense(64, activation='relu'),\n",
        "#             layers.Dropout(0.3),\n",
        "#             layers.Dense(10, activation='softmax')\n",
        "#         ])\n",
        "#         model.compile(optimizer='adam',\n",
        "#                       loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#                       metrics=['accuracy'])\n",
        "#         model.summary()\n",
        "#         return model\n",
        "\n",
        "# # 1D CNN + Attention Model\n",
        "# class CNN_1D_Attn():\n",
        "#     def __init__(self, input_shape):\n",
        "#         self.model = self.CreateModel(input_shape)\n",
        "#         self.model.summary()\n",
        "#     def CreateModel(self, input_shape):\n",
        "#         inputs = Input(shape=input_shape)\n",
        "#         x = Conv1D(16, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "#         x = BatchNormalization()(x)\n",
        "#         x = MaxPooling1D(pool_size=2)(x)\n",
        "#         x = Conv1D(32, 3, strides=1, padding='same', activation='relu')(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "#         x = MaxPooling1D(pool_size=2)(x)\n",
        "#         x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "#         x = MaxPooling1D(pool_size=2)(x)\n",
        "#         x_norm = LayerNormalization()(x)\n",
        "#         attn_output = MultiHeadAttention(num_heads=4, key_dim=16)(x_norm, x_norm)\n",
        "#         x = layers.Add()([x, attn_output])\n",
        "#         x = LayerNormalization()(x)\n",
        "#         x = GlobalAveragePooling1D()(x)\n",
        "#         x = Dense(64, activation='relu')(x)\n",
        "#         x = Dropout(0.3)(x)\n",
        "#         output = Dense(10, activation='softmax')(x)\n",
        "#         model = models.Model(inputs, output)\n",
        "#         model.compile(\n",
        "#             optimizer='adam',\n",
        "#             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#             metrics=['accuracy']\n",
        "#         )\n",
        "#         model.summary()\n",
        "#         return model\n",
        "\n",
        "# # 1D CNN + LSTM Model\n",
        "# class CNN_LSTM_1D():\n",
        "#     def __init__(self):\n",
        "#         self.model = self.build_model()\n",
        "#         self.model.summary()\n",
        "#     def build_model(self):\n",
        "#         input_seq = Input(shape=(1600,))\n",
        "#         X = Reshape((1600, 1))(input_seq)\n",
        "#         ec1_layer1 = Conv1D(50, 20, strides=2, activation='relu')(X)\n",
        "#         ec1_layer2 = Conv1D(30, 10, strides=2, activation='relu')(ec1_layer1)\n",
        "#         ec1_outputs = MaxPooling1D(pool_size=2)(ec1_layer2)\n",
        "#         ec2_layer1 = Conv1D(50, 8, strides=2, activation='relu')(X)\n",
        "#         ec2_layer2 = Conv1D(40, 6, strides=2, activation='relu')(ec2_layer1)\n",
        "#         ec2_layer3 = MaxPooling1D(pool_size=2)(ec2_layer2)\n",
        "#         ec2_layer4 = Conv1D(30, 4, strides=1, activation='relu')(ec2_layer3)\n",
        "#         ec2_outputs = ec2_layer4\n",
        "#         encoder = multiply([ec1_outputs, ec2_outputs])\n",
        "#         x = LSTM(60, return_sequences=True)(encoder)\n",
        "#         x = LSTM(60)(x)\n",
        "#         x = Dropout(0.5)(x)\n",
        "#         output = Dense(10, activation='softmax')(x)\n",
        "#         model = models.Model(input_seq, output)\n",
        "#         model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#         model.summary()\n",
        "#         return model\n",
        "\n",
        "# # 1D CNN + LSTM + Attention Model\n",
        "# class CNN_1D_LSTM_Attention():\n",
        "#     def __init__(self):\n",
        "#         self.model = self.build_model()\n",
        "#         self.model.summary()\n",
        "#     def build_model(self):\n",
        "#         input_seq = Input(shape=(1600,))\n",
        "#         X = Reshape((1600, 1))(input_seq)\n",
        "#         branch1 = Conv1D(32, 10, strides=2, padding='same')(X)\n",
        "#         branch1 = BatchNormalization()(branch1)\n",
        "#         branch1 = Activation('relu')(branch1)\n",
        "#         branch1 = Conv1D(16, 5, strides=2, padding='same')(branch1)\n",
        "#         branch1 = BatchNormalization()(branch1)\n",
        "#         branch1 = Activation('relu')(branch1)\n",
        "#         branch1 = MaxPooling1D(pool_size=2)(branch1)\n",
        "#         shortcut1 = Conv1D(16, 1, strides=4, padding='same')(X)\n",
        "#         shortcut1 = MaxPooling1D(pool_size=2)(shortcut1)\n",
        "#         branch1 = Add()([branch1, shortcut1])\n",
        "#         branch2 = Conv1D(32, 6, strides=2, padding='same')(X)\n",
        "#         branch2 = BatchNormalization()(branch2)\n",
        "#         branch2 = Activation('relu')(branch2)\n",
        "#         branch2 = Conv1D(16, 3, strides=2, padding='same')(branch2)\n",
        "#         branch2 = BatchNormalization()(branch2)\n",
        "#         branch2 = Activation('relu')(branch2)\n",
        "#         branch2 = MaxPooling1D(pool_size=2)(branch2)\n",
        "#         combined = Concatenate(axis=-1)([branch1, branch2])\n",
        "#         combined = LayerNormalization()(combined)\n",
        "#         attn_out = MultiHeadAttention(num_heads=4, key_dim=8)(combined, combined)\n",
        "#         attn_out = LayerNormalization()(attn_out)\n",
        "#         x = Bidirectional(LSTM(32, return_sequences=True))(attn_out)\n",
        "#         x = Bidirectional(LSTM(32))(x)\n",
        "#         x = Dense(64, activation='relu')(x)\n",
        "#         x = Dropout(0.3)(x)\n",
        "#         output = Dense(10, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
        "#         model = models.Model(input_seq, output)\n",
        "#         model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "#                       loss='categorical_crossentropy',\n",
        "#                       metrics=['accuracy'])\n",
        "#         model.summary()\n",
        "#         return model\n",
        "\n",
        "# # Modified Model\n",
        "# class CNN_1D_LSTM_Attn_Modified():\n",
        "#     def __init__(self):\n",
        "#         self.model = self.build_model()\n",
        "#         self.model.summary()\n",
        "#     def build_model(self):\n",
        "#         input_seq = Input(shape=(1600,))\n",
        "#         X = Reshape((1600, 1))(input_seq)\n",
        "#         branch1 = Conv1D(64, 10, strides=2, padding='same')(X)\n",
        "#         branch1 = BatchNormalization()(branch1)\n",
        "#         branch1 = Activation('relu')(branch1)\n",
        "#         branch1 = Conv1D(64, 5, strides=2, padding='same')(branch1)\n",
        "#         branch1 = BatchNormalization()(branch1)\n",
        "#         branch1 = Activation('relu')(branch1)\n",
        "#         branch1 = MaxPooling1D(pool_size=2)(branch1)\n",
        "#         shortcut1 = Conv1D(64, 1, strides=4, padding='same')(X)\n",
        "#         shortcut1 = MaxPooling1D(pool_size=2)(shortcut1)\n",
        "#         branch1 = Add()([branch1, shortcut1])\n",
        "#         branch2 = Conv1D(64, 6, strides=2, padding='same')(X)\n",
        "#         branch2 = BatchNormalization()(branch2)\n",
        "#         branch2 = Activation('relu')(branch2)\n",
        "#         branch2 = Conv1D(32, 3, strides=2, padding='same')(branch2)\n",
        "#         branch2 = BatchNormalization()(branch2)\n",
        "#         branch2 = Activation('relu')(branch2)\n",
        "#         branch2 = MaxPooling1D(pool_size=2)(branch2)\n",
        "#         combined = Concatenate(axis=-1)([branch1, branch2])\n",
        "#         combined = LayerNormalization()(combined)\n",
        "#         attn_out = MultiHeadAttention(num_heads=4, key_dim=8)(combined, combined)\n",
        "#         attn_out = LayerNormalization()(attn_out)\n",
        "#         x = Bidirectional(LSTM(32, return_sequences=True))(attn_out)\n",
        "#         x = Bidirectional(LSTM(32))(x)\n",
        "#         x = Dense(64, activation='relu')(x)\n",
        "#         x = Dropout(0.3)(x)\n",
        "#         output = Dense(10, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
        "#         model = models.Model(input_seq, output)\n",
        "#         model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "#                       loss='categorical_crossentropy',\n",
        "#                       metrics=['accuracy'])\n",
        "#         model.summary()\n",
        "#         return model\n",
        "\n",
        "# # Example: Train and evaluate 1D CNN model (repeat for other models as needed)\n",
        "# accuracy_1D, precision_1D, recall_1D, f1_1D, log_loss_1D, balanced_accuracy_1D = [], [], [], [], [], []\n",
        "# accuracy_1D_test, precision_1D_test, recall_1D_test, f1_1D_test, log_loss_1D_test, balanced_accuracy_1D_test = [], [], [], [], [], []\n",
        "\n",
        "# for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
        "#     print(f\"\\nFold {fold + 1}\")\n",
        "#     checkpoint_filepath = os.path.join(foldername_cnn, f\"best_model_{fold + 1}.keras\")\n",
        "#     checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
        "#                                  save_best_only=True, mode='max', verbose=1)\n",
        "#     model = CNN_1D()\n",
        "#     model.model.fit(\n",
        "#         X_1D_train[train_idx], y_train[train_idx],\n",
        "#         validation_data=(X_1D_train[val_idx], y_train[val_idx]),\n",
        "#         epochs=20,\n",
        "#         verbose=1,\n",
        "#         callbacks=[checkpoint]\n",
        "#     )\n",
        "#     best_model = load_model(checkpoint_filepath)\n",
        "#     y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
        "#     y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
        "#     y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
        "#     accuracy_1D.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
        "#     precision_1D.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "#     recall_1D.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "#     f1_1D.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
        "#     log_loss_1D.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
        "#     balanced_accuracy_1D.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
        "#     plt.figure(figsize=(6, 4))\n",
        "#     sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
        "#     plt.title(f'1D CNN Train Confusion Matrix - Fold {fold + 1}')\n",
        "#     plt.xlabel('Predicted')\n",
        "#     plt.ylabel('True')\n",
        "#     plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_train_fold_{fold + 1}.png\"))\n",
        "#     plt.close()\n",
        "#     y_pred_test_probs = best_model.predict(X_1D_test)\n",
        "#     y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
        "#     y_true_test = np.argmax(y_test, axis=1)\n",
        "#     accuracy_1D_test.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
        "#     precision_1D_test.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "#     recall_1D_test.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "#     f1_1D_test.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
        "#     log_loss_1D_test.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
        "#     balanced_accuracy_1D_test.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
        "#     plt.figure(figsize=(6, 4))\n",
        "#     sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
        "#     plt.title(f'1D CNN Test Confusion Matrix - Fold {fold + 1}')\n",
        "#     plt.xlabel('Predicted')\n",
        "#     plt.ylabel('True')\n",
        "#     plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_test_fold_{fold + 1}.png\"))\n",
        "#     plt.close()\n",
        "#     print(f\"Best model saved at: {checkpoint_filepath}\")\n",
        "\n",
        "# balanced_accuracy_1D_avg = round(np.mean(balanced_accuracy_1D), 3)\n",
        "# balanced_accuracy_1D_test_avg = round(np.mean(balanced_accuracy_1D_test), 3)\n",
        "# print(f\"Average Balanced Accuracy (Train): {balanced_accuracy_1D_avg}\")\n",
        "# print(f\"Average Balanced Accuracy (Test): {balanced_accuracy_1D_test_avg}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMDoN2VKvzUUjQ0qkv+X2NY",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ClassificationModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
