{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "from keras import layers, models, initializers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import random as rn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import time\n",
    "# Set seed for reproducibility\n",
    "sd = 1\n",
    "os.environ['PYTHONHASHSEED'] = str(sd)\n",
    "np.random.seed(sd)\n",
    "rn.seed(sd)\n",
    "tf.random.set_seed(sd)\n",
    "\n",
    "\n",
    "# Root directory that contains folders like K001, KA04, etc.\n",
    "root_dir = './Paderborn_PreCase1_Data' \n",
    "\n",
    "\n",
    "## Define class labels  \n",
    "#2016 Paper Case1 with Real Damages\n",
    "data_structure = {\n",
    "    0: (\"Healthy\", [\"K001\", \"K002\", \"K003\", \"K004\", \"K005\"]),\n",
    "    1: (\"OR_Damage\", [\"KA04\", \"KA15\", \"KA16\", \"KA22\", \"KA30\"]),\n",
    "    2: (\"IR_Damage\", [\"KI04\", \"KI14\", \"KI16\", \"KI18\", \"KI21\"]),\n",
    "}\n",
    "\n",
    "# data_structure = {\n",
    "#     0: (\"Healthy\", [\"K001\"]),\n",
    "#     1: (\"OR_Damage\", [\"KA04\"]),\n",
    "#     2: (\"IR_Damage\", [\"KI04\"]),\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# Signal extractor function\n",
    "def extract_signals_df(filepath, signal=\"all\"):\n",
    "    signals = {\n",
    "        \"vibration\": 6,\n",
    "        \"current_1\": 1,\n",
    "        \"current_2\": 2,\n",
    "    }\n",
    "\n",
    "    mat = loadmat(filepath, struct_as_record=False, squeeze_me=True)\n",
    "    field = next(k for k in mat if not k.startswith(\"__\"))\n",
    "    struct = mat[field]\n",
    "\n",
    "    X_channels = struct.X\n",
    "    Y_channels = struct.Y\n",
    "\n",
    "    if signal == \"vibration\":\n",
    "        v = Y_channels[signals[\"vibration\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(v, columns=[\"vibration\"])\n",
    "\n",
    "    elif signal == \"current\":\n",
    "        c1 = X_channels[signals[\"current_1\"]].Data.flatten().reshape(-1, 1)\n",
    "        c2 = Y_channels[signals[\"current_2\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(np.concatenate([c1, c2], axis=1), columns=[\"current_1\", \"current_2\"])\n",
    "\n",
    "    elif signal == \"all\":\n",
    "        v = Y_channels[signals[\"vibration\"]].Data.flatten().reshape(-1, 1)\n",
    "        c1 = X_channels[signals[\"current_1\"]].Data.flatten().reshape(-1, 1)\n",
    "        c2 = Y_channels[signals[\"current_2\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(np.concatenate([v, c1, c2], axis=1),\n",
    "                            columns=[\"vibration\", \"current_1\", \"current_2\"])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Signal must be one of: 'vibration', 'current', or 'all'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ebdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ./Paderborn_PreCase1_Data/K001/N09_M07_F10_K001_10.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K002/N09_M07_F10_K002_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K003/N09_M07_F10_K003_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K004/N09_M07_F10_K004_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K005/N09_M07_F10_K005_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA04/N09_M07_F10_KA04_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA15/N09_M07_F10_KA15_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA16/N09_M07_F10_KA16_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA22/N09_M07_F10_KA22_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA30/N09_M07_F10_KA30_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI04/N09_M07_F10_KI04_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI14/N09_M07_F10_KI14_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI16/N09_M07_F10_KI16_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI18/N09_M07_F10_KI18_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI21/N09_M07_F10_KI21_2.mat\n",
      "\n",
      "Combined data shape: (3845043, 5)\n",
      "   vibration  current_1  current_2  label               sample\n",
      "0   0.021362   0.000000  -1.431288      0  N09_M07_F10_K001_10\n",
      "1  -0.106812   0.000016  -1.486391      0  N09_M07_F10_K001_10\n",
      "2  -0.088501   0.000031  -1.567667      0  N09_M07_F10_K001_10\n",
      "3  -1.193237   0.000047  -1.482258      0  N09_M07_F10_K001_10\n",
      "4  -0.122070   0.000063  -1.475370      0  N09_M07_F10_K001_10\n",
      "\n",
      "Signal DataFrame shape: (3845043, 2)\n",
      "     signal  label\n",
      "0  0.021362      0\n",
      "1 -0.106812      0\n",
      "2 -0.088501      0\n",
      "3 -1.193237      0\n",
      "4 -0.122070      0\n"
     ]
    }
   ],
   "source": [
    "# # # Process only the first several .mat files from each folder or define the number\n",
    "all_data = []\n",
    "\n",
    "for label, (category, folders) in data_structure.items():\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder {folder_path} not found.\")\n",
    "            continue\n",
    "\n",
    "        mat_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".mat\")])\n",
    "        \n",
    "        # # Read the first two .mat files only \n",
    "        # for filename in mat_files[:2]:\n",
    "            \n",
    "        # Read the Second .mat files only \n",
    "        for filename in mat_files[1:2]:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                df = extract_signals_df(file_path, signal=\"all\")\n",
    "                df[\"label\"] = label\n",
    "                df[\"sample\"] = filename.replace(\".mat\", \"\")\n",
    "                all_data.append(df)\n",
    "                print(f\"Loaded: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")           \n",
    "\n",
    "# Concatenate all DataFrames\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(\"\\nCombined data shape:\", final_df.shape)\n",
    "print(final_df.head())\n",
    "\n",
    "# Select only vibration and label columns, then rename 'vibration' to 'signal'\n",
    "df_signals = final_df[[\"vibration\", \"label\"]].copy()\n",
    "df_signals.rename(columns={\"vibration\": \"signal\"}, inplace=True)\n",
    "\n",
    "# Preview the result\n",
    "print(\"\\nSignal DataFrame shape:\", df_signals.shape)\n",
    "print(df_signals.head())\n",
    "# Group signals by label and convert to list of 1D numpy arrays\n",
    "grouped_signals = [\n",
    "    df_signals[df_signals['label'] == i]['signal'].values.astype(float)\n",
    "    for i in sorted(df_signals['label'].unique())\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4b913",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2faf410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11999, 1600), (11999, 3), (11999, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling configuration\n",
    "interval_length = 320\n",
    "samples_per_block = 1600\n",
    "\n",
    "# Data preparation\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    No_of_blocks = (\n",
    "        round(adjusted_length / interval_length)\n",
    "        - round(samples_per_block / interval_length)\n",
    "        - 1\n",
    "    )\n",
    "    if No_of_blocks <= 0:\n",
    "        return np.empty((0, samples_per_block))\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "    for i in range(No_of_blocks):\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx : start_idx + samples_per_block].T\n",
    "    return SplitData\n",
    "\n",
    "def DataPreparation(DataList, interval_length, samples_per_block):\n",
    "    for count, signal in enumerate(DataList):\n",
    "        SplitData = Sampling(signal, interval_length, samples_per_block)\n",
    "        if SplitData.shape[0] == 0:\n",
    "            continue\n",
    "        y = np.zeros([len(SplitData), len(DataList)])\n",
    "        y[:, count] = 1\n",
    "        y1 = np.zeros([len(SplitData), 1])\n",
    "        y1[:, 0] = count\n",
    "        if count == 0:\n",
    "            X = SplitData\n",
    "            LabelPositional = y\n",
    "            Label = y1\n",
    "        else:\n",
    "            X = np.append(X, SplitData, axis=0)\n",
    "            LabelPositional = np.append(LabelPositional, y, axis=0)\n",
    "            Label = np.append(Label, y1, axis=0)\n",
    "    return X, LabelPositional, Label\n",
    "\n",
    "# Run preparation\n",
    "X, y_positional, y_labels = DataPreparation(grouped_signals, interval_length, samples_per_block)\n",
    "\n",
    "X.shape, y_positional.shape, y_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841eb200",
   "metadata": {},
   "source": [
    "### Random Shuffling Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ca6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.7883 - loss: 0.4801 - val_accuracy: 0.5378 - val_loss: 2.3008\n",
      "Epoch 2/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9439 - loss: 0.1401 - val_accuracy: 0.5699 - val_loss: 1.8288\n",
      "Epoch 3/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9653 - loss: 0.0951 - val_accuracy: 0.9618 - val_loss: 0.0888\n",
      "Epoch 4/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.0689 - val_accuracy: 0.9844 - val_loss: 0.0394\n",
      "Epoch 5/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.0592 - val_accuracy: 0.9887 - val_loss: 0.0307\n",
      "Epoch 6/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0444 - val_accuracy: 0.9943 - val_loss: 0.0192\n",
      "Epoch 7/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9859 - loss: 0.0385 - val_accuracy: 0.9863 - val_loss: 0.0376\n",
      "Epoch 8/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9865 - loss: 0.0354 - val_accuracy: 0.9948 - val_loss: 0.0168\n",
      "Epoch 9/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9904 - loss: 0.0281 - val_accuracy: 0.9948 - val_loss: 0.0183\n",
      "Epoch 10/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0285 - val_accuracy: 0.9934 - val_loss: 0.0174\n",
      "Epoch 11/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9910 - loss: 0.0265 - val_accuracy: 0.9891 - val_loss: 0.0325\n",
      "Epoch 12/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9925 - loss: 0.0218 - val_accuracy: 0.9920 - val_loss: 0.0231\n",
      "Epoch 13/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9927 - loss: 0.0187 - val_accuracy: 0.9967 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0163 - val_accuracy: 0.9825 - val_loss: 0.0441\n",
      "Epoch 15/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0142 - val_accuracy: 0.9972 - val_loss: 0.0089\n",
      "Epoch 16/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9928 - loss: 0.0164 - val_accuracy: 0.9967 - val_loss: 0.0116\n",
      "Epoch 17/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9958 - val_loss: 0.0138\n",
      "Epoch 18/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0130 - val_accuracy: 0.9924 - val_loss: 0.0208\n",
      "Epoch 19/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0095 - val_accuracy: 0.9967 - val_loss: 0.0085\n",
      "Epoch 20/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9976 - val_loss: 0.0072\n",
      "Epoch 21/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9934 - val_loss: 0.0208\n",
      "Epoch 22/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.9967 - val_loss: 0.0100\n",
      "Epoch 23/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9891 - val_loss: 0.0290\n",
      "Epoch 24/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0123 - val_accuracy: 0.9958 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9967 - val_loss: 0.0089\n",
      "Epoch 26/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9674 - val_loss: 0.1109\n",
      "Epoch 27/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9950 - loss: 0.0094 - val_accuracy: 0.9924 - val_loss: 0.0191\n",
      "Epoch 28/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.9877 - val_loss: 0.0289\n",
      "Epoch 29/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9599 - val_loss: 0.1443\n",
      "Epoch 30/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9726 - val_loss: 0.0796\n",
      "Epoch 31/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.9981 - val_loss: 0.0097\n",
      "Epoch 32/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9986 - val_loss: 0.0052\n",
      "Epoch 33/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9972 - val_loss: 0.0130\n",
      "Epoch 34/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9311 - val_loss: 0.4273\n",
      "Epoch 35/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9891 - val_loss: 0.0326\n",
      "Epoch 36/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9948 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0030 - val_accuracy: 0.9976 - val_loss: 0.0070\n",
      "Epoch 38/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.9500 - val_loss: 0.3330\n",
      "Epoch 39/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9603 - val_loss: 0.2154\n",
      "Epoch 40/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9986 - val_loss: 0.0044\n",
      "Epoch 41/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9991 - val_loss: 0.0077\n",
      "Epoch 42/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.9967 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9967 - val_loss: 0.0160\n",
      "Epoch 44/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9976 - val_loss: 0.0068\n",
      "Epoch 45/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0063 - val_accuracy: 0.9976 - val_loss: 0.0127\n",
      "Epoch 46/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9542 - val_loss: 0.1398\n",
      "Epoch 47/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9986 - val_loss: 0.0082\n",
      "Epoch 48/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 8.5799e-04 - val_accuracy: 0.9976 - val_loss: 0.0082\n",
      "Epoch 49/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.8872 - val_loss: 0.4989\n",
      "Epoch 50/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.9943 - val_loss: 0.0226\n",
      "Epoch 51/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9939 - val_loss: 0.0188\n",
      "Epoch 52/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9976 - val_loss: 0.0135\n",
      "Epoch 53/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.8961 - val_loss: 0.5847\n",
      "Epoch 54/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9972 - val_loss: 0.0149\n",
      "Epoch 55/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9986 - val_loss: 0.0066\n",
      "Epoch 56/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.3045e-04 - val_accuracy: 0.9991 - val_loss: 0.0078\n",
      "Epoch 57/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9825 - val_loss: 0.0551\n",
      "Epoch 58/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9958 - val_loss: 0.0164\n",
      "Epoch 59/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9976 - val_loss: 0.0078\n",
      "Epoch 60/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 8.9383e-04 - val_accuracy: 0.9981 - val_loss: 0.0088\n",
      "Epoch 61/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9948 - val_loss: 0.0161\n",
      "Epoch 62/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0046 - val_accuracy: 0.9873 - val_loss: 0.0383\n",
      "Epoch 63/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9948 - val_loss: 0.0308\n",
      "Epoch 64/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9981 - val_loss: 0.0105\n",
      "Epoch 65/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 0.0010 - val_accuracy: 0.9844 - val_loss: 0.0590\n",
      "Epoch 66/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0033 - val_accuracy: 0.9986 - val_loss: 0.0095\n",
      "Epoch 67/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0470e-04 - val_accuracy: 0.9986 - val_loss: 0.0096\n",
      "Epoch 68/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 4.7714e-04 - val_accuracy: 0.9981 - val_loss: 0.0115\n",
      "Epoch 69/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9835 - val_loss: 0.0683\n",
      "Epoch 70/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9958 - val_loss: 0.0131\n",
      "Epoch 71/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9943 - val_loss: 0.0202\n",
      "Epoch 72/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9627 - val_loss: 0.1680\n",
      "Epoch 73/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.9953 - val_loss: 0.0118\n",
      "Epoch 74/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 7.6992e-04 - val_accuracy: 0.9986 - val_loss: 0.0093\n",
      "Epoch 75/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 8.9837e-04 - val_accuracy: 0.9948 - val_loss: 0.0269\n",
      "Epoch 76/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9920 - val_loss: 0.0239\n",
      "Epoch 77/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.9924 - val_loss: 0.0205\n",
      "Epoch 78/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9993 - loss: 0.0013 - val_accuracy: 0.9958 - val_loss: 0.0104\n",
      "Epoch 79/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.0199e-04 - val_accuracy: 0.9981 - val_loss: 0.0064\n",
      "Epoch 80/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "Epoch 81/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9967 - val_loss: 0.0089\n",
      "Epoch 82/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 9.1050e-04 - val_accuracy: 0.9981 - val_loss: 0.0083\n",
      "Epoch 83/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.0457e-04 - val_accuracy: 0.9986 - val_loss: 0.0057\n",
      "Epoch 84/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3950e-04 - val_accuracy: 0.9981 - val_loss: 0.0071\n",
      "Epoch 85/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8199e-04 - val_accuracy: 0.9976 - val_loss: 0.0084\n",
      "Epoch 86/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.4509e-04 - val_accuracy: 0.9967 - val_loss: 0.0075\n",
      "Epoch 87/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2556e-04 - val_accuracy: 0.9924 - val_loss: 0.0298\n",
      "Epoch 88/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2870e-04 - val_accuracy: 0.9986 - val_loss: 0.0072\n",
      "Epoch 89/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.5232e-04 - val_accuracy: 0.9991 - val_loss: 0.0083\n",
      "Epoch 90/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.3634e-05 - val_accuracy: 0.9986 - val_loss: 0.0069\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.7874 - loss: 0.4907 - val_accuracy: 0.3362 - val_loss: 3.7605\n",
      "Epoch 2/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9375 - loss: 0.1570 - val_accuracy: 0.6374 - val_loss: 1.1489\n",
      "Epoch 3/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9609 - loss: 0.1096 - val_accuracy: 0.9254 - val_loss: 0.1730\n",
      "Epoch 4/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.0804 - val_accuracy: 0.9811 - val_loss: 0.0511\n",
      "Epoch 5/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9784 - loss: 0.0632 - val_accuracy: 0.9825 - val_loss: 0.0494\n",
      "Epoch 6/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9813 - loss: 0.0525 - val_accuracy: 0.9887 - val_loss: 0.0360\n",
      "Epoch 7/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9844 - loss: 0.0443 - val_accuracy: 0.9868 - val_loss: 0.0358\n",
      "Epoch 8/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9852 - loss: 0.0386 - val_accuracy: 0.9906 - val_loss: 0.0230\n",
      "Epoch 9/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9893 - loss: 0.0306 - val_accuracy: 0.9910 - val_loss: 0.0254\n",
      "Epoch 10/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9899 - loss: 0.0312 - val_accuracy: 0.9882 - val_loss: 0.0256\n",
      "Epoch 11/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9905 - loss: 0.0270 - val_accuracy: 0.9896 - val_loss: 0.0237\n",
      "Epoch 12/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9888 - loss: 0.0290 - val_accuracy: 0.9901 - val_loss: 0.0291\n",
      "Epoch 13/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9913 - loss: 0.0222 - val_accuracy: 0.9943 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9924 - loss: 0.0196 - val_accuracy: 0.9924 - val_loss: 0.0193\n",
      "Epoch 15/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9951 - loss: 0.0171 - val_accuracy: 0.9854 - val_loss: 0.0354\n",
      "Epoch 16/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9920 - loss: 0.0181 - val_accuracy: 0.9929 - val_loss: 0.0177\n",
      "Epoch 17/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9949 - loss: 0.0136 - val_accuracy: 0.9958 - val_loss: 0.0129\n",
      "Epoch 18/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9953 - loss: 0.0148 - val_accuracy: 0.9934 - val_loss: 0.0199\n",
      "Epoch 19/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.0146 - val_accuracy: 0.9972 - val_loss: 0.0093\n",
      "Epoch 20/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0112 - val_accuracy: 0.9901 - val_loss: 0.0311\n",
      "Epoch 21/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0108 - val_accuracy: 0.9887 - val_loss: 0.0322\n",
      "Epoch 22/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9924 - val_loss: 0.0210\n",
      "Epoch 23/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9970 - loss: 0.0108 - val_accuracy: 0.9863 - val_loss: 0.0413\n",
      "Epoch 24/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9953 - val_loss: 0.0103\n",
      "Epoch 25/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9960 - loss: 0.0092 - val_accuracy: 0.9858 - val_loss: 0.0454\n",
      "Epoch 26/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0083 - val_accuracy: 0.9958 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9967 - val_loss: 0.0096\n",
      "Epoch 28/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9924 - val_loss: 0.0169\n",
      "Epoch 29/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0049 - val_accuracy: 0.9873 - val_loss: 0.0399\n",
      "Epoch 30/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9972 - val_loss: 0.0131\n",
      "Epoch 31/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9849 - val_loss: 0.0416\n",
      "Epoch 32/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.9953 - val_loss: 0.0144\n",
      "Epoch 33/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9636 - val_loss: 0.2065\n",
      "Epoch 34/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9967 - val_loss: 0.0100\n",
      "Epoch 35/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0061 - val_accuracy: 0.9655 - val_loss: 0.2003\n",
      "Epoch 36/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9915 - val_loss: 0.0330\n",
      "Epoch 37/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9976 - loss: 0.0044 - val_accuracy: 0.9943 - val_loss: 0.0227\n",
      "Epoch 38/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9641 - val_loss: 0.1697\n",
      "Epoch 39/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9982 - loss: 0.0078 - val_accuracy: 0.9967 - val_loss: 0.0123\n",
      "Epoch 40/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9929 - val_loss: 0.0240\n",
      "Epoch 41/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9877 - val_loss: 0.0380\n",
      "Epoch 42/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9955 - loss: 0.0166 - val_accuracy: 0.9967 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9882 - val_loss: 0.0586\n",
      "Epoch 44/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9948 - val_loss: 0.0208\n",
      "Epoch 45/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.0796e-04 - val_accuracy: 0.9929 - val_loss: 0.0344\n",
      "Epoch 46/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0038 - val_accuracy: 0.9962 - val_loss: 0.0135\n",
      "Epoch 47/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.9660 - val_loss: 0.1864\n",
      "Epoch 48/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9972 - val_loss: 0.0076\n",
      "Epoch 49/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9160 - val_loss: 0.5173\n",
      "Epoch 50/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9972 - val_loss: 0.0115\n",
      "Epoch 51/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.9972 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9551 - val_loss: 0.2284\n",
      "Epoch 53/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.9958 - val_loss: 0.0139\n",
      "Epoch 54/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.9953 - val_loss: 0.0200\n",
      "Epoch 55/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9943 - val_loss: 0.0182\n",
      "Epoch 56/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9976 - val_loss: 0.0094\n",
      "Epoch 57/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9967 - val_loss: 0.0099\n",
      "Epoch 58/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 4.6907e-04 - val_accuracy: 0.9967 - val_loss: 0.0087\n",
      "Epoch 59/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.3839e-04 - val_accuracy: 0.9958 - val_loss: 0.0151\n",
      "Epoch 60/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9188 - val_loss: 0.8553\n",
      "Epoch 61/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9947 - loss: 0.0186 - val_accuracy: 0.9901 - val_loss: 0.0460\n",
      "Epoch 62/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9953 - val_loss: 0.0181\n",
      "Epoch 63/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 5.6134e-04 - val_accuracy: 0.9962 - val_loss: 0.0105\n",
      "Epoch 64/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.1133e-04 - val_accuracy: 0.9943 - val_loss: 0.0141\n",
      "Epoch 65/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 5.1877e-04 - val_accuracy: 0.9976 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0017 - val_accuracy: 0.9972 - val_loss: 0.0102\n",
      "Epoch 67/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0042 - val_accuracy: 0.9929 - val_loss: 0.0372\n",
      "Epoch 68/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.3639e-04 - val_accuracy: 0.9976 - val_loss: 0.0096\n",
      "Epoch 69/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9882 - val_loss: 0.0559\n",
      "Epoch 70/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9858 - val_loss: 0.0758\n",
      "Epoch 71/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.9934 - val_loss: 0.0264\n",
      "Epoch 72/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 4.2832e-04 - val_accuracy: 0.9967 - val_loss: 0.0093\n",
      "Epoch 73/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 3.4241e-04 - val_accuracy: 0.9948 - val_loss: 0.0120\n",
      "Epoch 74/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9920 - val_loss: 0.0228\n",
      "Epoch 75/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9943 - val_loss: 0.0205\n",
      "Epoch 76/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9504 - val_loss: 0.4149\n",
      "Epoch 77/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9929 - val_loss: 0.0226\n",
      "Epoch 78/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.0798e-04 - val_accuracy: 0.9967 - val_loss: 0.0124\n",
      "Epoch 79/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 8.0831e-04 - val_accuracy: 0.9953 - val_loss: 0.0173\n",
      "Epoch 80/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.5377e-04 - val_accuracy: 0.9958 - val_loss: 0.0139\n",
      "Epoch 81/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.7108e-04 - val_accuracy: 0.9943 - val_loss: 0.0169\n",
      "Epoch 82/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 3.9949e-04 - val_accuracy: 0.9750 - val_loss: 0.0982\n",
      "Epoch 83/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0122 - val_accuracy: 0.9962 - val_loss: 0.0157\n",
      "Epoch 84/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9939 - val_loss: 0.0207\n",
      "Epoch 85/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9910 - val_loss: 0.0319\n",
      "Epoch 86/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9990 - loss: 0.0018 - val_accuracy: 0.9953 - val_loss: 0.0136\n",
      "Epoch 87/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.6378e-04 - val_accuracy: 0.9953 - val_loss: 0.0167\n",
      "Epoch 88/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.2847e-04 - val_accuracy: 0.9939 - val_loss: 0.0216\n",
      "Epoch 89/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.4950e-04 - val_accuracy: 0.9939 - val_loss: 0.0166\n",
      "Epoch 90/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.2467e-04 - val_accuracy: 0.9958 - val_loss: 0.0228\n",
      "Epoch 91/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 5.6928e-04 - val_accuracy: 0.9858 - val_loss: 0.0410\n",
      "Epoch 92/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9949 - loss: 0.0131 - val_accuracy: 0.9754 - val_loss: 0.1540\n",
      "Epoch 93/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9934 - val_loss: 0.0339\n",
      "Epoch 94/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.8681e-04 - val_accuracy: 0.9948 - val_loss: 0.0153\n",
      "Epoch 95/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 3.5091e-04 - val_accuracy: 0.9972 - val_loss: 0.0101\n",
      "Epoch 96/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8176e-04 - val_accuracy: 0.9958 - val_loss: 0.0188\n",
      "Epoch 97/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9910 - val_loss: 0.0369\n",
      "Epoch 98/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0031 - val_accuracy: 0.9896 - val_loss: 0.0486\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.8389 - loss: 0.4175 - val_accuracy: 0.3234 - val_loss: 4.8756\n",
      "Epoch 2/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9415 - loss: 0.1372 - val_accuracy: 0.4320 - val_loss: 2.1745\n",
      "Epoch 3/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9581 - loss: 0.1038 - val_accuracy: 0.9202 - val_loss: 0.1769\n",
      "Epoch 4/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9700 - loss: 0.0816 - val_accuracy: 0.9561 - val_loss: 0.0992\n",
      "Epoch 5/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9782 - loss: 0.0633 - val_accuracy: 0.9249 - val_loss: 0.1710\n",
      "Epoch 6/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9812 - loss: 0.0545 - val_accuracy: 0.9386 - val_loss: 0.1351\n",
      "Epoch 7/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9832 - loss: 0.0454 - val_accuracy: 0.9268 - val_loss: 0.1682\n",
      "Epoch 8/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9854 - loss: 0.0391 - val_accuracy: 0.9098 - val_loss: 0.2074\n",
      "Epoch 9/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9855 - loss: 0.0412 - val_accuracy: 0.9481 - val_loss: 0.1198\n",
      "Epoch 10/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9884 - loss: 0.0334 - val_accuracy: 0.9528 - val_loss: 0.1035\n",
      "Epoch 11/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9879 - loss: 0.0327 - val_accuracy: 0.9778 - val_loss: 0.0542\n",
      "Epoch 12/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9912 - loss: 0.0261 - val_accuracy: 0.9410 - val_loss: 0.1396\n",
      "Epoch 13/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9894 - loss: 0.0308 - val_accuracy: 0.9920 - val_loss: 0.0210\n",
      "Epoch 14/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9922 - loss: 0.0241 - val_accuracy: 0.9915 - val_loss: 0.0233\n",
      "Epoch 15/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9941 - loss: 0.0206 - val_accuracy: 0.9901 - val_loss: 0.0298\n",
      "Epoch 16/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9926 - loss: 0.0214 - val_accuracy: 0.9835 - val_loss: 0.0516\n",
      "Epoch 17/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.9731 - val_loss: 0.0706\n",
      "Epoch 18/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9925 - loss: 0.0217 - val_accuracy: 0.9929 - val_loss: 0.0185\n",
      "Epoch 19/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9923 - loss: 0.0212 - val_accuracy: 0.9924 - val_loss: 0.0218\n",
      "Epoch 20/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9951 - loss: 0.0123 - val_accuracy: 0.9953 - val_loss: 0.0118\n",
      "Epoch 21/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.0137 - val_accuracy: 0.9920 - val_loss: 0.0234\n",
      "Epoch 22/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 0.9934 - val_loss: 0.0202\n",
      "Epoch 23/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9901 - val_loss: 0.0236\n",
      "Epoch 24/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9934 - val_loss: 0.0193\n",
      "Epoch 25/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9942 - loss: 0.0158 - val_accuracy: 0.9953 - val_loss: 0.0146\n",
      "Epoch 26/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9961 - loss: 0.0118 - val_accuracy: 0.9844 - val_loss: 0.0456\n",
      "Epoch 27/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.9773 - val_loss: 0.0860\n",
      "Epoch 28/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9953 - loss: 0.0126 - val_accuracy: 0.9915 - val_loss: 0.0287\n",
      "Epoch 29/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9802 - val_loss: 0.0979\n",
      "Epoch 30/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.9585 - val_loss: 0.1693\n",
      "Epoch 31/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9917 - loss: 0.0202 - val_accuracy: 0.9939 - val_loss: 0.0230\n",
      "Epoch 32/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9906 - val_loss: 0.0309\n",
      "Epoch 33/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9924 - val_loss: 0.0277\n",
      "Epoch 34/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9968 - loss: 0.0074 - val_accuracy: 0.9844 - val_loss: 0.0530\n",
      "Epoch 35/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0072 - val_accuracy: 0.9915 - val_loss: 0.0376\n",
      "Epoch 36/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9968 - loss: 0.0077 - val_accuracy: 0.9953 - val_loss: 0.0128\n",
      "Epoch 37/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9934 - val_loss: 0.0261\n",
      "Epoch 38/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9924 - val_loss: 0.0362\n",
      "Epoch 39/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9934 - val_loss: 0.0259\n",
      "Epoch 40/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.9207 - val_loss: 0.4541\n",
      "Epoch 41/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.8480 - val_loss: 0.7607\n",
      "Epoch 42/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.8702 - val_loss: 0.9138\n",
      "Epoch 43/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9887 - val_loss: 0.0362\n",
      "Epoch 44/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9887 - val_loss: 0.0587\n",
      "Epoch 45/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9976 - val_loss: 0.0061\n",
      "Epoch 46/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9967 - val_loss: 0.0121\n",
      "Epoch 47/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.8286 - val_loss: 1.0339\n",
      "Epoch 48/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.9929 - val_loss: 0.0322\n",
      "Epoch 49/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9934 - val_loss: 0.0228\n",
      "Epoch 50/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9972 - val_loss: 0.0105\n",
      "Epoch 51/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9891 - val_loss: 0.0564\n",
      "Epoch 52/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9920 - val_loss: 0.0456\n",
      "Epoch 53/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9948 - val_loss: 0.0261\n",
      "Epoch 54/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6115e-04 - val_accuracy: 0.9943 - val_loss: 0.0303\n",
      "Epoch 55/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9655 - val_loss: 0.1904\n",
      "Epoch 56/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9896 - val_loss: 0.0422\n",
      "Epoch 57/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9921 - loss: 0.0212 - val_accuracy: 0.9500 - val_loss: 0.2650\n",
      "Epoch 58/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0040 - val_accuracy: 0.8952 - val_loss: 0.6838\n",
      "Epoch 59/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9948 - val_loss: 0.0355\n",
      "Epoch 60/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.9953 - val_loss: 0.0204\n",
      "Epoch 61/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9948 - val_loss: 0.0270\n",
      "Epoch 62/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 9.2171e-04 - val_accuracy: 0.9953 - val_loss: 0.0275\n",
      "Epoch 63/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9948 - val_loss: 0.0193\n",
      "Epoch 64/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9953 - val_loss: 0.0229\n",
      "Epoch 65/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 5.1111e-04 - val_accuracy: 0.9939 - val_loss: 0.0277\n",
      "Epoch 66/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 6.2549e-04 - val_accuracy: 0.9816 - val_loss: 0.0826\n",
      "Epoch 67/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.9646 - val_loss: 0.1961\n",
      "Epoch 68/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.9920 - val_loss: 0.0443\n",
      "Epoch 69/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9967 - val_loss: 0.0106\n",
      "Epoch 70/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 8.5578e-04 - val_accuracy: 0.9773 - val_loss: 0.0931\n",
      "Epoch 71/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0062 - val_accuracy: 0.9976 - val_loss: 0.0119\n",
      "Epoch 72/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 7.8472e-04 - val_accuracy: 0.9967 - val_loss: 0.0166\n",
      "Epoch 73/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 3.8244e-04 - val_accuracy: 0.9972 - val_loss: 0.0148\n",
      "Epoch 74/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.2122e-04 - val_accuracy: 0.9967 - val_loss: 0.0143\n",
      "Epoch 75/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1159e-04 - val_accuracy: 0.9976 - val_loss: 0.0080\n",
      "Epoch 76/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.1055e-04 - val_accuracy: 0.9934 - val_loss: 0.0428\n",
      "Epoch 77/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9882 - val_loss: 0.0614\n",
      "Epoch 78/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9825 - val_loss: 0.1327\n",
      "Epoch 79/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9968 - loss: 0.0089 - val_accuracy: 0.9924 - val_loss: 0.0251\n",
      "Epoch 80/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9943 - val_loss: 0.0272\n",
      "Epoch 81/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 7.7273e-04 - val_accuracy: 0.9943 - val_loss: 0.0233\n",
      "Epoch 82/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.9967 - val_loss: 0.0127\n",
      "Epoch 83/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 5.7784e-04 - val_accuracy: 0.9958 - val_loss: 0.0228\n",
      "Epoch 84/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.3176e-04 - val_accuracy: 0.9962 - val_loss: 0.0163\n",
      "Epoch 85/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6319e-04 - val_accuracy: 0.9981 - val_loss: 0.0088\n",
      "Epoch 86/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.7985e-04 - val_accuracy: 0.9962 - val_loss: 0.0154\n",
      "Epoch 87/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1292e-04 - val_accuracy: 0.9981 - val_loss: 0.0090\n",
      "Epoch 88/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.1993e-04 - val_accuracy: 0.9976 - val_loss: 0.0096\n",
      "Epoch 89/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.1573e-04 - val_accuracy: 0.9948 - val_loss: 0.0372\n",
      "Epoch 90/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.7757e-04 - val_accuracy: 0.9877 - val_loss: 0.0753\n",
      "Epoch 91/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9967 - val_loss: 0.0088\n",
      "Epoch 92/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9953 - val_loss: 0.0197\n",
      "Epoch 93/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9868 - val_loss: 0.0756\n",
      "Epoch 94/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.1396e-04 - val_accuracy: 0.9901 - val_loss: 0.0597\n",
      "Epoch 95/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9967 - val_loss: 0.0200\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7958 - loss: 0.4915 - val_accuracy: 0.4367 - val_loss: 2.7597\n",
      "Epoch 2/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9450 - loss: 0.1425 - val_accuracy: 0.5283 - val_loss: 1.8819\n",
      "Epoch 3/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9617 - loss: 0.1006 - val_accuracy: 0.9509 - val_loss: 0.1039\n",
      "Epoch 4/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9696 - loss: 0.0817 - val_accuracy: 0.9920 - val_loss: 0.0359\n",
      "Epoch 5/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9775 - loss: 0.0653 - val_accuracy: 0.9778 - val_loss: 0.0701\n",
      "Epoch 6/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9778 - loss: 0.0593 - val_accuracy: 0.9825 - val_loss: 0.0478\n",
      "Epoch 7/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9810 - loss: 0.0528 - val_accuracy: 0.9891 - val_loss: 0.0266\n",
      "Epoch 8/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9835 - loss: 0.0461 - val_accuracy: 0.9972 - val_loss: 0.0152\n",
      "Epoch 9/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9868 - loss: 0.0418 - val_accuracy: 0.9877 - val_loss: 0.0357\n",
      "Epoch 10/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9885 - loss: 0.0325 - val_accuracy: 0.9967 - val_loss: 0.0123\n",
      "Epoch 11/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9863 - loss: 0.0395 - val_accuracy: 0.9962 - val_loss: 0.0137\n",
      "Epoch 12/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9906 - loss: 0.0314 - val_accuracy: 0.9245 - val_loss: 0.1722\n",
      "Epoch 13/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9901 - loss: 0.0302 - val_accuracy: 0.9958 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9933 - loss: 0.0199 - val_accuracy: 0.9958 - val_loss: 0.0121\n",
      "Epoch 15/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9929 - loss: 0.0220 - val_accuracy: 0.9948 - val_loss: 0.0173\n",
      "Epoch 16/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9907 - loss: 0.0222 - val_accuracy: 0.9962 - val_loss: 0.0179\n",
      "Epoch 17/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9937 - loss: 0.0189 - val_accuracy: 0.9958 - val_loss: 0.0145\n",
      "Epoch 18/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9935 - loss: 0.0206 - val_accuracy: 0.9967 - val_loss: 0.0140\n",
      "Epoch 19/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9938 - loss: 0.0169 - val_accuracy: 0.9896 - val_loss: 0.0301\n",
      "Epoch 20/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9929 - loss: 0.0236 - val_accuracy: 0.9948 - val_loss: 0.0133\n",
      "Epoch 21/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9962 - loss: 0.0122 - val_accuracy: 0.9896 - val_loss: 0.0284\n",
      "Epoch 22/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9959 - loss: 0.0109 - val_accuracy: 0.9962 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.9943 - val_loss: 0.0175\n",
      "Epoch 24/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.9948 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9967 - val_loss: 0.0104\n",
      "Epoch 26/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9958 - val_loss: 0.0117\n",
      "Epoch 27/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0108 - val_accuracy: 0.9958 - val_loss: 0.0133\n",
      "Epoch 28/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9976 - loss: 0.0100 - val_accuracy: 0.9972 - val_loss: 0.0084\n",
      "Epoch 29/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9967 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.9754 - val_loss: 0.0632\n",
      "Epoch 31/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9934 - loss: 0.0191 - val_accuracy: 0.9939 - val_loss: 0.0180\n",
      "Epoch 32/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9934 - val_loss: 0.0199\n",
      "Epoch 33/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9943 - val_loss: 0.0216\n",
      "Epoch 34/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 0.9976 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9978 - loss: 0.0047 - val_accuracy: 0.9906 - val_loss: 0.0291\n",
      "Epoch 36/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9953 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0080 - val_accuracy: 0.8862 - val_loss: 0.6697\n",
      "Epoch 38/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9936 - loss: 0.0200 - val_accuracy: 0.9939 - val_loss: 0.0216\n",
      "Epoch 39/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9977 - loss: 0.0053 - val_accuracy: 0.9849 - val_loss: 0.0653\n",
      "Epoch 40/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 0.9948 - val_loss: 0.0131\n",
      "Epoch 41/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.9967 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9896 - val_loss: 0.0391\n",
      "Epoch 43/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9948 - val_loss: 0.0240\n",
      "Epoch 44/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9987 - loss: 0.0030 - val_accuracy: 0.9981 - val_loss: 0.0079\n",
      "Epoch 45/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9955 - loss: 0.0125 - val_accuracy: 0.9740 - val_loss: 0.0767\n",
      "Epoch 46/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 0.9976 - val_loss: 0.0084\n",
      "Epoch 47/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9882 - val_loss: 0.0389\n",
      "Epoch 48/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0038 - val_accuracy: 0.9849 - val_loss: 0.0618\n",
      "Epoch 49/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.9972 - val_loss: 0.0074\n",
      "Epoch 50/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9967 - val_loss: 0.0093\n",
      "Epoch 51/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9882 - val_loss: 0.0414\n",
      "Epoch 52/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9989 - loss: 0.0024 - val_accuracy: 0.9608 - val_loss: 0.2067\n",
      "Epoch 53/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9953 - loss: 0.0122 - val_accuracy: 0.9901 - val_loss: 0.0380\n",
      "Epoch 54/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9976 - val_loss: 0.0070\n",
      "Epoch 55/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9958 - val_loss: 0.0164\n",
      "Epoch 56/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9986 - val_loss: 0.0039\n",
      "Epoch 57/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.6279e-04 - val_accuracy: 0.9967 - val_loss: 0.0117\n",
      "Epoch 58/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9998 - loss: 8.5200e-04 - val_accuracy: 0.9943 - val_loss: 0.0163\n",
      "Epoch 59/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9424 - val_loss: 0.2837\n",
      "Epoch 60/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.9830 - val_loss: 0.0717\n",
      "Epoch 61/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9967 - val_loss: 0.0102\n",
      "Epoch 62/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9967 - val_loss: 0.0098\n",
      "Epoch 63/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9452 - val_loss: 0.1911\n",
      "Epoch 64/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9910 - loss: 0.0281 - val_accuracy: 0.9939 - val_loss: 0.0233\n",
      "Epoch 65/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9958 - val_loss: 0.0160\n",
      "Epoch 66/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9976 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.8405e-04 - val_accuracy: 0.9953 - val_loss: 0.0123\n",
      "Epoch 68/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8686e-04 - val_accuracy: 0.9967 - val_loss: 0.0118\n",
      "Epoch 69/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.0957e-04 - val_accuracy: 0.9948 - val_loss: 0.0208\n",
      "Epoch 70/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.9055e-04 - val_accuracy: 0.9953 - val_loss: 0.0134\n",
      "Epoch 71/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9920 - val_loss: 0.0362\n",
      "Epoch 72/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9952 - loss: 0.0159 - val_accuracy: 0.9962 - val_loss: 0.0136\n",
      "Epoch 73/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9981 - loss: 0.0086 - val_accuracy: 0.9962 - val_loss: 0.0121\n",
      "Epoch 74/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9972 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9999 - loss: 5.3952e-04 - val_accuracy: 0.9981 - val_loss: 0.0067\n",
      "Epoch 76/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 9.7358e-04 - val_accuracy: 0.9910 - val_loss: 0.0367\n",
      "Epoch 77/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9969 - loss: 0.0128 - val_accuracy: 0.9967 - val_loss: 0.0077\n",
      "Epoch 78/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9976 - val_loss: 0.0069\n",
      "Epoch 79/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.1157e-04 - val_accuracy: 0.9972 - val_loss: 0.0087\n",
      "Epoch 80/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.7086e-04 - val_accuracy: 0.9976 - val_loss: 0.0072\n",
      "Epoch 81/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.5458e-04 - val_accuracy: 0.9967 - val_loss: 0.0114\n",
      "Epoch 82/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 1.3530e-04 - val_accuracy: 0.9972 - val_loss: 0.0079\n",
      "Epoch 83/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.6954e-04 - val_accuracy: 0.9986 - val_loss: 0.0081\n",
      "Epoch 84/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9599 - val_loss: 0.1552\n",
      "Epoch 85/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9932 - loss: 0.0149 - val_accuracy: 0.9972 - val_loss: 0.0080\n",
      "Epoch 86/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9981 - val_loss: 0.0081\n",
      "Epoch 87/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9958 - val_loss: 0.0131\n",
      "Epoch 88/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9887 - val_loss: 0.0412\n",
      "Epoch 89/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9999 - loss: 9.9569e-04 - val_accuracy: 0.9976 - val_loss: 0.0068\n",
      "Epoch 90/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6242e-04 - val_accuracy: 0.9972 - val_loss: 0.0072\n",
      "Epoch 91/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 2.3062e-04 - val_accuracy: 0.9972 - val_loss: 0.0072\n",
      "Epoch 92/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9773 - val_loss: 0.1213\n",
      "Epoch 93/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9939 - val_loss: 0.0187\n",
      "Epoch 94/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 9.3232e-04 - val_accuracy: 0.9948 - val_loss: 0.0185\n",
      "Epoch 95/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9976 - val_loss: 0.0091\n",
      "Epoch 96/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9981 - val_loss: 0.0054\n",
      "Epoch 97/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 5.6089e-04 - val_accuracy: 0.9986 - val_loss: 0.0047\n",
      "Epoch 98/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.2698e-04 - val_accuracy: 0.9972 - val_loss: 0.0073\n",
      "Epoch 99/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 9.6353e-04 - val_accuracy: 0.9976 - val_loss: 0.0045\n",
      "Epoch 100/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.6649e-04 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.7767 - loss: 0.5155 - val_accuracy: 0.3359 - val_loss: 3.1630\n",
      "Epoch 2/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9473 - loss: 0.1399 - val_accuracy: 0.5154 - val_loss: 1.5758\n",
      "Epoch 3/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9624 - loss: 0.0973 - val_accuracy: 0.9391 - val_loss: 0.1215\n",
      "Epoch 4/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9718 - loss: 0.0767 - val_accuracy: 0.9580 - val_loss: 0.0976\n",
      "Epoch 5/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9773 - loss: 0.0621 - val_accuracy: 0.9849 - val_loss: 0.0488\n",
      "Epoch 6/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9807 - loss: 0.0541 - val_accuracy: 0.9877 - val_loss: 0.0335\n",
      "Epoch 7/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9847 - loss: 0.0439 - val_accuracy: 0.9901 - val_loss: 0.0307\n",
      "Epoch 8/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9877 - loss: 0.0352 - val_accuracy: 0.9882 - val_loss: 0.0279\n",
      "Epoch 9/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9866 - loss: 0.0333 - val_accuracy: 0.9783 - val_loss: 0.0510\n",
      "Epoch 10/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9902 - loss: 0.0302 - val_accuracy: 0.9868 - val_loss: 0.0322\n",
      "Epoch 11/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9912 - loss: 0.0276 - val_accuracy: 0.9863 - val_loss: 0.0375\n",
      "Epoch 12/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9895 - loss: 0.0284 - val_accuracy: 0.9915 - val_loss: 0.0193\n",
      "Epoch 13/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9917 - loss: 0.0217 - val_accuracy: 0.9608 - val_loss: 0.0975\n",
      "Epoch 14/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9916 - loss: 0.0188 - val_accuracy: 0.9164 - val_loss: 0.2724\n",
      "Epoch 15/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.9816 - val_loss: 0.0453\n",
      "Epoch 16/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0137 - val_accuracy: 0.9825 - val_loss: 0.0501\n",
      "Epoch 17/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.9532 - val_loss: 0.1324\n",
      "Epoch 18/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9974 - loss: 0.0100 - val_accuracy: 0.9188 - val_loss: 0.2485\n",
      "Epoch 19/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 0.9901 - val_loss: 0.0287\n",
      "Epoch 20/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0141 - val_accuracy: 0.9910 - val_loss: 0.0259\n",
      "Epoch 21/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.9830 - val_loss: 0.0571\n",
      "Epoch 22/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9947 - loss: 0.0148 - val_accuracy: 0.9712 - val_loss: 0.0836\n",
      "Epoch 23/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9951 - loss: 0.0140 - val_accuracy: 0.9046 - val_loss: 0.3434\n",
      "Epoch 24/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9941 - loss: 0.0180 - val_accuracy: 0.9920 - val_loss: 0.0294\n",
      "Epoch 25/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9816 - val_loss: 0.0507\n",
      "Epoch 26/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.9872 - val_loss: 0.0355\n",
      "Epoch 27/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9946 - loss: 0.0115 - val_accuracy: 0.9877 - val_loss: 0.0409\n",
      "Epoch 28/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0113 - val_accuracy: 0.9717 - val_loss: 0.0933\n",
      "Epoch 29/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.9206 - val_loss: 0.3158\n",
      "Epoch 30/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.9943 - val_loss: 0.0164\n",
      "Epoch 31/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9943 - val_loss: 0.0149\n",
      "Epoch 32/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.8914 - val_loss: 0.4714\n",
      "Epoch 33/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0047 - val_accuracy: 0.9934 - val_loss: 0.0174\n",
      "Epoch 34/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9957 - val_loss: 0.0145\n",
      "Epoch 35/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9735 - val_loss: 0.0882\n",
      "Epoch 36/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0063 - val_accuracy: 0.9924 - val_loss: 0.0241\n",
      "Epoch 37/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.9650 - val_loss: 0.1442\n",
      "Epoch 38/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9764 - val_loss: 0.0914\n",
      "Epoch 39/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9950 - loss: 0.0134 - val_accuracy: 0.9948 - val_loss: 0.0158\n",
      "Epoch 40/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9783 - val_loss: 0.1491\n",
      "Epoch 41/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0093 - val_accuracy: 0.9939 - val_loss: 0.0279\n",
      "Epoch 42/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9939 - val_loss: 0.0204\n",
      "Epoch 43/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9915 - val_loss: 0.0312\n",
      "Epoch 44/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0096 - val_accuracy: 0.8800 - val_loss: 0.5570\n",
      "Epoch 45/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.9849 - val_loss: 0.0812\n",
      "Epoch 46/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9943 - val_loss: 0.0161\n",
      "Epoch 47/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.9920 - val_loss: 0.0314\n",
      "Epoch 48/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9997 - loss: 8.3938e-04 - val_accuracy: 0.9943 - val_loss: 0.0215\n",
      "Epoch 49/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 6.4266e-04 - val_accuracy: 0.9934 - val_loss: 0.0267\n",
      "Epoch 50/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 5.2900e-04 - val_accuracy: 0.9943 - val_loss: 0.0193\n",
      "Epoch 51/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9854 - val_loss: 0.0544\n",
      "Epoch 52/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9944 - loss: 0.0134 - val_accuracy: 0.9929 - val_loss: 0.0249\n",
      "Epoch 53/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0037 - val_accuracy: 0.9915 - val_loss: 0.0313\n",
      "Epoch 54/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9924 - val_loss: 0.0356\n",
      "Epoch 55/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9924 - val_loss: 0.0276\n",
      "Epoch 56/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9948 - val_loss: 0.0202\n",
      "Epoch 57/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9854 - val_loss: 0.0756\n",
      "Epoch 58/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9717 - val_loss: 0.0855\n",
      "Epoch 59/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9970 - loss: 0.0086 - val_accuracy: 0.9839 - val_loss: 0.0586\n",
      "Epoch 60/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9906 - val_loss: 0.0352\n",
      "Epoch 61/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 8.0912e-04 - val_accuracy: 0.9948 - val_loss: 0.0299\n",
      "Epoch 62/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9920 - val_loss: 0.0370\n",
      "Epoch 63/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.6190e-04 - val_accuracy: 0.9948 - val_loss: 0.0222\n",
      "Epoch 64/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.2305e-04 - val_accuracy: 0.9929 - val_loss: 0.0363\n",
      "Epoch 65/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9291 - val_loss: 0.4063\n",
      "Epoch 66/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9919 - loss: 0.0234 - val_accuracy: 0.9934 - val_loss: 0.0198\n",
      "Epoch 67/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0017 - val_accuracy: 0.9797 - val_loss: 0.1577\n",
      "Epoch 68/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.0333e-04 - val_accuracy: 0.9939 - val_loss: 0.0176\n",
      "Epoch 69/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 7.6616e-04 - val_accuracy: 0.9924 - val_loss: 0.0284\n",
      "Epoch 70/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9939 - val_loss: 0.0254\n",
      "Epoch 71/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9943 - val_loss: 0.0246\n",
      "Epoch 72/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9948 - val_loss: 0.0244\n",
      "Epoch 73/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9910 - val_loss: 0.0295\n",
      "Epoch 74/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9769 - val_loss: 0.0947\n",
      "Epoch 75/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9863 - val_loss: 0.0659\n",
      "Epoch 76/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9934 - val_loss: 0.0237\n",
      "Epoch 77/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9901 - val_loss: 0.0403\n",
      "Epoch 78/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9957 - val_loss: 0.0196\n",
      "Epoch 79/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 4.7734e-04 - val_accuracy: 0.8526 - val_loss: 1.2903\n",
      "Epoch 80/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9816 - val_loss: 0.0945\n",
      "Epoch 81/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0123 - val_accuracy: 0.9953 - val_loss: 0.0177\n",
      "Epoch 82/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0027 - val_accuracy: 0.9920 - val_loss: 0.0284\n",
      "Epoch 83/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 5.5084e-04 - val_accuracy: 0.9953 - val_loss: 0.0172\n",
      "Epoch 84/100\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9920 - val_loss: 0.0396\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Total Computation Time: 3764.38 seconds (62.74 minutes)\n",
      "Train Accuracy: 99.92%\n",
      "Test Accuracy: 99.71%\n",
      "Train Precision: 99.92%\n",
      "Test Precision: 99.71%\n",
      "Train Recall: 99.92%\n",
      "Test Recall: 99.71%\n",
      "Train Log Loss: 0.0026\n",
      "Test Log Loss: 0.0081\n",
      "Train Balanced Accuracy: 99.92%\n",
      "Test Balanced Accuracy: 99.71%\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train_split, X_test_split, y_train_positional_split, y_test_positional_split = train_test_split(\n",
    "    X, y_positional, test_size=0.2, random_state=sd, stratify=y_labels)\n",
    "\n",
    "X_1D_train = X_train_split.reshape([-1, samples_per_block, 1])\n",
    "X_1D_test = X_test_split.reshape([-1, samples_per_block, 1])\n",
    "input_shape = (samples_per_block, 1)   # Reshaped input\n",
    "\n",
    "class CNN_1D():\n",
    "    def __init__(self):\n",
    "        self.model = self.CreateModel()\n",
    "        self.model.summary()\n",
    "\n",
    "    def CreateModel(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            \n",
    "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Optimizer with a slightly higher learning rate\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "# Training with k-fold validation\n",
    "kSplits = 5\n",
    "kfold = KFold(n_splits=kSplits, random_state=32, shuffle=True)\n",
    "accuracy_1D = []\n",
    "precision_1D = []\n",
    "recall_1D = []\n",
    "log_loss_1D = []\n",
    "balanced_accuracy_1D = []  # Store balanced accuracy for each fold\n",
    "accuracy_1D_test = []\n",
    "precision_1D_test = []\n",
    "recall_1D_test = []\n",
    "log_loss_1D_test = []\n",
    "balanced_accuracy_1D_test = []  # Store balanced accuracy for test set\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X, y_positional):\n",
    "    Classification_1D = CNN_1D()\n",
    "    Classification_1D.model.fit(X[train_idx], y_positional[train_idx],\n",
    "                                validation_data=(X[test_idx], y_positional[test_idx]),\n",
    "                                epochs=100, callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    # Train set metrics\n",
    "    y_pred_proba_train = Classification_1D.model.predict(X[train_idx])\n",
    "    y_pred_train = np.argmax(y_pred_proba_train, axis=1)\n",
    "    y_true_train = np.argmax(y_positional[train_idx], axis=1)\n",
    "\n",
    "    accuracy_1D.append(accuracy_score(y_true_train, y_pred_train))\n",
    "    precision_1D.append(precision_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    recall_1D.append(recall_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    log_loss_1D.append(log_loss(y_true_train, y_pred_proba_train))\n",
    "    balanced_accuracy_1D.append(balanced_accuracy_score(y_true_train, y_pred_train))  # Balanced accuracy for train set\n",
    "    \n",
    "    # Test set metrics\n",
    "    y_pred_proba_test = Classification_1D.model.predict(X[test_idx])\n",
    "    y_pred_test = np.argmax(y_pred_proba_test, axis=1)\n",
    "    y_true_test = np.argmax(y_positional[test_idx], axis=1)\n",
    "\n",
    "    accuracy_1D_test.append(accuracy_score(y_true_test, y_pred_test))\n",
    "    precision_1D_test.append(precision_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    recall_1D_test.append(recall_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    log_loss_1D_test.append(log_loss(y_true_test, y_pred_proba_test))\n",
    "    balanced_accuracy_1D_test.append(balanced_accuracy_score(y_true_test, y_pred_test))  # Balanced accuracy for test set\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total Computation Time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "\n",
    "# Aggregated metrics\n",
    "CNN_1D_train_accuracy = np.mean(accuracy_1D) * 100\n",
    "CNN_1D_test_accuracy = np.mean(accuracy_1D_test) * 100\n",
    "CNN_1D_train_precision = np.mean(precision_1D) * 100\n",
    "CNN_1D_test_precision = np.mean(precision_1D_test) * 100\n",
    "CNN_1D_train_recall = np.mean(recall_1D) * 100\n",
    "CNN_1D_test_recall = np.mean(recall_1D_test) * 100\n",
    "CNN_1D_train_log_loss = np.mean(log_loss_1D)\n",
    "CNN_1D_test_log_loss = np.mean(log_loss_1D_test)\n",
    "CNN_1D_train_balanced_accuracy = np.mean(balanced_accuracy_1D) * 100  # Average balanced accuracy for train set\n",
    "CNN_1D_test_balanced_accuracy = np.mean(balanced_accuracy_1D_test) * 100  # Average balanced accuracy for test set\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Train Accuracy: {CNN_1D_train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {CNN_1D_test_accuracy:.2f}%\")\n",
    "print(f\"Train Precision: {CNN_1D_train_precision:.2f}%\")\n",
    "print(f\"Test Precision: {CNN_1D_test_precision:.2f}%\")\n",
    "print(f\"Train Recall: {CNN_1D_train_recall:.2f}%\")\n",
    "print(f\"Test Recall: {CNN_1D_test_recall:.2f}%\")\n",
    "print(f\"Train Log Loss: {CNN_1D_train_log_loss:.4f}\")\n",
    "print(f\"Test Log Loss: {CNN_1D_test_log_loss:.4f}\")\n",
    "print(f\"Train Balanced Accuracy: {CNN_1D_train_balanced_accuracy:.2f}%\")\n",
    "print(f\"Test Balanced Accuracy: {CNN_1D_test_balanced_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion Matrix Calculation\n",
    "# def ConfusionMatrix(Model, X, y):\n",
    "#     y_pred = np.argmax(Model.model.predict(X), axis=1)\n",
    "#     ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "#     return ConfusionMat\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "    y_pred_proba = Model.model.predict(X)  # Use Model.model instead of Model\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class labels\n",
    "    y_true = np.argmax(y, axis=1)  # Convert one-hot labels to class indices\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot results - CNN 1D\n",
    "plt.figure(1)\n",
    "plt.title('Confusion Matrix - CNN 1D Train')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_train, y_train_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Confusion Matrix - CNN 1D Test')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_test, y_test_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Train - Accuracy - CNN 1D')\n",
    "plt.bar(np.arange(1, kSplits + 1), [i * 100 for i in accuracy_1D])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70, 100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title('Train vs Test Accuracy - CNN 1D')\n",
    "plt.bar([1, 2], [CNN_1D_train_accuracy, CNN_1D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('sets')\n",
    "plt.xticks([1, 2], ['Train', 'Test'])\n",
    "plt.ylim([70, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa32dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train Accuracy: 99.92%\\nTest Accuracy: 99.71%\\nTrain Precision: 99.92%\\nTest Precision: 99.71%\\nTrain Recall: 99.92%\\nTest Recall: 99.71%\\nTrain Log Loss: 0.0026\\nTest Log Loss: 0.0081\\nTrain Balanced Accuracy: 99.92%\\nTest Balanced Accuracy: 99.71%'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Train Accuracy: 99.92%\n",
    "Test Accuracy: 99.71%\n",
    "Train Precision: 99.92%\n",
    "Test Precision: 99.71%\n",
    "Train Recall: 99.92%\n",
    "Test Recall: 99.71%\n",
    "Train Log Loss: 0.0026\n",
    "Test Log Loss: 0.0081\n",
    "Train Balanced Accuracy: 99.92%\n",
    "Test Balanced Accuracy: 99.71%'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cabb1e7",
   "metadata": {},
   "source": [
    "### Time Series-Based Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d72c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_stratified_split(X, y, train_ratio = 0.8):\n",
    "    num_classes = y.shape[1]\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        cls_indices = np.where(np.argmax(y, axis=1) == cls)[0]\n",
    "        n_train = int(train_ratio * len(cls_indices))\n",
    "        train_idx, test_idx = cls_indices[:n_train], cls_indices[n_train:]\n",
    "        X_train.append(X[train_idx])\n",
    "        # print(\"X_train shape:\", len(X_train))\n",
    "        y_train.append(y[train_idx])\n",
    "        # print(\"y_train shape:\", len(X_train))\n",
    "        X_test.append(X[test_idx])\n",
    "        # print(\"X_train shape:\", len(X_train))\n",
    "        y_test.append(y[test_idx])\n",
    "        # print(\"y_test shape:\", len(X_train))\n",
    "\n",
    "    return (\n",
    "        np.concatenate(X_train),\n",
    "        np.concatenate(y_train),\n",
    "        np.concatenate(X_test),\n",
    "        np.concatenate(y_test)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256d3047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9599, 1600, 1), (2400, 1600, 1), (9599,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = time_series_stratified_split(X, y_positional) # type: ignore\n",
    "\n",
    "X_1D_train = X_train.reshape(-1, samples_per_block, 1) # type: ignore\n",
    "X_1D_test = X_test.reshape(-1, samples_per_block, 1) # type: ignore\n",
    "\n",
    "input_shape = (samples_per_block, 1)\n",
    "y_train_classes = np.argmax(y_train, axis=1)\n",
    "\n",
    "X_1D_train.shape, X_1D_test.shape, y_train_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8f01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "k_split = 5\n",
    "kfold = StratifiedKFold(n_splits=k_split, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754339b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8466 - loss: 0.3907\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8468 - loss: 0.3901 - val_accuracy: 0.3328 - val_loss: 1.4108\n",
      "Epoch 2/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9487 - loss: 0.1198\n",
      "Epoch 2: val_accuracy improved from 0.33281 to 0.40885, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9487 - loss: 0.1197 - val_accuracy: 0.4089 - val_loss: 1.3291\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9637 - loss: 0.0878\n",
      "Epoch 3: val_accuracy improved from 0.40885 to 0.76823, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9637 - loss: 0.0878 - val_accuracy: 0.7682 - val_loss: 0.4520\n",
      "Epoch 4/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9763 - loss: 0.0653\n",
      "Epoch 4: val_accuracy improved from 0.76823 to 0.93906, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9763 - loss: 0.0653 - val_accuracy: 0.9391 - val_loss: 0.1253\n",
      "Epoch 5/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9812 - loss: 0.0504\n",
      "Epoch 5: val_accuracy did not improve from 0.93906\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9812 - loss: 0.0504 - val_accuracy: 0.9094 - val_loss: 0.1717\n",
      "Epoch 6/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9836 - loss: 0.0444\n",
      "Epoch 6: val_accuracy improved from 0.93906 to 0.97448, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9836 - loss: 0.0444 - val_accuracy: 0.9745 - val_loss: 0.0788\n",
      "Epoch 7/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9873 - loss: 0.0393\n",
      "Epoch 7: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9873 - loss: 0.0393 - val_accuracy: 0.9682 - val_loss: 0.0712\n",
      "Epoch 8/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9882 - loss: 0.0323\n",
      "Epoch 8: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9882 - loss: 0.0323 - val_accuracy: 0.9641 - val_loss: 0.0809\n",
      "Epoch 9/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9908 - loss: 0.0247\n",
      "Epoch 9: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9908 - loss: 0.0248 - val_accuracy: 0.9224 - val_loss: 0.1535\n",
      "Epoch 10/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9927 - loss: 0.0239\n",
      "Epoch 10: val_accuracy improved from 0.97448 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 11/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9933 - loss: 0.0210\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9995 - val_loss: 0.0056\n",
      "Epoch 12/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9955 - loss: 0.0159\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.9901 - val_loss: 0.0297\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0160\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9927 - val_loss: 0.0189\n",
      "Epoch 14/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9939 - loss: 0.0155\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9939 - loss: 0.0155 - val_accuracy: 0.9995 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9973 - loss: 0.0130\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9973 - loss: 0.0130 - val_accuracy: 0.9979 - val_loss: 0.0078\n",
      "Epoch 16/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9967 - loss: 0.0111\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9969 - val_loss: 0.0101\n",
      "Epoch 17/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9965 - loss: 0.0112\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9995 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9939 - loss: 0.0170\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9938 - loss: 0.0171 - val_accuracy: 0.9609 - val_loss: 0.1297\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9970 - loss: 0.0096\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9875 - val_loss: 0.0356\n",
      "Epoch 20/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9960 - loss: 0.0098\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9960 - loss: 0.0098 - val_accuracy: 0.9979 - val_loss: 0.0061\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8589 - loss: 0.3622\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8594 - loss: 0.3611 - val_accuracy: 0.3328 - val_loss: 3.8675\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9531 - loss: 0.1134\n",
      "Epoch 2: val_accuracy did not improve from 0.33281\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9531 - loss: 0.1134 - val_accuracy: 0.3328 - val_loss: 3.8282\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9678 - loss: 0.0819\n",
      "Epoch 3: val_accuracy improved from 0.33281 to 0.85365, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9678 - loss: 0.0819 - val_accuracy: 0.8536 - val_loss: 0.2874\n",
      "Epoch 4/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9737 - loss: 0.0673\n",
      "Epoch 4: val_accuracy improved from 0.85365 to 0.93698, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9737 - loss: 0.0673 - val_accuracy: 0.9370 - val_loss: 0.1578\n",
      "Epoch 5/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9811 - loss: 0.0528\n",
      "Epoch 5: val_accuracy improved from 0.93698 to 0.94635, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9811 - loss: 0.0528 - val_accuracy: 0.9464 - val_loss: 0.1367\n",
      "Epoch 6/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9825 - loss: 0.0450\n",
      "Epoch 6: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9825 - loss: 0.0450 - val_accuracy: 0.9281 - val_loss: 0.1670\n",
      "Epoch 7/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9879 - loss: 0.0358\n",
      "Epoch 7: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9879 - loss: 0.0358 - val_accuracy: 0.9010 - val_loss: 0.2613\n",
      "Epoch 8/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9886 - loss: 0.0314\n",
      "Epoch 8: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9886 - loss: 0.0314 - val_accuracy: 0.9385 - val_loss: 0.1625\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9909 - loss: 0.0288\n",
      "Epoch 9: val_accuracy improved from 0.94635 to 0.96146, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.0287 - val_accuracy: 0.9615 - val_loss: 0.1071\n",
      "Epoch 10/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9910 - loss: 0.0227\n",
      "Epoch 10: val_accuracy did not improve from 0.96146\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9910 - loss: 0.0227 - val_accuracy: 0.9557 - val_loss: 0.1172\n",
      "Epoch 11/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9942 - loss: 0.0186\n",
      "Epoch 11: val_accuracy did not improve from 0.96146\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.9568 - val_loss: 0.1228\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9936 - loss: 0.0180\n",
      "Epoch 12: val_accuracy improved from 0.96146 to 0.97344, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9936 - loss: 0.0181 - val_accuracy: 0.9734 - val_loss: 0.0667\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9959 - loss: 0.0139\n",
      "Epoch 13: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9959 - loss: 0.0139 - val_accuracy: 0.9510 - val_loss: 0.1398\n",
      "Epoch 14/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9941 - loss: 0.0158\n",
      "Epoch 14: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9417 - val_loss: 0.1941\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9940 - loss: 0.0169\n",
      "Epoch 15: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9940 - loss: 0.0168 - val_accuracy: 0.9094 - val_loss: 0.3019\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9968 - loss: 0.0094\n",
      "Epoch 16: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.9563 - val_loss: 0.1445\n",
      "Epoch 17/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9976 - loss: 0.0088\n",
      "Epoch 17: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9976 - loss: 0.0088 - val_accuracy: 0.9604 - val_loss: 0.1079\n",
      "Epoch 18/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9988 - loss: 0.0053\n",
      "Epoch 18: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 0.9370 - val_loss: 0.1818\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9971 - loss: 0.0090\n",
      "Epoch 19: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9432 - val_loss: 0.1977\n",
      "Epoch 20/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9975 - loss: 0.0087\n",
      "Epoch 20: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.8307 - val_loss: 0.9383\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7835 - loss: 0.4678\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.7847 - loss: 0.4655 - val_accuracy: 0.3328 - val_loss: 2.4130\n",
      "Epoch 2/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9522 - loss: 0.1200\n",
      "Epoch 2: val_accuracy improved from 0.33281 to 0.49896, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9522 - loss: 0.1200 - val_accuracy: 0.4990 - val_loss: 2.0530\n",
      "Epoch 3/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9668 - loss: 0.0888\n",
      "Epoch 3: val_accuracy improved from 0.49896 to 0.80885, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9667 - loss: 0.0888 - val_accuracy: 0.8089 - val_loss: 0.5009\n",
      "Epoch 4/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9684 - loss: 0.0769\n",
      "Epoch 4: val_accuracy improved from 0.80885 to 0.87292, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9684 - loss: 0.0768 - val_accuracy: 0.8729 - val_loss: 0.2694\n",
      "Epoch 5/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9797 - loss: 0.0598\n",
      "Epoch 5: val_accuracy improved from 0.87292 to 0.91406, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9797 - loss: 0.0598 - val_accuracy: 0.9141 - val_loss: 0.1732\n",
      "Epoch 6/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9829 - loss: 0.0501\n",
      "Epoch 6: val_accuracy improved from 0.91406 to 0.92708, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9829 - loss: 0.0501 - val_accuracy: 0.9271 - val_loss: 0.1436\n",
      "Epoch 7/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.0490\n",
      "Epoch 7: val_accuracy improved from 0.92708 to 0.94635, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9820 - loss: 0.0490 - val_accuracy: 0.9464 - val_loss: 0.1152\n",
      "Epoch 8/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9878 - loss: 0.0349\n",
      "Epoch 8: val_accuracy improved from 0.94635 to 0.94687, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9878 - loss: 0.0349 - val_accuracy: 0.9469 - val_loss: 0.1200\n",
      "Epoch 9/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9895 - loss: 0.0313\n",
      "Epoch 9: val_accuracy did not improve from 0.94687\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9895 - loss: 0.0313 - val_accuracy: 0.9370 - val_loss: 0.1416\n",
      "Epoch 10/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9920 - loss: 0.0258\n",
      "Epoch 10: val_accuracy improved from 0.94687 to 0.95521, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9920 - loss: 0.0258 - val_accuracy: 0.9552 - val_loss: 0.1027\n",
      "Epoch 11/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9919 - loss: 0.0240\n",
      "Epoch 11: val_accuracy improved from 0.95521 to 0.97083, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 0.9708 - val_loss: 0.0700\n",
      "Epoch 12/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9936 - loss: 0.0187\n",
      "Epoch 12: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9936 - loss: 0.0187 - val_accuracy: 0.9474 - val_loss: 0.1334\n",
      "Epoch 13/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0188\n",
      "Epoch 13: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0188 - val_accuracy: 0.9594 - val_loss: 0.1058\n",
      "Epoch 14/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9961 - loss: 0.0140\n",
      "Epoch 14: val_accuracy improved from 0.97083 to 0.98750, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9961 - loss: 0.0140 - val_accuracy: 0.9875 - val_loss: 0.0324\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9971 - loss: 0.0109\n",
      "Epoch 15: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.9677 - val_loss: 0.0744\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0073\n",
      "Epoch 16: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.9823 - val_loss: 0.0432\n",
      "Epoch 17/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9963 - loss: 0.0113\n",
      "Epoch 17: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 0.9859 - val_loss: 0.0413\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9970 - loss: 0.0110\n",
      "Epoch 18: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0110 - val_accuracy: 0.9495 - val_loss: 0.1499\n",
      "Epoch 19/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 19: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9719 - val_loss: 0.0737\n",
      "Epoch 20/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9977 - loss: 0.0082\n",
      "Epoch 20: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9828 - val_loss: 0.0445\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7943 - loss: 0.4857\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7954 - loss: 0.4834 - val_accuracy: 0.3333 - val_loss: 4.0608\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9418 - loss: 0.1493\n",
      "Epoch 2: val_accuracy improved from 0.33333 to 0.36510, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9418 - loss: 0.1493 - val_accuracy: 0.3651 - val_loss: 2.8508\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9599 - loss: 0.1055\n",
      "Epoch 3: val_accuracy improved from 0.36510 to 0.99583, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9599 - loss: 0.1055 - val_accuracy: 0.9958 - val_loss: 0.0279\n",
      "Epoch 4/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9691 - loss: 0.0788\n",
      "Epoch 4: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9691 - loss: 0.0788 - val_accuracy: 0.9646 - val_loss: 0.0694\n",
      "Epoch 5/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9742 - loss: 0.0633\n",
      "Epoch 5: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9742 - loss: 0.0634 - val_accuracy: 0.9760 - val_loss: 0.0493\n",
      "Epoch 6/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9785 - loss: 0.0578\n",
      "Epoch 6: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9785 - loss: 0.0578 - val_accuracy: 0.9792 - val_loss: 0.0550\n",
      "Epoch 7/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9825 - loss: 0.0496\n",
      "Epoch 7: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0496 - val_accuracy: 0.9875 - val_loss: 0.0335\n",
      "Epoch 8/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9869 - loss: 0.0415\n",
      "Epoch 8: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9869 - loss: 0.0415 - val_accuracy: 0.9911 - val_loss: 0.0244\n",
      "Epoch 9/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9863 - loss: 0.0371\n",
      "Epoch 9: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9863 - loss: 0.0371 - val_accuracy: 0.9839 - val_loss: 0.0345\n",
      "Epoch 10/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9897 - loss: 0.0326\n",
      "Epoch 10: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.9911 - val_loss: 0.0250\n",
      "Epoch 11/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9908 - loss: 0.0261\n",
      "Epoch 11: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9908 - loss: 0.0261 - val_accuracy: 0.9948 - val_loss: 0.0195\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0271\n",
      "Epoch 12: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9900 - loss: 0.0271 - val_accuracy: 0.9911 - val_loss: 0.0284\n",
      "Epoch 13/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9937 - loss: 0.0212\n",
      "Epoch 13: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.9885 - val_loss: 0.0341\n",
      "Epoch 14/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9942 - loss: 0.0176\n",
      "Epoch 14: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9942 - loss: 0.0177 - val_accuracy: 0.9807 - val_loss: 0.0442\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9949 - loss: 0.0164\n",
      "Epoch 15: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9949 - loss: 0.0164 - val_accuracy: 0.9859 - val_loss: 0.0349\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9951 - loss: 0.0175\n",
      "Epoch 16: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.9880 - val_loss: 0.0370\n",
      "Epoch 17/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9963 - loss: 0.0132\n",
      "Epoch 17: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.9583 - val_loss: 0.1343\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9940 - loss: 0.0181\n",
      "Epoch 18: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9940 - loss: 0.0181 - val_accuracy: 0.9885 - val_loss: 0.0356\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9955 - loss: 0.0119\n",
      "Epoch 19: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 0.9755 - val_loss: 0.0817\n",
      "Epoch 20/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9977 - loss: 0.0105\n",
      "Epoch 20: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0105 - val_accuracy: 0.9948 - val_loss: 0.0210\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7891 - loss: 0.4896\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33299, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7902 - loss: 0.4872 - val_accuracy: 0.3330 - val_loss: 4.8807\n",
      "Epoch 2/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9404 - loss: 0.1468\n",
      "Epoch 2: val_accuracy did not improve from 0.33299\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9404 - loss: 0.1467 - val_accuracy: 0.3330 - val_loss: 4.7716\n",
      "Epoch 3/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9681 - loss: 0.0953\n",
      "Epoch 3: val_accuracy improved from 0.33299 to 0.90620, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9681 - loss: 0.0952 - val_accuracy: 0.9062 - val_loss: 0.2015\n",
      "Epoch 4/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0733\n",
      "Epoch 4: val_accuracy improved from 0.90620 to 0.98593, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9753 - loss: 0.0733 - val_accuracy: 0.9859 - val_loss: 0.0446\n",
      "Epoch 5/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9785 - loss: 0.0574\n",
      "Epoch 5: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9785 - loss: 0.0574 - val_accuracy: 0.9859 - val_loss: 0.0408\n",
      "Epoch 6/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9826 - loss: 0.0483\n",
      "Epoch 6: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9826 - loss: 0.0483 - val_accuracy: 0.9766 - val_loss: 0.0647\n",
      "Epoch 7/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9863 - loss: 0.0430\n",
      "Epoch 7: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9863 - loss: 0.0430 - val_accuracy: 0.9614 - val_loss: 0.1083\n",
      "Epoch 8/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9888 - loss: 0.0346\n",
      "Epoch 8: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9888 - loss: 0.0346 - val_accuracy: 0.9781 - val_loss: 0.0617\n",
      "Epoch 9/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0322\n",
      "Epoch 9: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9918 - loss: 0.0322 - val_accuracy: 0.9562 - val_loss: 0.1283\n",
      "Epoch 10/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9934 - loss: 0.0238\n",
      "Epoch 10: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9934 - loss: 0.0238 - val_accuracy: 0.9630 - val_loss: 0.1154\n",
      "Epoch 11/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9929 - loss: 0.0243\n",
      "Epoch 11: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9929 - loss: 0.0242 - val_accuracy: 0.9854 - val_loss: 0.0386\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9941 - loss: 0.0199\n",
      "Epoch 12: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0199 - val_accuracy: 0.9609 - val_loss: 0.1131\n",
      "Epoch 13/20\n",
      "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9950 - loss: 0.0162\n",
      "Epoch 13: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9687 - val_loss: 0.1110\n",
      "Epoch 14/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9929 - loss: 0.0203\n",
      "Epoch 14: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9929 - loss: 0.0203 - val_accuracy: 0.9818 - val_loss: 0.0473\n",
      "Epoch 15/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9944 - loss: 0.0119\n",
      "Epoch 15: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0119 - val_accuracy: 0.9760 - val_loss: 0.0796\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9957 - loss: 0.0119\n",
      "Epoch 16: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.9396 - val_loss: 0.1871\n",
      "Epoch 17/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9965 - loss: 0.0101\n",
      "Epoch 17: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9965 - loss: 0.0101 - val_accuracy: 0.9682 - val_loss: 0.0785\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9973 - loss: 0.0102\n",
      "Epoch 18: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9973 - loss: 0.0102 - val_accuracy: 0.9802 - val_loss: 0.0515\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9982 - loss: 0.0059\n",
      "Epoch 19: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0059 - val_accuracy: 0.9729 - val_loss: 0.1153\n",
      "Epoch 20/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 20: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9698 - val_loss: 0.1087\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training with k-fold validation\n",
    "class CNN_1D():\n",
    "    def __init__(self):\n",
    "        self.model = self.CreateModel()\n",
    "        self.model.summary()\n",
    "\n",
    "    def CreateModel(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            \n",
    "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Optimizer with a slightly higher learning rate\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "foldername_cnn = os.path.join(os.getcwd(), \"Paderborn_baseline\", \"1D_CNN\")\n",
    "os.makedirs(foldername_cnn, exist_ok=True)\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, balanced_accuracy_score\n",
    "\n",
    "# Metric storage\n",
    "accuracy_1D_cnn, precision_1D_cnn, recall_1D_cnn, f1_1D_cnn, log_loss_1D_cnn, balanced_accuracy_1D_cnn = [], [], [], [], [], []\n",
    "accuracy_1D_test_cnn, precision_1D_test_cnn, recall_1D_test_cnn, f1_1D_test_cnn, log_loss_1D_test_cnn, balanced_accuracy_1D_test_cnn = [], [], [], [], [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    checkpoint_filepath = os.path.join(foldername_cnn, f\"best_model_{fold + 1}.keras\")\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
    "                                 save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "    model = CNN_1D()\n",
    "    model.model.fit(\n",
    "        X_1D_train[train_idx], y_train[train_idx],\n",
    "        validation_data=(X_1D_train[val_idx], y_train[val_idx]),\n",
    "        epochs=20,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "\n",
    "    best_model = load_model(checkpoint_filepath)\n",
    "\n",
    "    # Train fold subset evaluation\n",
    "    y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
    "    y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
    "    y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
    "\n",
    "    accuracy_1D_cnn.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
    "    precision_1D_cnn.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "    recall_1D_cnn.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "    f1_1D_cnn.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "    log_loss_1D_cnn.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
    "    balanced_accuracy_1D_cnn.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
    "\n",
    "\n",
    "    # Save confusion matrix for train\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'1D CNN Train Confusion Matrix - Fold {fold + 1}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_train_fold_{fold + 1}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Fixed test set evaluation\n",
    "    y_pred_test_probs = best_model.predict(X_1D_test)\n",
    "    y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
    "    y_true_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuracy_1D_test_cnn.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
    "    precision_1D_test_cnn.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "    recall_1D_test_cnn.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "    f1_1D_test_cnn.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "    log_loss_1D_test_cnn.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
    "    balanced_accuracy_1D_test_cnn.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
    "\n",
    "    # Save confusion matrix for test\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title(f'1D CNN Test Confusion Matrix - Fold {fold + 1}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_test_fold_{fold + 1}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    print(f\"Best model saved at: {checkpoint_filepath}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5f1040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D CNN Metrics:\n",
      "Train Accuracy: [0.883, 0.999, 1.0, 0.958, 0.99]\n",
      "Test Accuracy: [0.667, 0.668, 0.668, 0.666, 0.666]\n",
      "Precision: [0.446, 0.785, 0.809, 0.82, 0.531]\n",
      "Recall: [0.667, 0.668, 0.668, 0.666, 0.666]\n",
      "F1 Score: [0.534, 0.538, 0.549, 0.551, 0.535]\n",
      "Log Loss: [2.952, 4.181, 4.643, 2.942, 2.943]\n",
      "Balanced Accuracy: [0.667, 0.668, 0.668, 0.666, 0.666]\n"
     ]
    }
   ],
   "source": [
    "print(\"1D CNN Metrics:\")\n",
    "print(f\"Train Accuracy: {accuracy_1D_cnn}\")\n",
    "print(f\"Test Accuracy: {accuracy_1D_test_cnn}\")\n",
    "print(f\"Precision: {precision_1D_test_cnn}\")\n",
    "print(f\"Recall: {recall_1D_test_cnn}\")\n",
    "print(f\"F1 Score: {f1_1D_test_cnn}\")\n",
    "print(f\"Log Loss: {log_loss_1D_test_cnn}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_1D_test_cnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b6b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53587c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e05259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2c9659",
   "metadata": {},
   "source": [
    "### Full Code - Time Based Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ./Paderborn_PreCase1_Data/K001/N09_M07_F10_K001_10.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K002/N09_M07_F10_K002_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K003/N09_M07_F10_K003_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K004/N09_M07_F10_K004_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/K005/N09_M07_F10_K005_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA04/N09_M07_F10_KA04_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA15/N09_M07_F10_KA15_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA16/N09_M07_F10_KA16_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA22/N09_M07_F10_KA22_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KA30/N09_M07_F10_KA30_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI04/N09_M07_F10_KI04_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI14/N09_M07_F10_KI14_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI16/N09_M07_F10_KI16_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI18/N09_M07_F10_KI18_2.mat\n",
      "Loaded: ./Paderborn_PreCase1_Data/KI21/N09_M07_F10_KI21_2.mat\n",
      "\n",
      "Combined data shape: (3845043, 5)\n",
      "   vibration  current_1  current_2  label               sample\n",
      "0   0.021362   0.000000  -1.431288      0  N09_M07_F10_K001_10\n",
      "1  -0.106812   0.000016  -1.486391      0  N09_M07_F10_K001_10\n",
      "2  -0.088501   0.000031  -1.567667      0  N09_M07_F10_K001_10\n",
      "3  -1.193237   0.000047  -1.482258      0  N09_M07_F10_K001_10\n",
      "4  -0.122070   0.000063  -1.475370      0  N09_M07_F10_K001_10\n",
      "\n",
      "Signal DataFrame shape: (3845043, 2)\n",
      "     signal  label\n",
      "0  0.021362      0\n",
      "1 -0.106812      0\n",
      "2 -0.088501      0\n",
      "3 -1.193237      0\n",
      "4 -0.122070      0\n",
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8463 - loss: 0.3913\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8468 - loss: 0.3901 - val_accuracy: 0.3328 - val_loss: 1.4108\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9487 - loss: 0.1198\n",
      "Epoch 2: val_accuracy improved from 0.33281 to 0.40885, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9487 - loss: 0.1197 - val_accuracy: 0.4089 - val_loss: 1.3291\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9637 - loss: 0.0878\n",
      "Epoch 3: val_accuracy improved from 0.40885 to 0.76823, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9637 - loss: 0.0878 - val_accuracy: 0.7682 - val_loss: 0.4520\n",
      "Epoch 4/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9763 - loss: 0.0653\n",
      "Epoch 4: val_accuracy improved from 0.76823 to 0.93906, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9763 - loss: 0.0653 - val_accuracy: 0.9391 - val_loss: 0.1253\n",
      "Epoch 5/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9812 - loss: 0.0504\n",
      "Epoch 5: val_accuracy did not improve from 0.93906\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9812 - loss: 0.0504 - val_accuracy: 0.9094 - val_loss: 0.1717\n",
      "Epoch 6/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9836 - loss: 0.0444\n",
      "Epoch 6: val_accuracy improved from 0.93906 to 0.97448, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9836 - loss: 0.0444 - val_accuracy: 0.9745 - val_loss: 0.0788\n",
      "Epoch 7/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9873 - loss: 0.0393\n",
      "Epoch 7: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9873 - loss: 0.0393 - val_accuracy: 0.9682 - val_loss: 0.0712\n",
      "Epoch 8/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9882 - loss: 0.0323\n",
      "Epoch 8: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9882 - loss: 0.0323 - val_accuracy: 0.9641 - val_loss: 0.0809\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9908 - loss: 0.0247\n",
      "Epoch 9: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9908 - loss: 0.0248 - val_accuracy: 0.9224 - val_loss: 0.1535\n",
      "Epoch 10/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9927 - loss: 0.0239\n",
      "Epoch 10: val_accuracy improved from 0.97448 to 1.00000, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 11/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9933 - loss: 0.0210\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9995 - val_loss: 0.0056\n",
      "Epoch 12/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9955 - loss: 0.0159\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.9901 - val_loss: 0.0297\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9945 - loss: 0.0160\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9945 - loss: 0.0160 - val_accuracy: 0.9927 - val_loss: 0.0189\n",
      "Epoch 14/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9939 - loss: 0.0155\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9939 - loss: 0.0155 - val_accuracy: 0.9995 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9973 - loss: 0.0130\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9973 - loss: 0.0130 - val_accuracy: 0.9979 - val_loss: 0.0078\n",
      "Epoch 16/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9967 - loss: 0.0111\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9969 - val_loss: 0.0101\n",
      "Epoch 17/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9965 - loss: 0.0112\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9995 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9938 - loss: 0.0171\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9938 - loss: 0.0171 - val_accuracy: 0.9609 - val_loss: 0.1297\n",
      "Epoch 19/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9970 - loss: 0.0096\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9875 - val_loss: 0.0356\n",
      "Epoch 20/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9960 - loss: 0.0098\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9960 - loss: 0.0098 - val_accuracy: 0.9979 - val_loss: 0.0061\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_1.keras\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8592 - loss: 0.3616\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8594 - loss: 0.3611 - val_accuracy: 0.3328 - val_loss: 3.8675\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9531 - loss: 0.1134\n",
      "Epoch 2: val_accuracy did not improve from 0.33281\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9531 - loss: 0.1134 - val_accuracy: 0.3328 - val_loss: 3.8282\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9678 - loss: 0.0819\n",
      "Epoch 3: val_accuracy improved from 0.33281 to 0.85365, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9678 - loss: 0.0819 - val_accuracy: 0.8536 - val_loss: 0.2874\n",
      "Epoch 4/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9737 - loss: 0.0673\n",
      "Epoch 4: val_accuracy improved from 0.85365 to 0.93698, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9737 - loss: 0.0673 - val_accuracy: 0.9370 - val_loss: 0.1578\n",
      "Epoch 5/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9811 - loss: 0.0528\n",
      "Epoch 5: val_accuracy improved from 0.93698 to 0.94635, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9811 - loss: 0.0528 - val_accuracy: 0.9464 - val_loss: 0.1367\n",
      "Epoch 6/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9825 - loss: 0.0450\n",
      "Epoch 6: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9825 - loss: 0.0450 - val_accuracy: 0.9281 - val_loss: 0.1670\n",
      "Epoch 7/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9879 - loss: 0.0358\n",
      "Epoch 7: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9879 - loss: 0.0358 - val_accuracy: 0.9010 - val_loss: 0.2613\n",
      "Epoch 8/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9886 - loss: 0.0314\n",
      "Epoch 8: val_accuracy did not improve from 0.94635\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9886 - loss: 0.0314 - val_accuracy: 0.9385 - val_loss: 0.1625\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9909 - loss: 0.0288\n",
      "Epoch 9: val_accuracy improved from 0.94635 to 0.96146, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9909 - loss: 0.0287 - val_accuracy: 0.9615 - val_loss: 0.1071\n",
      "Epoch 10/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9910 - loss: 0.0227\n",
      "Epoch 10: val_accuracy did not improve from 0.96146\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9910 - loss: 0.0227 - val_accuracy: 0.9557 - val_loss: 0.1172\n",
      "Epoch 11/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9942 - loss: 0.0186\n",
      "Epoch 11: val_accuracy did not improve from 0.96146\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.9568 - val_loss: 0.1228\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9936 - loss: 0.0180\n",
      "Epoch 12: val_accuracy improved from 0.96146 to 0.97344, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9936 - loss: 0.0181 - val_accuracy: 0.9734 - val_loss: 0.0667\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9959 - loss: 0.0139\n",
      "Epoch 13: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9959 - loss: 0.0139 - val_accuracy: 0.9510 - val_loss: 0.1398\n",
      "Epoch 14/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9941 - loss: 0.0158\n",
      "Epoch 14: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9417 - val_loss: 0.1941\n",
      "Epoch 15/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9940 - loss: 0.0169\n",
      "Epoch 15: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9940 - loss: 0.0168 - val_accuracy: 0.9094 - val_loss: 0.3019\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9968 - loss: 0.0094\n",
      "Epoch 16: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.9563 - val_loss: 0.1445\n",
      "Epoch 17/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9976 - loss: 0.0088\n",
      "Epoch 17: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9976 - loss: 0.0088 - val_accuracy: 0.9604 - val_loss: 0.1079\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9988 - loss: 0.0053\n",
      "Epoch 18: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 0.9370 - val_loss: 0.1818\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9971 - loss: 0.0090\n",
      "Epoch 19: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9432 - val_loss: 0.1977\n",
      "Epoch 20/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9975 - loss: 0.0087\n",
      "Epoch 20: val_accuracy did not improve from 0.97344\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.8307 - val_loss: 0.9383\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_2.keras\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_21 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_22 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_23 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7839 - loss: 0.4670\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33281, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.7847 - loss: 0.4655 - val_accuracy: 0.3328 - val_loss: 2.4130\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9522 - loss: 0.1200\n",
      "Epoch 2: val_accuracy improved from 0.33281 to 0.49896, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9522 - loss: 0.1200 - val_accuracy: 0.4990 - val_loss: 2.0530\n",
      "Epoch 3/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9668 - loss: 0.0888\n",
      "Epoch 3: val_accuracy improved from 0.49896 to 0.80885, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9667 - loss: 0.0888 - val_accuracy: 0.8089 - val_loss: 0.5009\n",
      "Epoch 4/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9684 - loss: 0.0769\n",
      "Epoch 4: val_accuracy improved from 0.80885 to 0.87292, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9684 - loss: 0.0768 - val_accuracy: 0.8729 - val_loss: 0.2694\n",
      "Epoch 5/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9797 - loss: 0.0598\n",
      "Epoch 5: val_accuracy improved from 0.87292 to 0.91406, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9797 - loss: 0.0598 - val_accuracy: 0.9141 - val_loss: 0.1732\n",
      "Epoch 6/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9829 - loss: 0.0501\n",
      "Epoch 6: val_accuracy improved from 0.91406 to 0.92708, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9829 - loss: 0.0501 - val_accuracy: 0.9271 - val_loss: 0.1436\n",
      "Epoch 7/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9820 - loss: 0.0490\n",
      "Epoch 7: val_accuracy improved from 0.92708 to 0.94635, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9820 - loss: 0.0490 - val_accuracy: 0.9464 - val_loss: 0.1152\n",
      "Epoch 8/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9878 - loss: 0.0349\n",
      "Epoch 8: val_accuracy improved from 0.94635 to 0.94687, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9878 - loss: 0.0349 - val_accuracy: 0.9469 - val_loss: 0.1200\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9895 - loss: 0.0313\n",
      "Epoch 9: val_accuracy did not improve from 0.94687\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9895 - loss: 0.0313 - val_accuracy: 0.9370 - val_loss: 0.1416\n",
      "Epoch 10/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9920 - loss: 0.0258\n",
      "Epoch 10: val_accuracy improved from 0.94687 to 0.95521, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9920 - loss: 0.0258 - val_accuracy: 0.9552 - val_loss: 0.1027\n",
      "Epoch 11/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9919 - loss: 0.0240\n",
      "Epoch 11: val_accuracy improved from 0.95521 to 0.97083, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 0.9708 - val_loss: 0.0700\n",
      "Epoch 12/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9936 - loss: 0.0187\n",
      "Epoch 12: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9936 - loss: 0.0187 - val_accuracy: 0.9474 - val_loss: 0.1334\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9945 - loss: 0.0188\n",
      "Epoch 13: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9945 - loss: 0.0188 - val_accuracy: 0.9594 - val_loss: 0.1058\n",
      "Epoch 14/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9961 - loss: 0.0140\n",
      "Epoch 14: val_accuracy improved from 0.97083 to 0.98750, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9961 - loss: 0.0140 - val_accuracy: 0.9875 - val_loss: 0.0324\n",
      "Epoch 15/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9971 - loss: 0.0109\n",
      "Epoch 15: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.9677 - val_loss: 0.0744\n",
      "Epoch 16/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9980 - loss: 0.0073\n",
      "Epoch 16: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.9823 - val_loss: 0.0432\n",
      "Epoch 17/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9963 - loss: 0.0112\n",
      "Epoch 17: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 0.9859 - val_loss: 0.0413\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9970 - loss: 0.0110\n",
      "Epoch 18: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9970 - loss: 0.0110 - val_accuracy: 0.9495 - val_loss: 0.1499\n",
      "Epoch 19/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9977 - loss: 0.0072\n",
      "Epoch 19: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9719 - val_loss: 0.0737\n",
      "Epoch 20/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9977 - loss: 0.0082\n",
      "Epoch 20: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9828 - val_loss: 0.0445\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_3.keras\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_24 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_25 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_26 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7947 - loss: 0.4849\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7954 - loss: 0.4834 - val_accuracy: 0.3333 - val_loss: 4.0608\n",
      "Epoch 2/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9418 - loss: 0.1493\n",
      "Epoch 2: val_accuracy improved from 0.33333 to 0.36510, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9418 - loss: 0.1493 - val_accuracy: 0.3651 - val_loss: 2.8508\n",
      "Epoch 3/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9599 - loss: 0.1055\n",
      "Epoch 3: val_accuracy improved from 0.36510 to 0.99583, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9599 - loss: 0.1055 - val_accuracy: 0.9958 - val_loss: 0.0279\n",
      "Epoch 4/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9691 - loss: 0.0788\n",
      "Epoch 4: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9691 - loss: 0.0788 - val_accuracy: 0.9646 - val_loss: 0.0694\n",
      "Epoch 5/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9742 - loss: 0.0633\n",
      "Epoch 5: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.9742 - loss: 0.0634 - val_accuracy: 0.9760 - val_loss: 0.0493\n",
      "Epoch 6/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9785 - loss: 0.0578\n",
      "Epoch 6: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9785 - loss: 0.0578 - val_accuracy: 0.9792 - val_loss: 0.0550\n",
      "Epoch 7/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9826 - loss: 0.0496\n",
      "Epoch 7: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9826 - loss: 0.0496 - val_accuracy: 0.9875 - val_loss: 0.0335\n",
      "Epoch 8/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9869 - loss: 0.0415\n",
      "Epoch 8: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9869 - loss: 0.0415 - val_accuracy: 0.9911 - val_loss: 0.0244\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9863 - loss: 0.0371\n",
      "Epoch 9: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9863 - loss: 0.0371 - val_accuracy: 0.9839 - val_loss: 0.0345\n",
      "Epoch 10/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9897 - loss: 0.0326\n",
      "Epoch 10: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.9911 - val_loss: 0.0250\n",
      "Epoch 11/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9908 - loss: 0.0261\n",
      "Epoch 11: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9908 - loss: 0.0261 - val_accuracy: 0.9948 - val_loss: 0.0195\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9899 - loss: 0.0271\n",
      "Epoch 12: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9900 - loss: 0.0271 - val_accuracy: 0.9911 - val_loss: 0.0284\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9937 - loss: 0.0212\n",
      "Epoch 13: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.9885 - val_loss: 0.0341\n",
      "Epoch 14/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9942 - loss: 0.0176\n",
      "Epoch 14: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.9942 - loss: 0.0177 - val_accuracy: 0.9807 - val_loss: 0.0442\n",
      "Epoch 15/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9949 - loss: 0.0164\n",
      "Epoch 15: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9949 - loss: 0.0164 - val_accuracy: 0.9859 - val_loss: 0.0349\n",
      "Epoch 16/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9951 - loss: 0.0175\n",
      "Epoch 16: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.9880 - val_loss: 0.0370\n",
      "Epoch 17/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9963 - loss: 0.0132\n",
      "Epoch 17: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.9583 - val_loss: 0.1343\n",
      "Epoch 18/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9940 - loss: 0.0181\n",
      "Epoch 18: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.9940 - loss: 0.0181 - val_accuracy: 0.9885 - val_loss: 0.0356\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9955 - loss: 0.0119\n",
      "Epoch 19: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 0.9755 - val_loss: 0.0817\n",
      "Epoch 20/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9977 - loss: 0.0105\n",
      "Epoch 20: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9977 - loss: 0.0105 - val_accuracy: 0.9948 - val_loss: 0.0210\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_4.keras\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_9      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_27 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_28 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_29 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_9      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7895 - loss: 0.4888\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33299, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.7902 - loss: 0.4872 - val_accuracy: 0.3330 - val_loss: 4.8807\n",
      "Epoch 2/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9403 - loss: 0.1468\n",
      "Epoch 2: val_accuracy did not improve from 0.33299\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9404 - loss: 0.1467 - val_accuracy: 0.3330 - val_loss: 4.7716\n",
      "Epoch 3/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9681 - loss: 0.0953\n",
      "Epoch 3: val_accuracy improved from 0.33299 to 0.90620, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9681 - loss: 0.0952 - val_accuracy: 0.9062 - val_loss: 0.2015\n",
      "Epoch 4/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9753 - loss: 0.0733\n",
      "Epoch 4: val_accuracy improved from 0.90620 to 0.98593, saving model to /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9753 - loss: 0.0733 - val_accuracy: 0.9859 - val_loss: 0.0446\n",
      "Epoch 5/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9785 - loss: 0.0574\n",
      "Epoch 5: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9785 - loss: 0.0574 - val_accuracy: 0.9859 - val_loss: 0.0408\n",
      "Epoch 6/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9826 - loss: 0.0483\n",
      "Epoch 6: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9826 - loss: 0.0483 - val_accuracy: 0.9766 - val_loss: 0.0647\n",
      "Epoch 7/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9863 - loss: 0.0430\n",
      "Epoch 7: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9863 - loss: 0.0430 - val_accuracy: 0.9614 - val_loss: 0.1083\n",
      "Epoch 8/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9888 - loss: 0.0346\n",
      "Epoch 8: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9888 - loss: 0.0346 - val_accuracy: 0.9781 - val_loss: 0.0617\n",
      "Epoch 9/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9918 - loss: 0.0322\n",
      "Epoch 9: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9918 - loss: 0.0322 - val_accuracy: 0.9562 - val_loss: 0.1283\n",
      "Epoch 10/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9934 - loss: 0.0238\n",
      "Epoch 10: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9934 - loss: 0.0238 - val_accuracy: 0.9630 - val_loss: 0.1154\n",
      "Epoch 11/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9929 - loss: 0.0242\n",
      "Epoch 11: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9929 - loss: 0.0242 - val_accuracy: 0.9854 - val_loss: 0.0386\n",
      "Epoch 12/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9941 - loss: 0.0199\n",
      "Epoch 12: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9941 - loss: 0.0199 - val_accuracy: 0.9609 - val_loss: 0.1131\n",
      "Epoch 13/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9951 - loss: 0.0161\n",
      "Epoch 13: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9687 - val_loss: 0.1110\n",
      "Epoch 14/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9929 - loss: 0.0203\n",
      "Epoch 14: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9929 - loss: 0.0203 - val_accuracy: 0.9818 - val_loss: 0.0473\n",
      "Epoch 15/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9944 - loss: 0.0119\n",
      "Epoch 15: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9945 - loss: 0.0119 - val_accuracy: 0.9760 - val_loss: 0.0796\n",
      "Epoch 16/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9957 - loss: 0.0119\n",
      "Epoch 16: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.9396 - val_loss: 0.1871\n",
      "Epoch 17/20\n",
      "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9965 - loss: 0.0101\n",
      "Epoch 17: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9965 - loss: 0.0101 - val_accuracy: 0.9682 - val_loss: 0.0785\n",
      "Epoch 18/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9973 - loss: 0.0102\n",
      "Epoch 18: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9973 - loss: 0.0102 - val_accuracy: 0.9802 - val_loss: 0.0515\n",
      "Epoch 19/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0059\n",
      "Epoch 19: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9982 - loss: 0.0059 - val_accuracy: 0.9729 - val_loss: 0.1153\n",
      "Epoch 20/20\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 20: val_accuracy did not improve from 0.98593\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9698 - val_loss: 0.1087\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Best model saved at: /Users/user/Downloads/Code_Final_Version/Paderborn_baseline/1D_CNN/best_model_5.keras\n",
      "1D CNN Metrics:\n",
      "Train Accuracy: 96.60%\n",
      "Test Accuracy: 66.70%\n",
      "Train Precision: 97.18%\n",
      "Test Precision: 67.82%\n",
      "Train Recall: 96.60%\n",
      "Test Recall: 66.70%\n",
      "Train Log Loss: 0.0918\n",
      "Test Log Loss: 3.5322\n",
      "Train Balanced Accuracy: 96.60%\n",
      "Test Balanced Accuracy: 66.70%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 353\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Computation Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 310\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Plot aggregated confusion matrices\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Train confusion matrix (using the last best model)\u001b[39;00m\n\u001b[1;32m    309\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m--> 310\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mConfusionMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_1D_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, annot_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfontsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m}, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYlGnBu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix - CNN 1D Train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    312\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 180\u001b[0m, in \u001b[0;36mConfusionMatrix\u001b[0;34m(Model, X, y)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mConfusionMatrix\u001b[39m(Model, X, y):\n\u001b[0;32m--> 180\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m    181\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    182\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'model'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Random Seed for Reproducibility\n",
    "sd = 1\n",
    "os.environ['PYTHONHASHSEED'] = str(sd)\n",
    "np.random.seed(sd)\n",
    "rn.seed(sd)\n",
    "tf.random.set_seed(sd)\n",
    "\n",
    "# Configuration\n",
    "root_dir = './Paderborn_PreCase1_Data'\n",
    "\n",
    "data_structure = {\n",
    "    0: (\"Healthy\", [\"K001\", \"K002\", \"K003\", \"K004\", \"K005\"]),\n",
    "    1: (\"OR_Damage\", [\"KA04\", \"KA15\", \"KA16\", \"KA22\", \"KA30\"]),\n",
    "    2: (\"IR_Damage\", [\"KI04\", \"KI14\", \"KI16\", \"KI18\", \"KI21\"]),\n",
    "}\n",
    "\n",
    "# Data Extraction Function\n",
    "def extract_signals_df(filepath, signal=\"all\"):\n",
    "    signals = {\n",
    "        \"vibration\": 6,\n",
    "        \"current_1\": 1,\n",
    "        \"current_2\": 2,\n",
    "    }\n",
    "    mat = loadmat(filepath, struct_as_record=False, squeeze_me=True)\n",
    "    field = next(k for k in mat if not k.startswith(\"__\"))\n",
    "    struct = mat[field]\n",
    "    X_channels = struct.X\n",
    "    Y_channels = struct.Y\n",
    "    if signal == \"vibration\":\n",
    "        v = Y_channels[signals[\"vibration\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(v, columns=[\"vibration\"])\n",
    "    elif signal == \"current\":\n",
    "        c1 = X_channels[signals[\"current_1\"]].Data.flatten().reshape(-1, 1)\n",
    "        c2 = Y_channels[signals[\"current_2\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(np.concatenate([c1, c2], axis=1), columns=[\"current_1\", \"current_2\"])\n",
    "    elif signal == \"all\":\n",
    "        v = Y_channels[signals[\"vibration\"]].Data.flatten().reshape(-1, 1)\n",
    "        c1 = X_channels[signals[\"current_1\"]].Data.flatten().reshape(-1, 1)\n",
    "        c2 = Y_channels[signals[\"current_2\"]].Data.flatten().reshape(-1, 1)\n",
    "        return pd.DataFrame(np.concatenate([v, c1, c2], axis=1),\n",
    "                            columns=[\"vibration\", \"current_1\", \"current_2\"])\n",
    "    else:\n",
    "        raise ValueError(\"Signal must be one of: 'vibration', 'current', or 'all'\")\n",
    "\n",
    "# Data Loading\n",
    "def load_data():\n",
    "    all_data = []\n",
    "    for label, (category, folders) in data_structure.items():\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(root_dir, folder)\n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"Warning: Folder {folder_path} not found.\")\n",
    "                continue\n",
    "            mat_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".mat\")])\n",
    "            for filename in mat_files[1:2]:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    df = extract_signals_df(file_path, signal=\"all\")\n",
    "                    df[\"label\"] = label\n",
    "                    df[\"sample\"] = filename.replace(\".mat\", \"\")\n",
    "                    all_data.append(df)\n",
    "                    print(f\"Loaded: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(final_df):\n",
    "    df_signals = final_df[[\"vibration\", \"label\"]].copy()\n",
    "    df_signals.rename(columns={\"vibration\": \"signal\"}, inplace=True)\n",
    "    print(\"\\nSignal DataFrame shape:\", df_signals.shape)\n",
    "    print(df_signals.head())\n",
    "    \n",
    "    grouped_signals = [\n",
    "        df_signals[df_signals['label'] == i]['signal'].values.astype(float)\n",
    "        for i in sorted(df_signals['label'].unique())\n",
    "    ]\n",
    "    return grouped_signals\n",
    "\n",
    "# Data Sampling\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    No_of_blocks = (\n",
    "        round(adjusted_length / interval_length)\n",
    "        - round(samples_per_block / interval_length)\n",
    "        - 1\n",
    "    )\n",
    "    if No_of_blocks <= 0:\n",
    "        return np.empty((0, samples_per_block))\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "    for i in range(No_of_blocks):\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx : start_idx + samples_per_block].T\n",
    "    return SplitData\n",
    "\n",
    "# Data Preparation\n",
    "def DataPreparation(DataList, interval_length, samples_per_block):\n",
    "    for count, signal in enumerate(DataList):\n",
    "        SplitData = Sampling(signal, interval_length, samples_per_block)\n",
    "        if SplitData.shape[0] == 0:\n",
    "            continue\n",
    "        y = np.zeros([len(SplitData), len(DataList)])\n",
    "        y[:, count] = 1\n",
    "        y1 = np.zeros([len(SplitData), 1])\n",
    "        y1[:, 0] = count\n",
    "        if count == 0:\n",
    "            X = SplitData\n",
    "            LabelPositional = y\n",
    "            Label = y1\n",
    "        else:\n",
    "            X = np.append(X, SplitData, axis=0)\n",
    "            LabelPositional = np.append(LabelPositional, y, axis=0)\n",
    "            Label = np.append(Label, y1, axis=0)\n",
    "    return X, LabelPositional, Label\n",
    "\n",
    "# Data Splitting\n",
    "def time_series_stratified_split(X, y, train_ratio=0.8):\n",
    "    num_classes = y.shape[1]\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "    for cls in range(num_classes):\n",
    "        cls_indices = np.where(np.argmax(y, axis=1) == cls)[0]\n",
    "        n_train = int(train_ratio * len(cls_indices))\n",
    "        train_idx, test_idx = cls_indices[:n_train], cls_indices[n_train:]\n",
    "        X_train.append(X[train_idx])\n",
    "        y_train.append(y[train_idx])\n",
    "        X_test.append(X[test_idx])\n",
    "        y_test.append(y[test_idx])\n",
    "    return (\n",
    "        np.concatenate(X_train),\n",
    "        np.concatenate(y_train),\n",
    "        np.concatenate(X_test),\n",
    "        np.concatenate(y_test)\n",
    "    )\n",
    "\n",
    "# CNN Model Definition\n",
    "class CNN_1D:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = self.CreateModel(input_shape)\n",
    "        self.model.summary()\n",
    "    \n",
    "    def CreateModel(self, input_shape):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# Confusion Matrix Function\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "    y_pred_proba = Model.model.predict(X)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    # Constants\n",
    "    interval_length = 320\n",
    "    samples_per_block = 1600\n",
    "    k_split = 5\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    final_df = load_data()\n",
    "    print(\"\\nCombined data shape:\", final_df.shape)\n",
    "    print(final_df.head())\n",
    "    \n",
    "    grouped_signals = preprocess_data(final_df)\n",
    "    X, y_positional, y_labels = DataPreparation(grouped_signals, interval_length, samples_per_block)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, y_train, X_test, y_test = time_series_stratified_split(X, y_positional)\n",
    "    X_1D_train = X_train.reshape(-1, samples_per_block, 1)\n",
    "    X_1D_test = X_test.reshape(-1, samples_per_block, 1)\n",
    "    input_shape = (samples_per_block, 1)\n",
    "    y_train_classes = np.argmax(y_train, axis=1)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    accuracy_1D_cnn, precision_1D_cnn, recall_1D_cnn = [], [], []\n",
    "    f1_1D_cnn, log_loss_1D_cnn, balanced_accuracy_1D_cnn = [], [], []\n",
    "    accuracy_1D_test_cnn, precision_1D_test_cnn, recall_1D_test_cnn = [], [], []\n",
    "    f1_1D_test_cnn, log_loss_1D_test_cnn, balanced_accuracy_1D_test_cnn = [], [], []\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    kfold = StratifiedKFold(n_splits=k_split, shuffle=False)\n",
    "    foldername_cnn = os.path.join(os.getcwd(), \"Paderborn_baseline\", \"1D_CNN\")\n",
    "    os.makedirs(foldername_cnn, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_1D_train, y_train_classes)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        checkpoint_filepath = os.path.join(foldername_cnn, f\"best_model_{fold + 1}.keras\")\n",
    "        checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy',\n",
    "                                    save_best_only=True, mode='max', verbose=1)\n",
    "        \n",
    "        # Train model\n",
    "        model = CNN_1D(input_shape)\n",
    "        model.model.fit(\n",
    "            X_1D_train[train_idx], y_train[train_idx],\n",
    "            validation_data=(X_1D_train[val_idx], y_train[val_idx]),\n",
    "            epochs=20,\n",
    "            verbose=1,\n",
    "            callbacks=[checkpoint]\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        best_model = load_model(checkpoint_filepath)\n",
    "        y_pred_train_probs = best_model.predict(X_1D_train[train_idx])\n",
    "        y_pred_train = np.argmax(y_pred_train_probs, axis=1)\n",
    "        y_true_train = np.argmax(y_train[train_idx], axis=1)\n",
    "        \n",
    "        # Training metrics\n",
    "        accuracy_1D_cnn.append(round(accuracy_score(y_true_train, y_pred_train), 3))\n",
    "        precision_1D_cnn.append(round(precision_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "        recall_1D_cnn.append(round(recall_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "        f1_1D_cnn.append(round(f1_score(y_true_train, y_pred_train, average='weighted'), 3))\n",
    "        log_loss_1D_cnn.append(round(log_loss(y_true_train, y_pred_train_probs), 3))\n",
    "        balanced_accuracy_1D_cnn.append(round(balanced_accuracy_score(y_true_train, y_pred_train), 3))\n",
    "        \n",
    "        # Training confusion matrix (per fold)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(confusion_matrix(y_true_train, y_pred_train), annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'1D CNN Train Confusion Matrix - Fold {fold + 1}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_train_fold_{fold + 1}.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        # Test evaluation\n",
    "        y_pred_test_probs = best_model.predict(X_1D_test)\n",
    "        y_pred_test = np.argmax(y_pred_test_probs, axis=1)\n",
    "        y_true_test = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # Test metrics\n",
    "        accuracy_1D_test_cnn.append(round(accuracy_score(y_true_test, y_pred_test), 3))\n",
    "        precision_1D_test_cnn.append(round(precision_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "        recall_1D_test_cnn.append(round(recall_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "        f1_1D_test_cnn.append(round(f1_score(y_true_test, y_pred_test, average='weighted'), 3))\n",
    "        log_loss_1D_test_cnn.append(round(log_loss(y_true_test, y_pred_test_probs), 3))\n",
    "        balanced_accuracy_1D_test_cnn.append(round(balanced_accuracy_score(y_true_test, y_pred_test), 3))\n",
    "        \n",
    "        # Test confusion matrix (per fold)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(confusion_matrix(y_true_test, y_pred_test), annot=True, fmt='d', cmap='Greens')\n",
    "        plt.title(f'1D CNN Test Confusion Matrix - Fold {fold + 1}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(os.path.join(foldername_cnn, f\"1D_CNN_conf_matrix_test_fold_{fold + 1}.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Best model saved at: {checkpoint_filepath}\")\n",
    "    \n",
    "    # Compute aggregated metrics\n",
    "    CNN_1D_train_accuracy = np.mean(accuracy_1D_cnn) * 100\n",
    "    CNN_1D_test_accuracy = np.mean(accuracy_1D_test_cnn) * 100\n",
    "    CNN_1D_train_precision = np.mean(precision_1D_cnn) * 100\n",
    "    CNN_1D_test_precision = np.mean(precision_1D_test_cnn) * 100\n",
    "    CNN_1D_train_recall = np.mean(recall_1D_cnn) * 100\n",
    "    CNN_1D_test_recall = np.mean(recall_1D_test_cnn) * 100\n",
    "    CNN_1D_train_log_loss = np.mean(log_loss_1D_cnn)\n",
    "    CNN_1D_test_log_loss = np.mean(log_loss_1D_test_cnn)\n",
    "    CNN_1D_train_balanced_accuracy = np.mean(balanced_accuracy_1D_cnn) * 100\n",
    "    CNN_1D_test_balanced_accuracy = np.mean(balanced_accuracy_1D_test_cnn) * 100\n",
    "    \n",
    "    # Print aggregated metrics\n",
    "    print(\"1D CNN Metrics:\")\n",
    "    print(f\"Train Accuracy: {CNN_1D_train_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {CNN_1D_test_accuracy:.2f}%\")\n",
    "    print(f\"Train Precision: {CNN_1D_train_precision:.2f}%\")\n",
    "    print(f\"Test Precision: {CNN_1D_test_precision:.2f}%\")\n",
    "    print(f\"Train Recall: {CNN_1D_train_recall:.2f}%\")\n",
    "    print(f\"Test Recall: {CNN_1D_test_recall:.2f}%\")\n",
    "    print(f\"Train Log Loss: {CNN_1D_train_log_loss:.4f}\")\n",
    "    print(f\"Test Log Loss: {CNN_1D_test_log_loss:.4f}\")\n",
    "    print(f\"Train Balanced Accuracy: {CNN_1D_train_balanced_accuracy:.2f}%\")\n",
    "    print(f\"Test Balanced Accuracy: {CNN_1D_test_balanced_accuracy:.2f}%\")\n",
    "    \n",
    "    # Plot aggregated confusion matrices\n",
    "    # Train confusion matrix (using the last best model)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(ConfusionMatrix(model, X_1D_train, y_train), annot=True, fmt='d', annot_kws={\"fontsize\": 8}, cmap=\"YlGnBu\")\n",
    "    plt.title('Confusion Matrix - CNN 1D Train')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(foldername_cnn, \"1D_CNN_conf_matrix_train_aggregated.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Test confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(ConfusionMatrix(model, X_1D_test, y_test), annot=True, fmt='d', annot_kws={\"fontsize\": 8}, cmap=\"YlGnBu\")\n",
    "    plt.title('Confusion Matrix - CNN 1D Test')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(foldername_cnn, \"1D_CNN_conf_matrix_test_aggregated.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot training accuracy per fold\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(np.arange(1, k_split + 1), [i * 100 for i in accuracy_1D_cnn])\n",
    "    plt.title('Train - Accuracy - CNN 1D')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Folds')\n",
    "    plt.ylim([70, 100])\n",
    "    plt.savefig(os.path.join(foldername_cnn, \"1D_CNN_train_accuracy_per_fold.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot train vs test accuracy\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar([1, 2], [CNN_1D_train_accuracy, CNN_1D_test_accuracy])\n",
    "    plt.title('Train vs Test Accuracy - CNN 1D')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Sets')\n",
    "    plt.xticks([1, 2], ['Train', 'Test'])\n",
    "    plt.ylim([70, 100])\n",
    "    plt.savefig(os.path.join(foldername_cnn, \"1D_CNN_train_vs_test_accuracy.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Print computation time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total Computation Time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32d74847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(ConfusionMatrix(model, X_1D_train, y_train), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70516fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'True')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(ConfusionMatrix(model, X_1D_test, y_test), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.title('Confusion Matrix - CNN 1D Test')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1befb634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
