{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7b1a76",
   "metadata": {},
   "source": [
    "### Random Shuffle-Based Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.7784 - loss: 0.5038 - val_accuracy: 0.6087 - val_loss: 0.8036\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9275 - loss: 0.1830 - val_accuracy: 0.7632 - val_loss: 0.5189\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9446 - loss: 0.1398 - val_accuracy: 0.8941 - val_loss: 0.1886\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9522 - loss: 0.1213 - val_accuracy: 0.9296 - val_loss: 0.1389\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9601 - loss: 0.1007 - val_accuracy: 0.9381 - val_loss: 0.1160\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9654 - loss: 0.0872 - val_accuracy: 0.9461 - val_loss: 0.1303\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9704 - loss: 0.0802 - val_accuracy: 0.9419 - val_loss: 0.1305\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9716 - loss: 0.0724 - val_accuracy: 0.9877 - val_loss: 0.0393\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9774 - loss: 0.0558 - val_accuracy: 0.9877 - val_loss: 0.0340\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9805 - loss: 0.0496 - val_accuracy: 0.9891 - val_loss: 0.0329\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.9810 - loss: 0.0472 - val_accuracy: 0.9920 - val_loss: 0.0248\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9845 - loss: 0.0410 - val_accuracy: 0.9853 - val_loss: 0.0459\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9896 - loss: 0.0307 - val_accuracy: 0.9863 - val_loss: 0.0333\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9916 - loss: 0.0256 - val_accuracy: 0.9877 - val_loss: 0.0354\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9911 - loss: 0.0241 - val_accuracy: 0.9646 - val_loss: 0.1114\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9924 - loss: 0.0244 - val_accuracy: 0.9556 - val_loss: 0.1254\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9922 - loss: 0.0270 - val_accuracy: 0.9164 - val_loss: 0.2844\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.9944 - loss: 0.0184 - val_accuracy: 0.9594 - val_loss: 0.1270\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9941 - loss: 0.0194 - val_accuracy: 0.9896 - val_loss: 0.0313\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9955 - loss: 0.0166 - val_accuracy: 0.9948 - val_loss: 0.0140\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.9917 - loss: 0.0227 - val_accuracy: 0.8842 - val_loss: 0.4919\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9956 - loss: 0.0128 - val_accuracy: 0.9872 - val_loss: 0.0362\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0104 - val_accuracy: 0.9920 - val_loss: 0.0199\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9962 - val_loss: 0.0103\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9955 - loss: 0.0125 - val_accuracy: 0.9910 - val_loss: 0.0219\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.9750 - val_loss: 0.0611\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0151 - val_accuracy: 0.9872 - val_loss: 0.0321\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.9967 - val_loss: 0.0092\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9901 - val_loss: 0.0290\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.8932 - val_loss: 0.4523\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9891 - val_loss: 0.0300\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.9953 - val_loss: 0.0115\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9858 - val_loss: 0.0428\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9636 - val_loss: 0.1202\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9972 - val_loss: 0.0059\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0057 - val_accuracy: 0.9924 - val_loss: 0.0201\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9981 - val_loss: 0.0051\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0036 - val_accuracy: 0.9452 - val_loss: 0.1986\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0073 - val_accuracy: 0.9712 - val_loss: 0.1115\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9949 - loss: 0.0196 - val_accuracy: 0.9943 - val_loss: 0.0219\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.9972 - val_loss: 0.0079\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0117 - val_accuracy: 0.9981 - val_loss: 0.0038\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.9962 - val_loss: 0.0078\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9915 - val_loss: 0.0321\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9698 - val_loss: 0.1351\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9976 - val_loss: 0.0065\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9984 - loss: 0.0035 - val_accuracy: 0.9905 - val_loss: 0.0258\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.9943 - val_loss: 0.0098\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.1495e-04 - val_accuracy: 0.9995 - val_loss: 9.7215e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9957 - val_loss: 0.0146\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9949 - loss: 0.0147 - val_accuracy: 0.9929 - val_loss: 0.0157\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9617 - val_loss: 0.1579\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.2966e-04 - val_accuracy: 0.9957 - val_loss: 0.0123\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.9359e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9929 - val_loss: 0.0215\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9305 - val_loss: 0.2654\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9929 - val_loss: 0.0248\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9920 - val_loss: 0.0188\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9973 - loss: 0.0061 - val_accuracy: 0.9546 - val_loss: 0.2718\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9976 - val_loss: 0.0100\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9768 - val_loss: 0.0813\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9981 - val_loss: 0.0048\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9924 - val_loss: 0.0203\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9943 - val_loss: 0.0214\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9953 - val_loss: 0.0129\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 7.2830e-04 - val_accuracy: 0.9948 - val_loss: 0.0123\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9967 - val_loss: 0.0042\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9948 - val_loss: 0.0150\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9986 - val_loss: 0.0054\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9991 - val_loss: 0.0035\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9976 - val_loss: 0.0055\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.8025 - val_loss: 0.7471\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: 0.0145 - val_accuracy: 0.9797 - val_loss: 0.0757\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9986 - val_loss: 0.0020\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 4.2176e-04 - val_accuracy: 0.9995 - val_loss: 6.3875e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 3.3865e-04 - val_accuracy: 0.9995 - val_loss: 7.6637e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9998 - loss: 5.5835e-04 - val_accuracy: 0.9995 - val_loss: 8.6459e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9999 - loss: 5.9934e-04 - val_accuracy: 0.8393 - val_loss: 1.3945\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9991 - val_loss: 0.0023\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.9957 - val_loss: 0.0072\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 5.8202e-04 - val_accuracy: 0.9981 - val_loss: 0.0069\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0118 - val_accuracy: 0.9981 - val_loss: 0.0056\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.4383e-04 - val_accuracy: 0.9972 - val_loss: 0.0099\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9986 - val_loss: 0.0029\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.0576e-04 - val_accuracy: 0.9991 - val_loss: 0.0023\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.3405e-05 - val_accuracy: 0.9991 - val_loss: 0.0012\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9999 - loss: 5.5596e-04 - val_accuracy: 0.9962 - val_loss: 0.0138\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9998 - loss: 9.3416e-04 - val_accuracy: 0.9967 - val_loss: 0.0131\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9991 - val_loss: 0.0055\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9542 - val_loss: 0.3061\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9995 - val_loss: 0.0029\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9957 - val_loss: 0.0126\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.9991 - val_loss: 0.0019\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 4.3276e-04 - val_accuracy: 0.9929 - val_loss: 0.0239\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 3.2267e-04 - val_accuracy: 1.0000 - val_loss: 3.9175e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.7846e-04 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.6699e-05 - val_accuracy: 0.9995 - val_loss: 5.8290e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.4957e-04 - val_accuracy: 1.0000 - val_loss: 3.3627e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.2681e-05 - val_accuracy: 0.9480 - val_loss: 0.2402\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0248 - val_accuracy: 0.9981 - val_loss: 0.0040\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9920 - val_loss: 0.0230\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 4.2378e-04 - val_accuracy: 1.0000 - val_loss: 7.6513e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6076e-04 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9972 - val_loss: 0.0107\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 1.9994e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9996 - loss: 8.7978e-04 - val_accuracy: 1.0000 - val_loss: 3.0237e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9986 - val_loss: 0.0026\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 9.1903e-04 - val_accuracy: 1.0000 - val_loss: 2.8403e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 4.1114e-04 - val_accuracy: 0.9986 - val_loss: 0.0033\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9910 - val_loss: 0.0303\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9693 - val_loss: 0.1516\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9995 - val_loss: 0.0031\n",
      "Epoch 119/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 5.0684e-04 - val_accuracy: 0.9991 - val_loss: 0.0048\n",
      "Epoch 120/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0130 - val_accuracy: 0.9981 - val_loss: 0.0043\n",
      "Epoch 121/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 7.2896e-04 - val_accuracy: 0.9991 - val_loss: 0.0035\n",
      "Epoch 122/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 8.8947e-04 - val_accuracy: 0.9981 - val_loss: 0.0046\n",
      "Epoch 123/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.9981 - val_loss: 0.0032\n",
      "Epoch 124/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 9.6842e-04 - val_accuracy: 0.9976 - val_loss: 0.0034\n",
      "Epoch 125/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9991 - val_loss: 0.0017\n",
      "Epoch 126/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9929 - val_loss: 0.0280\n",
      "Epoch 127/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.1326e-04 - val_accuracy: 0.9991 - val_loss: 0.0013\n",
      "Epoch 128/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2130e-04 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 129/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.8294e-05 - val_accuracy: 1.0000 - val_loss: 9.8170e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.1752e-04 - val_accuracy: 0.9991 - val_loss: 0.0011\n",
      "Epoch 131/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.7757e-05 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 132/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.9890e-05 - val_accuracy: 0.9986 - val_loss: 0.0031\n",
      "Epoch 133/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.2901e-05 - val_accuracy: 0.9986 - val_loss: 0.0021\n",
      "Epoch 134/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.0883e-05 - val_accuracy: 0.9995 - val_loss: 8.4006e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.0861e-05 - val_accuracy: 0.9986 - val_loss: 0.0017\n",
      "Epoch 136/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.0091e-05 - val_accuracy: 0.9995 - val_loss: 5.0761e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.3908e-05 - val_accuracy: 0.9976 - val_loss: 0.0107\n",
      "Epoch 138/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3098e-05 - val_accuracy: 0.9995 - val_loss: 8.3840e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 0.8686 - val_loss: 0.9595\n",
      "Epoch 140/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0041 - val_accuracy: 0.9976 - val_loss: 0.0040\n",
      "Epoch 141/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 142/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.6478e-04 - val_accuracy: 0.9995 - val_loss: 8.1374e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5661e-04 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 144/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.6485e-04 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 145/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
      "Epoch 146/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.1748e-04 - val_accuracy: 1.0000 - val_loss: 7.7784e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.6948e-04 - val_accuracy: 0.9995 - val_loss: 5.8826e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.1512e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 149/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.3094e-04 - val_accuracy: 0.9995 - val_loss: 5.1079e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.8910e-05 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 151/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.0302e-04 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 152/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2434e-04 - val_accuracy: 1.0000 - val_loss: 4.7252e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.3544e-04 - val_accuracy: 1.0000 - val_loss: 5.3802e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.9896 - val_loss: 0.0359\n",
      "Epoch 155/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 6.0582e-04 - val_accuracy: 0.9967 - val_loss: 0.0070\n",
      "Epoch 156/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9991 - val_loss: 0.0010\n",
      "Epoch 157/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.4813e-04 - val_accuracy: 0.9991 - val_loss: 0.0012\n",
      "Epoch 158/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.6747e-04 - val_accuracy: 0.9976 - val_loss: 0.0058\n",
      "Epoch 159/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 5.3783e-04 - val_accuracy: 0.9986 - val_loss: 0.0020\n",
      "Epoch 160/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 1.8103e-04 - val_accuracy: 0.9991 - val_loss: 0.0018\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.7788 - loss: 0.4906 - val_accuracy: 0.3243 - val_loss: 4.0035\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9253 - loss: 0.1828 - val_accuracy: 0.5740 - val_loss: 1.3039\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9435 - loss: 0.1349 - val_accuracy: 0.9730 - val_loss: 0.0879\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9510 - loss: 0.1204 - val_accuracy: 0.9858 - val_loss: 0.0540\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9585 - loss: 0.1026 - val_accuracy: 0.9560 - val_loss: 0.0814\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9611 - loss: 0.0986 - val_accuracy: 0.9560 - val_loss: 0.0802\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.9639 - loss: 0.0906 - val_accuracy: 0.9877 - val_loss: 0.0412\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9691 - loss: 0.0759 - val_accuracy: 0.9773 - val_loss: 0.0554\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9711 - loss: 0.0720 - val_accuracy: 0.9877 - val_loss: 0.0352\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9751 - loss: 0.0641 - val_accuracy: 0.9901 - val_loss: 0.0342\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9805 - loss: 0.0531 - val_accuracy: 0.9896 - val_loss: 0.0335\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9796 - loss: 0.0579 - val_accuracy: 0.9939 - val_loss: 0.0229\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9849 - loss: 0.0432 - val_accuracy: 0.9882 - val_loss: 0.0317\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9858 - loss: 0.0413 - val_accuracy: 0.9910 - val_loss: 0.0289\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9908 - loss: 0.0276 - val_accuracy: 0.9948 - val_loss: 0.0168\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9925 - loss: 0.0233 - val_accuracy: 0.9608 - val_loss: 0.0979\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0206 - val_accuracy: 0.9981 - val_loss: 0.0096\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9945 - loss: 0.0170 - val_accuracy: 0.9929 - val_loss: 0.0213\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9916 - loss: 0.0220 - val_accuracy: 0.9981 - val_loss: 0.0099\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9872 - val_loss: 0.0322\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.0207 - val_accuracy: 0.9868 - val_loss: 0.0349\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0104 - val_accuracy: 0.9882 - val_loss: 0.0332\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0132 - val_accuracy: 0.9953 - val_loss: 0.0151\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9853 - val_loss: 0.0310\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0170 - val_accuracy: 0.9820 - val_loss: 0.0591\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9947 - loss: 0.0151 - val_accuracy: 0.9981 - val_loss: 0.0054\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0075 - val_accuracy: 0.9901 - val_loss: 0.0217\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9952 - loss: 0.0140 - val_accuracy: 0.9953 - val_loss: 0.0129\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0206 - val_accuracy: 0.9962 - val_loss: 0.0103\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9960 - loss: 0.0143 - val_accuracy: 0.9943 - val_loss: 0.0149\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9816 - val_loss: 0.0774\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.9773 - val_loss: 0.0538\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 0.9967 - val_loss: 0.0106\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9991 - val_loss: 0.0033\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9924 - val_loss: 0.0296\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9570 - val_loss: 0.1396\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9981 - val_loss: 0.0061\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9976 - val_loss: 0.0063\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9111 - val_loss: 0.3214\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9934 - loss: 0.0154 - val_accuracy: 0.9768 - val_loss: 0.0687\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9995 - val_loss: 0.0020\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9991 - val_loss: 0.0039\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.9281 - val_loss: 0.2229\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9986 - val_loss: 0.0050\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.9972 - val_loss: 0.0090\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9962 - val_loss: 0.0124\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9905 - val_loss: 0.0202\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9891 - val_loss: 0.0523\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9806 - val_loss: 0.0563\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.9981 - val_loss: 0.0044\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9976 - val_loss: 0.0073\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 9.4422e-04 - val_accuracy: 0.9972 - val_loss: 0.0088\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.6426 - val_loss: 3.8105\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0180 - val_accuracy: 0.9962 - val_loss: 0.0141\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.9962 - val_loss: 0.0113\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9976 - val_loss: 0.0071\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9943 - val_loss: 0.0316\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9986 - val_loss: 0.0079\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 7.9684e-04 - val_accuracy: 0.9991 - val_loss: 0.0058\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9466 - val_loss: 0.1897\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0305 - val_accuracy: 0.9986 - val_loss: 0.0049\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9598 - val_loss: 0.1730\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.4939e-04 - val_accuracy: 0.9972 - val_loss: 0.0112\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.1510e-04 - val_accuracy: 0.9939 - val_loss: 0.0306\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9943 - val_loss: 0.0236\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9995 - val_loss: 0.0027\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9976 - val_loss: 0.0058\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 5.5401e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.9062e-04 - val_accuracy: 0.9976 - val_loss: 0.0082\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.4776e-04 - val_accuracy: 0.9967 - val_loss: 0.0094\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.7144 - val_loss: 1.5902\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9944 - loss: 0.0196 - val_accuracy: 0.9967 - val_loss: 0.0075\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9929 - val_loss: 0.0361\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.9924 - val_loss: 0.0227\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.9986 - val_loss: 0.0059\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9981 - val_loss: 0.0061\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9991 - val_loss: 0.0063\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.8336e-04 - val_accuracy: 0.9972 - val_loss: 0.0130\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 8.5888e-04 - val_accuracy: 0.9972 - val_loss: 0.0150\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.2179e-04 - val_accuracy: 0.9957 - val_loss: 0.0217\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.7132e-04 - val_accuracy: 0.9972 - val_loss: 0.0128\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9959 - loss: 0.0144 - val_accuracy: 0.9844 - val_loss: 0.0522\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.8052 - val_loss: 0.9616\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.9924 - val_loss: 0.0282\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0020 - val_accuracy: 0.9986 - val_loss: 0.0082\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.4643e-04 - val_accuracy: 0.9986 - val_loss: 0.0061\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9957 - val_loss: 0.0176\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9981 - val_loss: 0.0087\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.6586e-04 - val_accuracy: 0.9986 - val_loss: 0.0072\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7929 - loss: 0.4534 - val_accuracy: 0.3390 - val_loss: 4.2792\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9230 - loss: 0.1894 - val_accuracy: 0.3839 - val_loss: 2.2446\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9360 - loss: 0.1467 - val_accuracy: 0.9735 - val_loss: 0.0788\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9515 - loss: 0.1172 - val_accuracy: 0.9603 - val_loss: 0.0890\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9568 - loss: 0.1009 - val_accuracy: 0.9598 - val_loss: 0.0867\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9673 - loss: 0.0842 - val_accuracy: 0.9248 - val_loss: 0.1485\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9701 - loss: 0.0760 - val_accuracy: 0.9154 - val_loss: 0.2133\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9731 - loss: 0.0666 - val_accuracy: 0.8426 - val_loss: 0.4443\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9755 - loss: 0.0618 - val_accuracy: 0.8747 - val_loss: 0.3484\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9814 - loss: 0.0505 - val_accuracy: 0.8936 - val_loss: 0.2649\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9825 - loss: 0.0463 - val_accuracy: 0.7858 - val_loss: 0.9882\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9853 - loss: 0.0413 - val_accuracy: 0.7905 - val_loss: 0.7339\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9855 - loss: 0.0394 - val_accuracy: 0.8066 - val_loss: 0.7024\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9872 - loss: 0.0373 - val_accuracy: 0.7655 - val_loss: 0.8862\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9903 - loss: 0.0306 - val_accuracy: 0.7957 - val_loss: 0.9837\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0324 - val_accuracy: 0.7579 - val_loss: 1.4429\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9901 - loss: 0.0260 - val_accuracy: 0.8449 - val_loss: 0.6553\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0217 - val_accuracy: 0.7948 - val_loss: 1.1077\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0233 - val_accuracy: 0.7560 - val_loss: 1.5248\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.7887 - val_loss: 1.4373\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0192 - val_accuracy: 0.8851 - val_loss: 0.6165\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0124 - val_accuracy: 0.9305 - val_loss: 0.3233\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0129 - val_accuracy: 0.9125 - val_loss: 0.3880\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9962 - loss: 0.0146 - val_accuracy: 0.9135 - val_loss: 0.3586\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0125 - val_accuracy: 0.9097 - val_loss: 0.5655\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0108 - val_accuracy: 0.9277 - val_loss: 0.3763\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.8511 - val_loss: 0.7462\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0053 - val_accuracy: 0.9054 - val_loss: 0.4684\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0073 - val_accuracy: 0.8827 - val_loss: 0.5224\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9966 - loss: 0.0122 - val_accuracy: 0.9442 - val_loss: 0.2065\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.9560 - val_loss: 0.1812\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.6775 - val_loss: 2.4656\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9897 - loss: 0.0324 - val_accuracy: 0.9773 - val_loss: 0.0749\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0081 - val_accuracy: 0.9759 - val_loss: 0.0807\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9787 - val_loss: 0.0699\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.9064 - val_loss: 0.8329\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 0.9948 - val_loss: 0.0223\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9593 - val_loss: 0.1640\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0147 - val_accuracy: 0.9976 - val_loss: 0.0062\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.8563 - val_loss: 0.9337\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 0.9910 - val_loss: 0.0255\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9953 - val_loss: 0.0134\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9891 - val_loss: 0.0333\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0173 - val_accuracy: 0.9811 - val_loss: 0.0630\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.8577 - val_loss: 0.9318\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9764 - val_loss: 0.0778\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9957 - val_loss: 0.0086\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9040 - val_loss: 1.3134\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0091 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.8794 - val_loss: 1.2019\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 0.9953 - val_loss: 0.0115\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9965 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 7.7757e-04 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 6.5164e-04 - val_accuracy: 0.9981 - val_loss: 0.0065\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.5511e-04 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.4825e-04 - val_accuracy: 0.9991 - val_loss: 0.0027\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.8667e-04 - val_accuracy: 0.9905 - val_loss: 0.0371\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9844 - loss: 0.0462 - val_accuracy: 0.9343 - val_loss: 0.2993\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9953 - val_loss: 0.0139\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9934 - val_loss: 0.0248\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9987 - loss: 0.0052 - val_accuracy: 0.9863 - val_loss: 0.0494\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.6349e-04 - val_accuracy: 0.9991 - val_loss: 0.0023\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.4858e-04 - val_accuracy: 0.9910 - val_loss: 0.0355\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0019 - val_accuracy: 0.9896 - val_loss: 0.0292\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.8506 - val_loss: 1.3556\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9858 - val_loss: 0.0431\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0068 - val_accuracy: 0.9986 - val_loss: 0.0040\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9991 - val_loss: 0.0023\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9792 - val_loss: 0.0945\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9915 - val_loss: 0.0282\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9979 - loss: 0.0049 - val_accuracy: 0.9981 - val_loss: 0.0126\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.9513 - val_loss: 0.2690\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9981 - val_loss: 0.0041\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9991 - val_loss: 0.0046\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 7.8186e-04 - val_accuracy: 0.9981 - val_loss: 0.0052\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9608 - val_loss: 0.1825\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9182 - val_loss: 0.5928\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9976 - val_loss: 0.0092\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9986 - val_loss: 0.0032\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.7115e-04 - val_accuracy: 0.9158 - val_loss: 0.6043\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9926 - loss: 0.0213 - val_accuracy: 0.9905 - val_loss: 0.0238\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0043 - val_accuracy: 0.9981 - val_loss: 0.0050\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9967 - val_loss: 0.0094\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9948 - val_loss: 0.0161\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.2395e-04 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.4959e-04 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 4.4612e-04 - val_accuracy: 0.9929 - val_loss: 0.0286\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.8473 - val_loss: 1.8315\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.9300 - val_loss: 0.4072\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.9527 - val_loss: 0.3605\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9929 - val_loss: 0.0236\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9972 - val_loss: 0.0120\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9972 - val_loss: 0.0073\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.7279e-04 - val_accuracy: 0.9868 - val_loss: 0.0521\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.8846 - val_loss: 0.5709\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9904 - loss: 0.0386 - val_accuracy: 0.9981 - val_loss: 0.0059\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9910 - val_loss: 0.0266\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.9972 - val_loss: 0.0135\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 9.3458e-04 - val_accuracy: 0.9981 - val_loss: 0.0059\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0024 - val_accuracy: 0.9948 - val_loss: 0.0306\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0040 - val_accuracy: 0.9726 - val_loss: 0.1673\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0039 - val_accuracy: 0.9920 - val_loss: 0.0246\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0062 - val_accuracy: 0.9976 - val_loss: 0.0069\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9915 - val_loss: 0.0376\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.2223e-04 - val_accuracy: 0.9981 - val_loss: 0.0099\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.6524e-04 - val_accuracy: 0.9981 - val_loss: 0.0062\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 9.3107e-04 - val_accuracy: 0.9986 - val_loss: 0.0039\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 4.6045e-04 - val_accuracy: 0.9976 - val_loss: 0.0092\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.6814e-04 - val_accuracy: 0.9381 - val_loss: 0.3747\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 9.2249e-04 - val_accuracy: 0.9991 - val_loss: 0.0056\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.3304e-04 - val_accuracy: 0.9991 - val_loss: 0.0052\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0227 - val_accuracy: 0.8794 - val_loss: 1.0390\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.9995 - val_loss: 0.0043\n",
      "Epoch 119/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.9972 - val_loss: 0.0133\n",
      "Epoch 120/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 4.2504e-04 - val_accuracy: 0.9220 - val_loss: 0.3510\n",
      "Epoch 121/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0116 - val_accuracy: 0.9749 - val_loss: 0.1394\n",
      "Epoch 122/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9991 - val_loss: 0.0048\n",
      "Epoch 123/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 7.2611e-04 - val_accuracy: 0.9995 - val_loss: 0.0038\n",
      "Epoch 124/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 5.6907e-04 - val_accuracy: 0.9991 - val_loss: 0.0039\n",
      "Epoch 125/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6445e-04 - val_accuracy: 0.9986 - val_loss: 0.0037\n",
      "Epoch 126/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.0116e-04 - val_accuracy: 0.9995 - val_loss: 0.0038\n",
      "Epoch 127/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9882 - val_loss: 0.0358\n",
      "Epoch 128/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9939 - val_loss: 0.0198\n",
      "Epoch 129/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.6727e-04 - val_accuracy: 0.9986 - val_loss: 0.0030\n",
      "Epoch 130/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 3.3631e-04 - val_accuracy: 0.9981 - val_loss: 0.0057\n",
      "Epoch 131/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 8.0928e-04 - val_accuracy: 0.9981 - val_loss: 0.0092\n",
      "Epoch 132/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9641 - val_loss: 0.1281\n",
      "Epoch 133/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0218 - val_accuracy: 0.9924 - val_loss: 0.0248\n",
      "Epoch 134/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.7996e-04 - val_accuracy: 0.9991 - val_loss: 0.0040\n",
      "Epoch 135/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.8535e-04 - val_accuracy: 0.9929 - val_loss: 0.0297\n",
      "Epoch 136/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 6.5772e-04 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 137/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9915 - val_loss: 0.0322\n",
      "Epoch 138/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 0.8875 - val_loss: 0.7557\n",
      "Epoch 139/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0039 - val_accuracy: 0.9976 - val_loss: 0.0090\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.7708 - loss: 0.4973 - val_accuracy: 0.3267 - val_loss: 4.0056\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2127 - val_accuracy: 0.5173 - val_loss: 1.3017\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9294 - loss: 0.1606 - val_accuracy: 0.9423 - val_loss: 0.1114\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9479 - loss: 0.1271 - val_accuracy: 0.9522 - val_loss: 0.0886\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9559 - loss: 0.1073 - val_accuracy: 0.9631 - val_loss: 0.0807\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9637 - loss: 0.0930 - val_accuracy: 0.9626 - val_loss: 0.0743\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9704 - loss: 0.0782 - val_accuracy: 0.9882 - val_loss: 0.0433\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9725 - loss: 0.0705 - val_accuracy: 0.9929 - val_loss: 0.0310\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9747 - loss: 0.0652 - val_accuracy: 0.9863 - val_loss: 0.0425\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9767 - loss: 0.0599 - val_accuracy: 0.9466 - val_loss: 0.1125\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9785 - loss: 0.0542 - val_accuracy: 0.9863 - val_loss: 0.0400\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0417 - val_accuracy: 0.9943 - val_loss: 0.0195\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9841 - loss: 0.0418 - val_accuracy: 0.9650 - val_loss: 0.0813\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0359 - val_accuracy: 0.9631 - val_loss: 0.0903\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9895 - loss: 0.0297 - val_accuracy: 0.9546 - val_loss: 0.1116\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9945 - loss: 0.0213 - val_accuracy: 0.9759 - val_loss: 0.0504\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.0200 - val_accuracy: 0.9967 - val_loss: 0.0126\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9921 - loss: 0.0227 - val_accuracy: 0.9702 - val_loss: 0.1259\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9925 - loss: 0.0229 - val_accuracy: 0.9882 - val_loss: 0.0408\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0224 - val_accuracy: 0.9173 - val_loss: 0.3175\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9942 - loss: 0.0171 - val_accuracy: 0.8913 - val_loss: 0.4894\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9944 - loss: 0.0177 - val_accuracy: 0.9177 - val_loss: 0.2695\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9945 - loss: 0.0139 - val_accuracy: 0.9371 - val_loss: 0.1800\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.9584 - val_loss: 0.1368\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9868 - val_loss: 0.0401\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9929 - loss: 0.0182 - val_accuracy: 0.9664 - val_loss: 0.1166\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0104 - val_accuracy: 0.9901 - val_loss: 0.0352\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0060 - val_accuracy: 0.8676 - val_loss: 0.4977\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.9962 - val_loss: 0.0112\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.9820 - val_loss: 0.0578\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9882 - val_loss: 0.0462\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9853 - val_loss: 0.0705\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.9825 - val_loss: 0.0730\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.9603 - val_loss: 0.1377\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.9929 - val_loss: 0.0246\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9726 - val_loss: 0.0856\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9948 - val_loss: 0.0221\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9967 - val_loss: 0.0093\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.9976 - val_loss: 0.0096\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9986 - val_loss: 0.0051\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9872 - val_loss: 0.0324\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9934 - val_loss: 0.0209\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9962 - val_loss: 0.0121\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.9806 - val_loss: 0.1008\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9976 - val_loss: 0.0046\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0092 - val_accuracy: 0.9910 - val_loss: 0.0258\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.8879 - val_loss: 0.6334\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9972 - val_loss: 0.0119\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9768 - val_loss: 0.0985\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9943 - val_loss: 0.0221\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9957 - val_loss: 0.0131\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9957 - val_loss: 0.0145\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.5793e-04 - val_accuracy: 0.9981 - val_loss: 0.0055\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.6856 - val_loss: 4.4376\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0043 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9967 - val_loss: 0.0148\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9920 - val_loss: 0.0215\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9797 - val_loss: 0.0827\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9920 - val_loss: 0.0310\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9357 - val_loss: 0.2669\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 6.5420e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9981 - val_loss: 0.0041\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.5507e-04 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.1626e-04 - val_accuracy: 1.0000 - val_loss: 1.7361e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.9067e-04 - val_accuracy: 0.9991 - val_loss: 0.0013\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.8861 - val_loss: 1.5981\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 0.8194 - val_loss: 1.9921\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9956 - loss: 0.0102 - val_accuracy: 0.9948 - val_loss: 0.0198\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9986 - val_loss: 0.0021\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 8.4143e-04 - val_accuracy: 0.9991 - val_loss: 0.0026\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 5.9186e-04 - val_accuracy: 0.9858 - val_loss: 0.0399\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0035 - val_accuracy: 0.9986 - val_loss: 0.0046\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.7345e-04 - val_accuracy: 0.9986 - val_loss: 0.0028\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 8.2312e-04 - val_accuracy: 0.9678 - val_loss: 0.2160\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.8752 - val_loss: 0.8491\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0024 - val_accuracy: 0.9976 - val_loss: 0.0080\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9119e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 7.5153e-04 - val_accuracy: 0.9920 - val_loss: 0.0417\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9976 - val_loss: 0.0087\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 8.9982e-04 - val_accuracy: 0.9674 - val_loss: 0.1839\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9961 - loss: 0.0123 - val_accuracy: 0.9816 - val_loss: 0.0674\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9948 - val_loss: 0.0210\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9915 - val_loss: 0.0346\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.6307e-04 - val_accuracy: 0.9991 - val_loss: 0.0017\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9348 - val_loss: 0.4780\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.0361e-04 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6932e-04 - val_accuracy: 0.9991 - val_loss: 0.0017\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.9073e-04 - val_accuracy: 1.0000 - val_loss: 4.1936e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.5156e-04 - val_accuracy: 0.9598 - val_loss: 0.1508\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.8591 - val_loss: 0.5235\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.9806 - val_loss: 0.0779\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9981 - val_loss: 0.0041\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.9468e-04 - val_accuracy: 0.9995 - val_loss: 7.4068e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.2021e-04 - val_accuracy: 0.9995 - val_loss: 5.1843e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9891 - val_loss: 0.0269\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9730 - val_loss: 0.1239\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9835 - val_loss: 0.0659\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 7.8219e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.4035e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.4188e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.5135e-04 - val_accuracy: 0.9995 - val_loss: 9.4157e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 6.4162e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 3.5764e-04 - val_accuracy: 0.9995 - val_loss: 5.6855e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.3784e-05 - val_accuracy: 0.9967 - val_loss: 0.0113\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.8771 - val_loss: 0.7263\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 7.4844e-04 - val_accuracy: 0.9991 - val_loss: 0.0012\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.8809e-04 - val_accuracy: 1.0000 - val_loss: 1.9077e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.8652e-04 - val_accuracy: 0.9981 - val_loss: 0.0027\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0749e-04 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5423e-04 - val_accuracy: 0.9986 - val_loss: 0.0023\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3706e-04 - val_accuracy: 0.9995 - val_loss: 6.4091e-04\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7642 - loss: 0.5243 - val_accuracy: 0.3267 - val_loss: 3.6279\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9202 - loss: 0.2017 - val_accuracy: 0.3891 - val_loss: 1.6601\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9363 - loss: 0.1585 - val_accuracy: 0.9305 - val_loss: 0.1549\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9436 - loss: 0.1388 - val_accuracy: 0.9371 - val_loss: 0.1274\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9479 - loss: 0.1229 - val_accuracy: 0.9508 - val_loss: 0.0848\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9549 - loss: 0.1101 - val_accuracy: 0.9442 - val_loss: 0.1012\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9531 - loss: 0.1030 - val_accuracy: 0.9447 - val_loss: 0.0997\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9523 - loss: 0.1026 - val_accuracy: 0.9385 - val_loss: 0.1272\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9621 - loss: 0.0912 - val_accuracy: 0.9447 - val_loss: 0.1104\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9681 - loss: 0.0847 - val_accuracy: 0.9423 - val_loss: 0.1164\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9685 - loss: 0.0813 - val_accuracy: 0.9574 - val_loss: 0.0773\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9731 - loss: 0.0750 - val_accuracy: 0.9565 - val_loss: 0.0815\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9765 - loss: 0.0623 - val_accuracy: 0.9608 - val_loss: 0.0711\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9815 - loss: 0.0555 - val_accuracy: 0.9972 - val_loss: 0.0180\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0447 - val_accuracy: 0.9910 - val_loss: 0.0225\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9881 - loss: 0.0367 - val_accuracy: 0.9754 - val_loss: 0.0466\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9867 - loss: 0.0394 - val_accuracy: 0.9693 - val_loss: 0.0669\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0266 - val_accuracy: 0.9939 - val_loss: 0.0176\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9935 - loss: 0.0218 - val_accuracy: 0.9934 - val_loss: 0.0163\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0184 - val_accuracy: 0.9986 - val_loss: 0.0067\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0184 - val_accuracy: 0.9872 - val_loss: 0.0271\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0146 - val_accuracy: 0.9905 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.9603 - val_loss: 0.1220\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.9981 - val_loss: 0.0075\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.9976 - val_loss: 0.0115\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9946 - loss: 0.0132 - val_accuracy: 0.9981 - val_loss: 0.0069\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.9986 - val_loss: 0.0058\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9967 - val_loss: 0.0076\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9969 - loss: 0.0080 - val_accuracy: 0.9806 - val_loss: 0.0443\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0076 - val_accuracy: 0.9976 - val_loss: 0.0095\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0131 - val_accuracy: 0.9518 - val_loss: 0.2064\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0117 - val_accuracy: 0.9986 - val_loss: 0.0035\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9972 - val_loss: 0.0081\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9959 - loss: 0.0120 - val_accuracy: 0.9986 - val_loss: 0.0043\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0043 - val_accuracy: 0.9693 - val_loss: 0.0754\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9981 - val_loss: 0.0052\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0087 - val_accuracy: 0.9740 - val_loss: 0.0942\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9976 - val_loss: 0.0050\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9674 - val_loss: 0.1458\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.9924 - val_loss: 0.0150\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9991 - val_loss: 0.0013\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0056 - val_accuracy: 0.9887 - val_loss: 0.0342\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9423 - val_loss: 0.2933\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9948 - val_loss: 0.0159\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.9986 - val_loss: 0.0037\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9792 - val_loss: 0.0842\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9986 - val_loss: 0.0025\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0074 - val_accuracy: 0.9868 - val_loss: 0.0406\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9981 - val_loss: 0.0027\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 3.0136e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 9.1575e-04 - val_accuracy: 1.0000 - val_loss: 4.3977e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0033 - val_accuracy: 0.9806 - val_loss: 0.0757\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0027 - val_accuracy: 0.9991 - val_loss: 0.0019\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.9991 - val_loss: 0.0047\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.3040e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9963 - loss: 0.0122 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.9934 - val_loss: 0.0176\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9934 - val_loss: 0.0195\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0065 - val_accuracy: 0.9125 - val_loss: 0.3795\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9986 - val_loss: 0.0055\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 9.5974e-04 - val_accuracy: 0.9839 - val_loss: 0.0588\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9929 - val_loss: 0.0173\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.9128e-04 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9986 - val_loss: 0.0024\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.8175e-04 - val_accuracy: 0.9991 - val_loss: 0.0030\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.5907e-04 - val_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 6.7932e-04 - val_accuracy: 0.9910 - val_loss: 0.0395\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.0952e-04 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.8648 - val_loss: 1.1434\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 0.9801 - val_loss: 0.0779\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9965 - loss: 0.0094 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9839 - val_loss: 0.0487\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0033\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 5.1205e-04 - val_accuracy: 0.9972 - val_loss: 0.0063\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.0658e-04 - val_accuracy: 0.9825 - val_loss: 0.0661\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.7930e-04 - val_accuracy: 0.9872 - val_loss: 0.0370\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9660 - val_loss: 0.0987\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 0.9995 - val_loss: 0.0036\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.7172e-04 - val_accuracy: 1.0000 - val_loss: 6.4493e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.7162e-04 - val_accuracy: 0.9995 - val_loss: 4.6824e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.8805e-04 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.9910 - val_loss: 0.0259\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9962 - val_loss: 0.0104\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9920 - val_loss: 0.0270\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9976 - loss: 0.0052 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0049 - val_accuracy: 0.9953 - val_loss: 0.0120\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.7266e-04 - val_accuracy: 0.9995 - val_loss: 8.6094e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 6.2521e-04 - val_accuracy: 0.9995 - val_loss: 7.2218e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1521e-04 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.2368e-04 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3984e-04 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5141e-04 - val_accuracy: 0.9981 - val_loss: 0.0054\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0701e-04 - val_accuracy: 0.9267 - val_loss: 0.4490\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9946 - loss: 0.0207 - val_accuracy: 0.9905 - val_loss: 0.0257\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9995 - val_loss: 0.0023\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9910 - val_loss: 0.0326\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Total Computation Time: 4339.07 seconds (72.32 minutes)\n",
      "Train Accuracy: 99.99%\n",
      "Test Accuracy: 99.92%\n",
      "Train Precision: 99.99%\n",
      "Test Precision: 99.92%\n",
      "Train Recall: 99.99%\n",
      "Test Recall: 99.92%\n",
      "Train Log Loss: 0.0006\n",
      "Test Log Loss: 0.0023\n",
      "Train Balanced Accuracy: 99.99%\n",
      "Test Balanced Accuracy: 99.92%\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, confusion_matrix\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import time\n",
    "\n",
    "# Set seed for reproducibility\n",
    "sd = 1  # Seed value\n",
    "os.environ['PYTHONHASHSEED'] = str(sd)\n",
    "np.random.seed(sd)\n",
    "rn.seed(sd)\n",
    "tf.random.set_seed(sd)\n",
    "\n",
    "\n",
    "# Modified load data function\n",
    "def load_data(folder):\n",
    "    data_list = []\n",
    "\n",
    "    for label in range(3):\n",
    "        if label == 0:\n",
    "            filename = f\"PaderBorn_IB_PreCase1_SetC_Label{label}.csv\"\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                signal_data = df[\"signal\"].values\n",
    "                data_list.append(signal_data)\n",
    "            else:\n",
    "                print(f\"Warning: {file_path} not found!\")\n",
    "        else:\n",
    "            all_parts = []\n",
    "            for part in range(1, 6):\n",
    "                filename = f\"PaderBorn_IB_PreCase1_Augmented_ddpm_SetC_Label{label}_Part{part}.csv\"\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                if os.path.exists(file_path):\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    signal_data = df[\"signal\"].values\n",
    "                    all_parts.append(signal_data)\n",
    "                else:\n",
    "                    print(f\"Warning: {file_path} not found!\")\n",
    "            if all_parts:\n",
    "                concatenated = np.concatenate(all_parts)\n",
    "                data_list.append(concatenated)\n",
    "            else:\n",
    "                data_list.append(np.array([]))  # In case no parts were found\n",
    "    return data_list\n",
    "\n",
    "# Usage\n",
    "folder_path = \"PaderBorn_IB_PreCase1_SetC\"\n",
    "df_signals = load_data(folder_path)\n",
    "\n",
    "\n",
    "# Sampling configuration\n",
    "interval_length = 290\n",
    "samples_per_block = 1600\n",
    "\n",
    "# Data preparation\n",
    "def Sampling(Data, interval_length, samples_per_block, ignore_points=0):\n",
    "    adjusted_length = len(Data) - 2 * ignore_points\n",
    "    No_of_blocks = (\n",
    "        round(adjusted_length / interval_length)\n",
    "        - round(samples_per_block / interval_length)\n",
    "        - 1\n",
    "    )\n",
    "    if No_of_blocks <= 0:\n",
    "        return np.empty((0, samples_per_block))\n",
    "    SplitData = np.zeros([No_of_blocks, samples_per_block])\n",
    "    for i in range(No_of_blocks):\n",
    "        start_idx = ignore_points + i * interval_length\n",
    "        SplitData[i, :] = Data[start_idx : start_idx + samples_per_block].T\n",
    "    return SplitData\n",
    "\n",
    "def DataPreparation(DataList, interval_length, samples_per_block):\n",
    "    for count, signal in enumerate(DataList):\n",
    "        SplitData = Sampling(signal, interval_length, samples_per_block)\n",
    "        if SplitData.shape[0] == 0:\n",
    "            continue\n",
    "        y = np.zeros([len(SplitData), len(DataList)])\n",
    "        y[:, count] = 1\n",
    "        y1 = np.zeros([len(SplitData), 1])\n",
    "        y1[:, 0] = count\n",
    "        if count == 0:\n",
    "            X = SplitData\n",
    "            LabelPositional = y\n",
    "            Label = y1\n",
    "        else:\n",
    "            X = np.append(X, SplitData, axis=0)\n",
    "            LabelPositional = np.append(LabelPositional, y, axis=0)\n",
    "            Label = np.append(Label, y1, axis=0)\n",
    "    return X, LabelPositional, Label\n",
    "\n",
    "# Run preparation\n",
    "X_train, y_train_positional, y_train = DataPreparation(df_signals, interval_length, samples_per_block)\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train_split, X_test_split, y_train_positional_split, y_test_positional_split = train_test_split(\n",
    "    X_train, y_train_positional, test_size=0.2, random_state=sd, stratify=y_train)\n",
    "\n",
    "X_1D_train = X_train_split.reshape([-1, samples_per_block, 1])\n",
    "X_1D_test = X_test_split.reshape([-1, samples_per_block, 1])\n",
    "input_shape = (samples_per_block, 1)   # Reshaped input\n",
    "\n",
    "class CNN_1D():\n",
    "    def __init__(self):\n",
    "        self.model = self.CreateModel()\n",
    "        self.model.summary()\n",
    "\n",
    "    def CreateModel(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            \n",
    "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Optimizer with a slightly higher learning rate\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "# Training with k-fold validation\n",
    "kSplits = 5\n",
    "kfold = KFold(n_splits=kSplits, random_state=32, shuffle=True)\n",
    "accuracy_1D = []\n",
    "precision_1D = []\n",
    "recall_1D = []\n",
    "log_loss_1D = []\n",
    "balanced_accuracy_1D = []  # Store balanced accuracy for each fold\n",
    "accuracy_1D_test = []\n",
    "precision_1D_test = []\n",
    "recall_1D_test = []\n",
    "log_loss_1D_test = []\n",
    "balanced_accuracy_1D_test = []  # Store balanced accuracy for test set\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X_1D_train, y_train_positional_split):\n",
    "    Classification_1D = CNN_1D()\n",
    "    Classification_1D.model.fit(X_1D_train[train_idx], y_train_positional_split[train_idx],\n",
    "                                validation_data=(X_1D_train[test_idx], y_train_positional_split[test_idx]),\n",
    "                                epochs=200, callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    # Train set metrics\n",
    "    y_pred_proba_train = Classification_1D.model.predict(X_1D_train)\n",
    "    y_pred_train = np.argmax(y_pred_proba_train, axis=1)\n",
    "    y_true_train = np.argmax(y_train_positional_split, axis=1)\n",
    "\n",
    "    accuracy_1D.append(accuracy_score(y_true_train, y_pred_train))\n",
    "    precision_1D.append(precision_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    recall_1D.append(recall_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    log_loss_1D.append(log_loss(y_true_train, y_pred_proba_train))\n",
    "    balanced_accuracy_1D.append(balanced_accuracy_score(y_true_train, y_pred_train))  # Balanced accuracy for train set\n",
    "    \n",
    "    # Test set metrics\n",
    "    y_pred_proba_test = Classification_1D.model.predict(X_1D_test)\n",
    "    y_pred_test = np.argmax(y_pred_proba_test, axis=1)\n",
    "    y_true_test = np.argmax(y_test_positional_split, axis=1)\n",
    "\n",
    "    accuracy_1D_test.append(accuracy_score(y_true_test, y_pred_test))\n",
    "    precision_1D_test.append(precision_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    recall_1D_test.append(recall_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    log_loss_1D_test.append(log_loss(y_true_test, y_pred_proba_test))\n",
    "    balanced_accuracy_1D_test.append(balanced_accuracy_score(y_true_test, y_pred_test))  # Balanced accuracy for test set\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total Computation Time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "\n",
    "# Aggregated metrics\n",
    "CNN_1D_train_accuracy = np.mean(accuracy_1D) * 100\n",
    "CNN_1D_test_accuracy = np.mean(accuracy_1D_test) * 100\n",
    "CNN_1D_train_precision = np.mean(precision_1D) * 100\n",
    "CNN_1D_test_precision = np.mean(precision_1D_test) * 100\n",
    "CNN_1D_train_recall = np.mean(recall_1D) * 100\n",
    "CNN_1D_test_recall = np.mean(recall_1D_test) * 100\n",
    "CNN_1D_train_log_loss = np.mean(log_loss_1D)\n",
    "CNN_1D_test_log_loss = np.mean(log_loss_1D_test)\n",
    "CNN_1D_train_balanced_accuracy = np.mean(balanced_accuracy_1D) * 100  # Average balanced accuracy for train set\n",
    "CNN_1D_test_balanced_accuracy = np.mean(balanced_accuracy_1D_test) * 100  # Average balanced accuracy for test set\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Train Accuracy: {CNN_1D_train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {CNN_1D_test_accuracy:.2f}%\")\n",
    "print(f\"Train Precision: {CNN_1D_train_precision:.2f}%\")\n",
    "print(f\"Test Precision: {CNN_1D_test_precision:.2f}%\")\n",
    "print(f\"Train Recall: {CNN_1D_train_recall:.2f}%\")\n",
    "print(f\"Test Recall: {CNN_1D_test_recall:.2f}%\")\n",
    "print(f\"Train Log Loss: {CNN_1D_train_log_loss:.4f}\")\n",
    "print(f\"Test Log Loss: {CNN_1D_test_log_loss:.4f}\")\n",
    "print(f\"Train Balanced Accuracy: {CNN_1D_train_balanced_accuracy:.2f}%\")\n",
    "print(f\"Test Balanced Accuracy: {CNN_1D_test_balanced_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion Matrix Calculation\n",
    "# def ConfusionMatrix(Model, X, y):\n",
    "#     y_pred = np.argmax(Model.model.predict(X), axis=1)\n",
    "#     ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "#     return ConfusionMat\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "    y_pred_proba = Model.model.predict(X)  # Use Model.model instead of Model\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class labels\n",
    "    y_true = np.argmax(y, axis=1)  # Convert one-hot labels to class indices\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot results - CNN 1D\n",
    "plt.figure(1)\n",
    "plt.title('Confusion Matrix - CNN 1D Train')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_train, y_train_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Confusion Matrix - CNN 1D Test')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_test, y_test_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Train - Accuracy - CNN 1D')\n",
    "plt.bar(np.arange(1, kSplits + 1), [i * 100 for i in accuracy_1D])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70, 100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title('Train vs Test Accuracy - CNN 1D')\n",
    "plt.bar([1, 2], [CNN_1D_train_accuracy, CNN_1D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('sets')\n",
    "plt.xticks([1, 2], ['Train', 'Test'])\n",
    "plt.ylim([70, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184684ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae11f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf1847e",
   "metadata": {},
   "source": [
    "### Time-Based Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab320f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data split:\n",
      "X_train shape: (10575, 1600)\n",
      "y_train shape: (10575, 3)\n",
      "X_test shape: (2646, 1600)\n",
      "y_test shape: (2646, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.7809 - loss: 0.4867 - val_accuracy: 0.3308 - val_loss: 2.1994\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9303 - loss: 0.1679 - val_accuracy: 0.7216 - val_loss: 0.6671\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9480 - loss: 0.1319 - val_accuracy: 0.9225 - val_loss: 0.1488\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9590 - loss: 0.1062 - val_accuracy: 0.9759 - val_loss: 0.0635\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9645 - loss: 0.0897 - val_accuracy: 0.9282 - val_loss: 0.1365\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9698 - loss: 0.0780 - val_accuracy: 0.9249 - val_loss: 0.1565\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9725 - loss: 0.0709 - val_accuracy: 0.9778 - val_loss: 0.0607\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9736 - loss: 0.0642 - val_accuracy: 0.9353 - val_loss: 0.1319\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9740 - loss: 0.0608 - val_accuracy: 0.9698 - val_loss: 0.0665\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9818 - loss: 0.0489 - val_accuracy: 0.9579 - val_loss: 0.0866\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9847 - loss: 0.0413 - val_accuracy: 0.9419 - val_loss: 0.1323\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9873 - loss: 0.0368 - val_accuracy: 0.9920 - val_loss: 0.0220\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9897 - loss: 0.0316 - val_accuracy: 0.9811 - val_loss: 0.0456\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0284 - val_accuracy: 0.9820 - val_loss: 0.0461\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9928 - loss: 0.0245 - val_accuracy: 0.9882 - val_loss: 0.0317\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0224 - val_accuracy: 0.9844 - val_loss: 0.0369\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9926 - loss: 0.0235 - val_accuracy: 0.9523 - val_loss: 0.1289\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0175 - val_accuracy: 0.9806 - val_loss: 0.0493\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9956 - loss: 0.0142 - val_accuracy: 0.9872 - val_loss: 0.0301\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9881 - loss: 0.0318 - val_accuracy: 0.9778 - val_loss: 0.0572\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.9631 - val_loss: 0.1136\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0158 - val_accuracy: 0.9816 - val_loss: 0.0423\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0177 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9575 - val_loss: 0.1341\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9258 - val_loss: 0.2593\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9891 - val_loss: 0.0287\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.9849 - val_loss: 0.0395\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9835 - val_loss: 0.0387\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0140 - val_accuracy: 0.9905 - val_loss: 0.0238\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9972 - val_loss: 0.0084\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9991 - val_loss: 0.0030\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.9830 - val_loss: 0.0560\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9896 - val_loss: 0.0261\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9863 - val_loss: 0.0408\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0099 - val_accuracy: 0.9976 - val_loss: 0.0056\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9863 - val_loss: 0.0444\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9910 - val_loss: 0.0215\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0140 - val_accuracy: 0.9953 - val_loss: 0.0150\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9480 - val_loss: 0.2116\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9972 - val_loss: 0.0050\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9924 - val_loss: 0.0250\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9924 - val_loss: 0.0232\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9976 - val_loss: 0.0068\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9906 - loss: 0.0317 - val_accuracy: 0.9608 - val_loss: 0.1332\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9560 - val_loss: 0.1791\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9976 - val_loss: 0.0057\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9674 - val_loss: 0.1239\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9986 - val_loss: 0.0021\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9986 - val_loss: 0.0031\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9792 - val_loss: 0.0564\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0023 - val_accuracy: 0.9792 - val_loss: 0.0679\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9967 - val_loss: 0.0126\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 9.6056e-04 - val_accuracy: 0.9967 - val_loss: 0.0092\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9050 - val_loss: 0.7224\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0027 - val_accuracy: 0.9929 - val_loss: 0.0262\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9698 - val_loss: 0.1187\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9853 - val_loss: 0.0551\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8984 - val_loss: 0.9915\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0072 - val_accuracy: 0.9934 - val_loss: 0.0216\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9976 - val_loss: 0.0067\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9664 - val_loss: 0.1146\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9825 - val_loss: 0.0565\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9981 - val_loss: 0.0044\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9438 - val_loss: 0.2942\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.9976 - val_loss: 0.0061\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9868 - val_loss: 0.0431\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.9910 - val_loss: 0.0325\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0044 - val_accuracy: 0.9981 - val_loss: 0.0055\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9981 - val_loss: 0.0059\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.7614e-04 - val_accuracy: 0.9986 - val_loss: 0.0051\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9934 - val_loss: 0.0197\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 0.9962 - val_loss: 0.0119\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0017 - val_accuracy: 0.9972 - val_loss: 0.0075\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.9858 - val_loss: 0.0484\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9972 - val_loss: 0.0089\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.7945e-04 - val_accuracy: 0.9972 - val_loss: 0.0058\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 6.2465e-04 - val_accuracy: 0.9976 - val_loss: 0.0092\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 4.0771e-04 - val_accuracy: 0.9981 - val_loss: 0.0049\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0059 - val_accuracy: 0.9627 - val_loss: 0.1379\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9759 - val_loss: 0.1045\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9768 - val_loss: 0.1041\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9972 - val_loss: 0.0071\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9967 - val_loss: 0.0070\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 7.0193e-04 - val_accuracy: 0.9986 - val_loss: 0.0035\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 7.3318e-04 - val_accuracy: 0.9976 - val_loss: 0.0067\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9083 - val_loss: 0.4178\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9957 - val_loss: 0.0134\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 9.6484e-04 - val_accuracy: 0.9598 - val_loss: 0.1964\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9872 - val_loss: 0.0593\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.9471 - val_loss: 0.3106\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9981 - val_loss: 0.0053\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.7275e-04 - val_accuracy: 0.9976 - val_loss: 0.0077\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2319e-04 - val_accuracy: 0.9981 - val_loss: 0.0048\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9651e-04 - val_accuracy: 0.9986 - val_loss: 0.0025\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3279e-04 - val_accuracy: 0.9920 - val_loss: 0.0301\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.5217 - val_loss: 10.5203\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0116 - val_accuracy: 0.9802 - val_loss: 0.0795\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9962 - val_loss: 0.0097\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.7830 - loss: 0.4856 - val_accuracy: 0.3243 - val_loss: 3.1082\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9259 - loss: 0.1802 - val_accuracy: 0.6066 - val_loss: 1.2213\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9456 - loss: 0.1386 - val_accuracy: 0.9697 - val_loss: 0.0939\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9535 - loss: 0.1155 - val_accuracy: 0.9522 - val_loss: 0.0870\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9561 - loss: 0.1065 - val_accuracy: 0.9546 - val_loss: 0.0805\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9615 - loss: 0.0952 - val_accuracy: 0.9778 - val_loss: 0.0557\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9659 - loss: 0.0804 - val_accuracy: 0.9863 - val_loss: 0.0448\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.0810 - val_accuracy: 0.9749 - val_loss: 0.0568\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9720 - loss: 0.0677 - val_accuracy: 0.9901 - val_loss: 0.0357\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9723 - loss: 0.0659 - val_accuracy: 0.9910 - val_loss: 0.0307\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9770 - loss: 0.0584 - val_accuracy: 0.9835 - val_loss: 0.0423\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9780 - loss: 0.0525 - val_accuracy: 0.9872 - val_loss: 0.0350\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9837 - loss: 0.0476 - val_accuracy: 0.9891 - val_loss: 0.0323\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9846 - loss: 0.0415 - val_accuracy: 0.9905 - val_loss: 0.0280\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9849 - loss: 0.0369 - val_accuracy: 0.9863 - val_loss: 0.0327\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9892 - loss: 0.0318 - val_accuracy: 0.9877 - val_loss: 0.0310\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0291 - val_accuracy: 0.9811 - val_loss: 0.0464\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0241 - val_accuracy: 0.9915 - val_loss: 0.0231\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9935 - loss: 0.0182 - val_accuracy: 0.9839 - val_loss: 0.0510\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0176 - val_accuracy: 0.9872 - val_loss: 0.0317\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.9962 - val_loss: 0.0112\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0199 - val_accuracy: 0.9395 - val_loss: 0.1913\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0146 - val_accuracy: 0.9962 - val_loss: 0.0104\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9940 - loss: 0.0167 - val_accuracy: 0.9948 - val_loss: 0.0146\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.9957 - val_loss: 0.0106\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.9797 - val_loss: 0.0598\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0104 - val_accuracy: 0.9967 - val_loss: 0.0077\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0182 - val_accuracy: 0.9882 - val_loss: 0.0323\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0092 - val_accuracy: 0.9967 - val_loss: 0.0083\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9825 - val_loss: 0.0529\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9976 - val_loss: 0.0090\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9934 - val_loss: 0.0199\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9976 - val_loss: 0.0046\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.9962 - val_loss: 0.0136\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9603 - val_loss: 0.1652\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9972 - val_loss: 0.0070\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9953 - val_loss: 0.0121\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0110 - val_accuracy: 0.9967 - val_loss: 0.0088\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9253 - val_loss: 0.2290\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9839 - val_loss: 0.0580\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9943 - val_loss: 0.0167\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9991 - val_loss: 0.0034\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0028 - val_accuracy: 0.9366 - val_loss: 0.3659\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9981 - val_loss: 0.0061\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9991 - val_loss: 0.0035\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9986 - val_loss: 0.0034\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.6321e-04 - val_accuracy: 0.9995 - val_loss: 0.0017\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0036 - val_accuracy: 0.9229 - val_loss: 0.3835\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9872 - loss: 0.0518 - val_accuracy: 0.9981 - val_loss: 0.0075\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9991 - val_loss: 0.0019\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9995 - val_loss: 0.0028\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9976 - val_loss: 0.0061\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9972 - val_loss: 0.0116\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9981 - val_loss: 0.0061\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9986 - val_loss: 0.0033\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9754 - val_loss: 0.1176\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 7.8783e-04 - val_accuracy: 0.9995 - val_loss: 0.0029\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0091 - val_accuracy: 0.8676 - val_loss: 0.5463\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.9976 - val_loss: 0.0099\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9972 - val_loss: 0.0106\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9991 - val_loss: 0.0032\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9976 - val_loss: 0.0062\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 9.2493e-04 - val_accuracy: 0.9976 - val_loss: 0.0075\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 8.8512e-04 - val_accuracy: 0.9976 - val_loss: 0.0084\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.9967 - val_loss: 0.0166\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9693 - val_loss: 0.0890\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9816 - val_loss: 0.0567\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.1805e-04 - val_accuracy: 0.9991 - val_loss: 0.0040\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 9.6277e-04 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.0997e-04 - val_accuracy: 0.9991 - val_loss: 0.0027\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9967 - val_loss: 0.0105\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9986 - val_loss: 0.0060\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0075 - val_accuracy: 0.9948 - val_loss: 0.0199\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 9.7846e-04 - val_accuracy: 0.9924 - val_loss: 0.0317\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0049 - val_accuracy: 0.9976 - val_loss: 0.0120\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.7908e-04 - val_accuracy: 0.9976 - val_loss: 0.0085\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.7872e-04 - val_accuracy: 0.9986 - val_loss: 0.0037\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.8525e-04 - val_accuracy: 0.9726 - val_loss: 0.0896\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9872 - val_loss: 0.0510\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9872 - val_loss: 0.0459\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9296 - val_loss: 0.4683\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9943 - val_loss: 0.0191\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 6.0075e-04 - val_accuracy: 0.9972 - val_loss: 0.0076\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.8833e-04 - val_accuracy: 0.9976 - val_loss: 0.0072\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9021 - val_loss: 1.4471\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0206 - val_accuracy: 0.9991 - val_loss: 0.0060\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9976 - val_loss: 0.0066\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6741e-04 - val_accuracy: 0.9953 - val_loss: 0.0137\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.4830e-04 - val_accuracy: 0.9972 - val_loss: 0.0060\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9986 - val_loss: 0.0043\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9957 - val_loss: 0.0190\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 9.6149e-04 - val_accuracy: 0.9858 - val_loss: 0.0564\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9972 - val_loss: 0.0116\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0064 - val_accuracy: 0.9981 - val_loss: 0.0054\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 8.4330e-04 - val_accuracy: 0.9508 - val_loss: 0.2106\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9986 - val_loss: 0.0073\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_21 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_22 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_23 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7643 - loss: 0.5196 - val_accuracy: 0.3655 - val_loss: 0.9608\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9263 - loss: 0.1824 - val_accuracy: 0.7087 - val_loss: 0.5608\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9405 - loss: 0.1426 - val_accuracy: 0.9357 - val_loss: 0.1316\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.1139 - val_accuracy: 0.9764 - val_loss: 0.0795\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9633 - loss: 0.0901 - val_accuracy: 0.9636 - val_loss: 0.0830\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9686 - loss: 0.0794 - val_accuracy: 0.8988 - val_loss: 0.2694\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9737 - loss: 0.0650 - val_accuracy: 0.9182 - val_loss: 0.1625\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9761 - loss: 0.0606 - val_accuracy: 0.8979 - val_loss: 0.2594\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9800 - loss: 0.0508 - val_accuracy: 0.8312 - val_loss: 0.5796\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.9824 - loss: 0.0437 - val_accuracy: 0.7745 - val_loss: 1.0720\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9879 - loss: 0.0343 - val_accuracy: 0.7943 - val_loss: 0.8332\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.7887 - val_loss: 0.9612\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0283 - val_accuracy: 0.8019 - val_loss: 0.9787\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0237 - val_accuracy: 0.8960 - val_loss: 0.3576\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0324 - val_accuracy: 0.8652 - val_loss: 0.5110\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0189 - val_accuracy: 0.8766 - val_loss: 0.4201\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0128 - val_accuracy: 0.9017 - val_loss: 0.3492\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.9083 - val_loss: 0.3229\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9702 - val_loss: 0.0705\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.9943 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9966 - loss: 0.0123 - val_accuracy: 0.8761 - val_loss: 0.4932\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 0.9012 - val_loss: 0.3610\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0122 - val_accuracy: 0.9948 - val_loss: 0.0152\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9972 - loss: 0.0097 - val_accuracy: 0.9371 - val_loss: 0.2405\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.9962 - val_loss: 0.0102\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0132 - val_accuracy: 0.8511 - val_loss: 0.7926\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9825 - val_loss: 0.0502\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9532 - val_loss: 0.1530\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 0.9674 - val_loss: 0.0777\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.9882 - val_loss: 0.0307\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9967 - val_loss: 0.0064\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0129 - val_accuracy: 0.9957 - val_loss: 0.0124\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9959 - loss: 0.0103 - val_accuracy: 0.9683 - val_loss: 0.1034\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9957 - val_loss: 0.0097\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9896 - val_loss: 0.0264\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.8983 - val_loss: 0.5482\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9943 - val_loss: 0.0193\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9489 - val_loss: 0.2670\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9976 - val_loss: 0.0071\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9955 - loss: 0.0117 - val_accuracy: 0.8255 - val_loss: 0.9955\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9967 - val_loss: 0.0115\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9997 - loss: 0.0025 - val_accuracy: 0.9877 - val_loss: 0.0338\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.7310 - val_loss: 2.8711\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0146 - val_accuracy: 0.9939 - val_loss: 0.0193\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.9910 - val_loss: 0.0298\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0103 - val_accuracy: 0.9967 - val_loss: 0.0087\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9986 - val_loss: 0.0051\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9986 - val_loss: 0.0044\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 8.3679e-04 - val_accuracy: 0.9986 - val_loss: 0.0072\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.9385 - val_loss: 0.2729\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9939 - loss: 0.0200 - val_accuracy: 0.9872 - val_loss: 0.0543\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9678 - val_loss: 0.1387\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9986 - val_loss: 0.0058\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0036 - val_accuracy: 0.9858 - val_loss: 0.0641\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9981 - val_loss: 0.0051\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9915 - val_loss: 0.0455\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9960 - loss: 0.0146 - val_accuracy: 0.9645 - val_loss: 0.1568\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9920 - val_loss: 0.0330\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9974 - loss: 0.0057 - val_accuracy: 0.9773 - val_loss: 0.1048\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0038 - val_accuracy: 0.9981 - val_loss: 0.0037\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9991 - val_loss: 0.0045\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9962 - val_loss: 0.0133\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9934 - val_loss: 0.0288\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9981 - val_loss: 0.0091\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0020 - val_accuracy: 0.9830 - val_loss: 0.0795\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9976 - val_loss: 0.0070\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 8.1491e-04 - val_accuracy: 0.9972 - val_loss: 0.0113\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9981 - val_loss: 0.0076\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9745 - val_loss: 0.1154\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9915 - val_loss: 0.0286\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9778 - val_loss: 0.1029\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9972 - val_loss: 0.0111\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.6271e-04 - val_accuracy: 0.9986 - val_loss: 0.0063\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 4.3528e-04 - val_accuracy: 0.9986 - val_loss: 0.0058\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 9.9112e-04 - val_accuracy: 0.9872 - val_loss: 0.0515\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9918 - loss: 0.0250 - val_accuracy: 0.9948 - val_loss: 0.0200\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9962 - val_loss: 0.0158\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 9.8740e-04 - val_accuracy: 0.9920 - val_loss: 0.0270\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0024 - val_accuracy: 0.9059 - val_loss: 0.5502\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9513 - val_loss: 0.2389\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9957 - val_loss: 0.0211\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9314 - val_loss: 0.3552\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9934 - val_loss: 0.0149\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9972 - val_loss: 0.0097\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.9990e-04 - val_accuracy: 0.9995 - val_loss: 0.0038\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 2.6684e-04 - val_accuracy: 0.9962 - val_loss: 0.0090\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9811 - val_loss: 0.0808\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9863 - val_loss: 0.0493\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.7056e-04 - val_accuracy: 0.9986 - val_loss: 0.0059\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.1549e-04 - val_accuracy: 0.9995 - val_loss: 0.0017\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 9.7168e-04 - val_accuracy: 0.9981 - val_loss: 0.0067\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.8293 - val_loss: 1.4382\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0102 - val_accuracy: 0.9314 - val_loss: 0.4425\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9868 - val_loss: 0.0394\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9792 - val_loss: 0.1007\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.8420e-04 - val_accuracy: 0.9995 - val_loss: 0.0017\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1446e-04 - val_accuracy: 0.9939 - val_loss: 0.0204\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0025\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6794e-04 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0039 - val_accuracy: 0.8898 - val_loss: 0.3881\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9296 - val_loss: 0.5630\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9934 - val_loss: 0.0275\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9693 - val_loss: 0.1762\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.9976 - val_loss: 0.0106\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 8.5228e-04 - val_accuracy: 0.9953 - val_loss: 0.0164\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 7.4625e-04 - val_accuracy: 0.9995 - val_loss: 0.0036\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 9.5255e-04 - val_accuracy: 0.9995 - val_loss: 0.0043\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 4.9411e-04 - val_accuracy: 0.8809 - val_loss: 0.9058\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9792 - val_loss: 0.0941\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9707 - val_loss: 0.1329\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.9986 - val_loss: 0.0081\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3912e-04 - val_accuracy: 0.9991 - val_loss: 0.0060\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7120e-04 - val_accuracy: 0.9712 - val_loss: 0.1503\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9986 - val_loss: 0.0065\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9986 - val_loss: 0.0042\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2619e-04 - val_accuracy: 0.9991 - val_loss: 0.0042\n",
      "Epoch 119/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.0248e-04 - val_accuracy: 0.9957 - val_loss: 0.0171\n",
      "Epoch 120/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 9.3688e-04 - val_accuracy: 0.9991 - val_loss: 0.0043\n",
      "Epoch 121/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.4524e-04 - val_accuracy: 0.9986 - val_loss: 0.0042\n",
      "Epoch 122/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 3.8448e-04 - val_accuracy: 0.8340 - val_loss: 1.2963\n",
      "Epoch 123/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9929 - loss: 0.0236 - val_accuracy: 0.9986 - val_loss: 0.0093\n",
      "Epoch 124/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.5807e-04 - val_accuracy: 0.9986 - val_loss: 0.0039\n",
      "Epoch 125/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9702 - val_loss: 0.1301\n",
      "Epoch 126/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.9991 - val_loss: 0.0016\n",
      "Epoch 127/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.7537e-04 - val_accuracy: 1.0000 - val_loss: 8.9076e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.2270e-04 - val_accuracy: 0.9991 - val_loss: 0.0032\n",
      "Epoch 129/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 8.3296e-04 - val_accuracy: 0.9995 - val_loss: 7.6206e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4314e-04 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
      "Epoch 131/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.7105e-04 - val_accuracy: 0.9712 - val_loss: 0.1644\n",
      "Epoch 132/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 8.8766e-04 - val_accuracy: 0.9981 - val_loss: 0.0050\n",
      "Epoch 133/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.2120e-04 - val_accuracy: 0.9991 - val_loss: 0.0038\n",
      "Epoch 134/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.6212e-04 - val_accuracy: 0.9981 - val_loss: 0.0064\n",
      "Epoch 135/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 3.4570e-04 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 136/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9277 - val_loss: 0.5054\n",
      "Epoch 137/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9868 - val_loss: 0.0690\n",
      "Epoch 138/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9991 - val_loss: 0.0050\n",
      "Epoch 139/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0056 - val_accuracy: 0.9957 - val_loss: 0.0113\n",
      "Epoch 140/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9740 - val_loss: 0.1164\n",
      "Epoch 141/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.0959e-04 - val_accuracy: 0.9986 - val_loss: 0.0112\n",
      "Epoch 142/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 4.4465e-04 - val_accuracy: 0.9206 - val_loss: 0.5837\n",
      "Epoch 143/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9991 - val_loss: 0.0024\n",
      "Epoch 144/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0022\n",
      "Epoch 145/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.3246e-04 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
      "Epoch 146/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9986 - val_loss: 0.0075\n",
      "Epoch 147/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.1168e-04 - val_accuracy: 0.9986 - val_loss: 0.0087\n",
      "Epoch 148/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1353e-04 - val_accuracy: 0.9991 - val_loss: 0.0054\n",
      "Epoch 149/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.3467e-04 - val_accuracy: 0.8700 - val_loss: 1.5886\n",
      "Epoch 150/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9830 - val_loss: 0.0865\n",
      "Epoch 151/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0102 - val_accuracy: 0.9972 - val_loss: 0.0042\n",
      "Epoch 152/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9957 - val_loss: 0.0146\n",
      "Epoch 153/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9891 - val_loss: 0.0525\n",
      "Epoch 154/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9995 - val_loss: 0.0042\n",
      "Epoch 155/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1977e-04 - val_accuracy: 0.9995 - val_loss: 0.0050\n",
      "Epoch 156/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 7.2330e-04 - val_accuracy: 0.9995 - val_loss: 0.0041\n",
      "Epoch 157/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.3176e-04 - val_accuracy: 0.9995 - val_loss: 0.0039\n",
      "Epoch 158/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9967 - val_loss: 0.0103\n",
      "Epoch 159/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.9735 - val_loss: 0.1140\n",
      "Epoch 160/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9995 - val_loss: 0.0039\n",
      "Epoch 161/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 6.8621e-04 - val_accuracy: 0.9868 - val_loss: 0.0634\n",
      "Epoch 162/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 9.8049e-04 - val_accuracy: 0.9991 - val_loss: 0.0062\n",
      "Epoch 163/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.7530e-04 - val_accuracy: 0.9991 - val_loss: 0.0058\n",
      "Epoch 164/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7382e-04 - val_accuracy: 0.9991 - val_loss: 0.0067\n",
      "Epoch 165/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 3.9928e-04 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
      "Epoch 166/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6194e-04 - val_accuracy: 0.9995 - val_loss: 0.0023\n",
      "Epoch 167/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.0218e-04 - val_accuracy: 0.9991 - val_loss: 0.0033\n",
      "Epoch 168/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0151e-04 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
      "Epoch 169/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 8.9048e-04 - val_accuracy: 0.9991 - val_loss: 0.0048\n",
      "Epoch 170/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3433e-04 - val_accuracy: 0.9991 - val_loss: 0.0066\n",
      "Epoch 171/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9953 - val_loss: 0.0167\n",
      "Epoch 172/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9991 - val_loss: 0.0092\n",
      "Epoch 173/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.9981 - val_loss: 0.0124\n",
      "Epoch 174/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.7065e-04 - val_accuracy: 0.9991 - val_loss: 0.0097\n",
      "Epoch 175/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9806 - val_loss: 0.1173\n",
      "Epoch 176/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.1220e-04 - val_accuracy: 0.9896 - val_loss: 0.0597\n",
      "Epoch 177/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.9946e-04 - val_accuracy: 0.9929 - val_loss: 0.0267\n",
      "Epoch 178/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0037\n",
      "Epoch 179/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9806 - val_loss: 0.0952\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_24 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_25 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_26 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.7998 - loss: 0.4850 - val_accuracy: 0.3267 - val_loss: 1.9193\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9211 - loss: 0.1916 - val_accuracy: 0.6487 - val_loss: 1.0714\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9406 - loss: 0.1418 - val_accuracy: 0.9707 - val_loss: 0.0986\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9519 - loss: 0.1201 - val_accuracy: 0.9631 - val_loss: 0.0702\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9608 - loss: 0.0982 - val_accuracy: 0.9797 - val_loss: 0.0498\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9656 - loss: 0.0868 - val_accuracy: 0.9593 - val_loss: 0.0789\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9683 - loss: 0.0786 - val_accuracy: 0.9475 - val_loss: 0.1174\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9718 - loss: 0.0715 - val_accuracy: 0.9612 - val_loss: 0.0791\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9751 - loss: 0.0667 - val_accuracy: 0.9593 - val_loss: 0.0933\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9769 - loss: 0.0581 - val_accuracy: 0.9267 - val_loss: 0.1899\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9824 - loss: 0.0481 - val_accuracy: 0.9556 - val_loss: 0.1043\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9829 - loss: 0.0437 - val_accuracy: 0.9759 - val_loss: 0.0649\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0438 - val_accuracy: 0.9797 - val_loss: 0.0473\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9880 - loss: 0.0354 - val_accuracy: 0.9589 - val_loss: 0.0961\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0299 - val_accuracy: 0.9806 - val_loss: 0.0496\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0251 - val_accuracy: 0.9551 - val_loss: 0.1175\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0239 - val_accuracy: 0.9485 - val_loss: 0.1316\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9892 - loss: 0.0274 - val_accuracy: 0.9749 - val_loss: 0.0590\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9937 - loss: 0.0179 - val_accuracy: 0.9835 - val_loss: 0.0439\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9928 - loss: 0.0207 - val_accuracy: 0.9688 - val_loss: 0.0927\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0183 - val_accuracy: 0.9645 - val_loss: 0.1107\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9963 - loss: 0.0127 - val_accuracy: 0.9811 - val_loss: 0.0547\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.9664 - val_loss: 0.1133\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 0.9272 - val_loss: 0.2372\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0086 - val_accuracy: 0.9972 - val_loss: 0.0077\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0095 - val_accuracy: 0.9962 - val_loss: 0.0115\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.9598 - val_loss: 0.1513\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9797 - val_loss: 0.0713\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9863 - val_loss: 0.0432\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.9967 - val_loss: 0.0067\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9513 - val_loss: 0.2389\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9960 - loss: 0.0130 - val_accuracy: 0.8908 - val_loss: 0.6641\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.9811 - val_loss: 0.0637\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0058 - val_accuracy: 0.9735 - val_loss: 0.0763\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9882 - val_loss: 0.0433\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 0.9485 - val_loss: 0.2351\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9948 - val_loss: 0.0169\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9920 - val_loss: 0.0315\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9962 - val_loss: 0.0125\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9929 - val_loss: 0.0265\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9976 - val_loss: 0.0088\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.9962 - val_loss: 0.0143\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9933 - loss: 0.0189 - val_accuracy: 0.9641 - val_loss: 0.1603\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9962 - val_loss: 0.0092\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9943 - val_loss: 0.0144\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9929 - val_loss: 0.0306\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.9849 - val_loss: 0.0472\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 0.9570 - val_loss: 0.1960\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.9976 - val_loss: 0.0065\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.9981 - val_loss: 0.0048\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9929 - val_loss: 0.0226\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9943 - val_loss: 0.0271\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.6156 - val_loss: 2.7000\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 0.9976 - val_loss: 0.0065\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9934 - val_loss: 0.0259\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9953 - val_loss: 0.0196\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9953 - val_loss: 0.0139\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 8.1199e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.7790e-04 - val_accuracy: 0.9745 - val_loss: 0.1160\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9674 - val_loss: 0.1172\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9901 - val_loss: 0.0299\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.9678 - val_loss: 0.1760\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0024 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9986 - val_loss: 0.0024\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9678 - val_loss: 0.0939\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9942 - loss: 0.0174 - val_accuracy: 0.9868 - val_loss: 0.0434\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9976 - val_loss: 0.0106\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 7.4762e-04 - val_accuracy: 0.9991 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.4533e-04 - val_accuracy: 0.9991 - val_loss: 0.0043\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9971 - loss: 0.0067 - val_accuracy: 0.9981 - val_loss: 0.0083\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9995 - val_loss: 0.0028\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.4425e-04 - val_accuracy: 0.9972 - val_loss: 0.0088\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 5.8951e-04 - val_accuracy: 0.9972 - val_loss: 0.0153\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.5938e-04 - val_accuracy: 0.9981 - val_loss: 0.0046\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 5.9264e-04 - val_accuracy: 0.9976 - val_loss: 0.0067\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8549e-04 - val_accuracy: 0.9778 - val_loss: 0.0669\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0118 - val_accuracy: 0.9825 - val_loss: 0.0919\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9986 - val_loss: 0.0025\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.9290e-04 - val_accuracy: 0.9981 - val_loss: 0.0047\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9121 - val_loss: 0.4394\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9853 - val_loss: 0.0816\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.7693 - val_loss: 2.8251\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9986 - val_loss: 0.0031\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.4417e-04 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9986 - val_loss: 0.0060\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9981 - val_loss: 0.0062\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9972 - val_loss: 0.0056\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9943 - val_loss: 0.0179\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 7.8566e-04 - val_accuracy: 0.9721 - val_loss: 0.0986\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9972 - val_loss: 0.0170\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9981 - val_loss: 0.0046\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.6603e-04 - val_accuracy: 1.0000 - val_loss: 7.0280e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9943 - val_loss: 0.0158\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9991 - val_loss: 0.0018\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.7898e-04 - val_accuracy: 0.9981 - val_loss: 0.0064\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9835 - val_loss: 0.0547\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9957 - val_loss: 0.0099\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9920 - val_loss: 0.0322\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.2492e-04 - val_accuracy: 0.9995 - val_loss: 9.0695e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9977e-04 - val_accuracy: 0.9995 - val_loss: 8.8689e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.0059e-04 - val_accuracy: 0.9995 - val_loss: 8.6793e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0194e-04 - val_accuracy: 0.9995 - val_loss: 8.4780e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4819e-04 - val_accuracy: 0.9995 - val_loss: 0.0018\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2063e-04 - val_accuracy: 0.9995 - val_loss: 0.0023\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9963 - loss: 0.0102 - val_accuracy: 0.7887 - val_loss: 1.2132\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0176 - val_accuracy: 0.9967 - val_loss: 0.0089\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9981 - val_loss: 0.0043\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7271e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0060 - val_accuracy: 0.9764 - val_loss: 0.1008\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9986 - val_loss: 0.0029\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 8.7841e-04 - val_accuracy: 0.9981 - val_loss: 0.0048\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 9.9329e-04 - val_accuracy: 0.9991 - val_loss: 0.0038\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.2774e-04 - val_accuracy: 0.9972 - val_loss: 0.0060\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0021\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9957 - val_loss: 0.0164\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9991 - val_loss: 0.0051\n",
      "Epoch 119/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9527 - val_loss: 0.3333\n",
      "Epoch 120/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 121/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 3.8764e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.8828e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 5.0384e-04 - val_accuracy: 1.0000 - val_loss: 4.8388e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 4.2330e-04 - val_accuracy: 1.0000 - val_loss: 2.7224e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3027e-04 - val_accuracy: 1.0000 - val_loss: 4.9371e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1349e-04 - val_accuracy: 0.9589 - val_loss: 0.1668\n",
      "Epoch 127/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9966 - loss: 0.0095 - val_accuracy: 0.9986 - val_loss: 0.0045\n",
      "Epoch 128/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9995 - val_loss: 0.0021\n",
      "Epoch 129/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.0019 - val_accuracy: 0.9853 - val_loss: 0.0711\n",
      "Epoch 130/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.1028e-04 - val_accuracy: 0.9991 - val_loss: 0.0026\n",
      "Epoch 131/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 3.2359e-04 - val_accuracy: 0.9995 - val_loss: 4.5023e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9998 - loss: 7.3751e-04 - val_accuracy: 0.9981 - val_loss: 0.0079\n",
      "Epoch 133/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 134/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.2531e-04 - val_accuracy: 1.0000 - val_loss: 2.4912e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.2795e-04 - val_accuracy: 0.9995 - val_loss: 6.2996e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.2318e-04 - val_accuracy: 0.9995 - val_loss: 5.6724e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9064e-04 - val_accuracy: 0.9953 - val_loss: 0.0186\n",
      "Epoch 138/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.3322e-04 - val_accuracy: 0.9991 - val_loss: 0.0031\n",
      "Epoch 139/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3209e-04 - val_accuracy: 1.0000 - val_loss: 2.4294e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9381 - val_loss: 0.2371\n",
      "Epoch 141/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9986 - val_loss: 0.0055\n",
      "Epoch 142/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
      "Epoch 143/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 144/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.3042e-04 - val_accuracy: 0.9995 - val_loss: 0.0025\n",
      "Epoch 145/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.9340e-04 - val_accuracy: 0.9986 - val_loss: 0.0025\n",
      "Epoch 146/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3790e-04 - val_accuracy: 0.9991 - val_loss: 0.0027\n",
      "Epoch 147/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.9346e-04 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 148/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.2472e-04 - val_accuracy: 0.9948 - val_loss: 0.0223\n",
      "Epoch 149/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 7.7613e-04 - val_accuracy: 0.6265 - val_loss: 3.7968\n",
      "Epoch 150/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0117 - val_accuracy: 0.9972 - val_loss: 0.0094\n",
      "Epoch 151/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9991 - val_loss: 0.0049\n",
      "Epoch 152/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8191e-04 - val_accuracy: 0.9986 - val_loss: 0.0067\n",
      "Epoch 153/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0178e-04 - val_accuracy: 0.9939 - val_loss: 0.0182\n",
      "Epoch 154/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9961 - loss: 0.0091 - val_accuracy: 0.9991 - val_loss: 0.0033\n",
      "Epoch 155/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.0961e-04 - val_accuracy: 1.0000 - val_loss: 4.5908e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.7658e-04 - val_accuracy: 1.0000 - val_loss: 4.8601e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 2.8476e-04 - val_accuracy: 1.0000 - val_loss: 3.2637e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 4.8742e-04 - val_accuracy: 0.9470 - val_loss: 0.3599\n",
      "Epoch 159/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.9483e-04 - val_accuracy: 0.9995 - val_loss: 8.5357e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3193e-04 - val_accuracy: 0.9934 - val_loss: 0.0284\n",
      "Epoch 161/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0972e-04 - val_accuracy: 0.9995 - val_loss: 7.5101e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.3370e-04 - val_accuracy: 0.9816 - val_loss: 0.1136\n",
      "Epoch 163/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0246 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 164/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 9.9082e-04 - val_accuracy: 0.9995 - val_loss: 9.7497e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 6.8163e-04 - val_accuracy: 0.9986 - val_loss: 0.0079\n",
      "Epoch 166/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.0024e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 167/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.2924e-04 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 168/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 7.0165e-04 - val_accuracy: 0.9995 - val_loss: 0.0022\n",
      "Epoch 169/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 9.7874e-04 - val_accuracy: 0.9754 - val_loss: 0.1274\n",
      "Epoch 170/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0070 - val_accuracy: 0.9787 - val_loss: 0.0918\n",
      "Epoch 171/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9981 - val_loss: 0.0042\n",
      "Epoch 172/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.0029e-04 - val_accuracy: 0.9995 - val_loss: 7.6569e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.4301e-05 - val_accuracy: 0.9995 - val_loss: 8.8222e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.2028e-05 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
      "Epoch 175/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.8618e-05 - val_accuracy: 0.9995 - val_loss: 5.6021e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 4.7454e-04 - val_accuracy: 0.9986 - val_loss: 0.0022\n",
      "Epoch 177/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 8.7479e-04 - val_accuracy: 1.0000 - val_loss: 8.5956e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0019 - val_accuracy: 0.9849 - val_loss: 0.0564\n",
      "Epoch 179/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.7020e-04 - val_accuracy: 0.9934 - val_loss: 0.0294\n",
      "Epoch 180/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 181/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.9110e-04 - val_accuracy: 1.0000 - val_loss: 3.9119e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.2159e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.6793e-04 - val_accuracy: 1.0000 - val_loss: 3.2085e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7130e-04 - val_accuracy: 1.0000 - val_loss: 1.7107e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4075e-04 - val_accuracy: 1.0000 - val_loss: 2.6122e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.9976 - val_loss: 0.0097\n",
      "Epoch 187/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9986 - val_loss: 0.0054\n",
      "Epoch 188/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.7820e-04 - val_accuracy: 0.9995 - val_loss: 9.4608e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.0764e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 190/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9986 - val_loss: 0.0032\n",
      "Epoch 191/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6886e-04 - val_accuracy: 1.0000 - val_loss: 2.0841e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2462e-04 - val_accuracy: 1.0000 - val_loss: 1.7699e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 5.7811e-04 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 194/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9655e-04 - val_accuracy: 1.0000 - val_loss: 2.0440e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.5362e-05 - val_accuracy: 1.0000 - val_loss: 1.1760e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.3300e-05 - val_accuracy: 1.0000 - val_loss: 3.6976e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.8053e-05 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 198/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5077e-04 - val_accuracy: 1.0000 - val_loss: 5.0203e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0062 - val_accuracy: 0.9716 - val_loss: 0.1488\n",
      "Epoch 200/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_9      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_27 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_28 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_29 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_9      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,643</span> (49.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,643\u001b[0m (49.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,419</span> (48.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,419\u001b[0m (48.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.7262 - loss: 0.5724 - val_accuracy: 0.3461 - val_loss: 3.0581\n",
      "Epoch 2/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9052 - loss: 0.2220 - val_accuracy: 0.5986 - val_loss: 1.1569\n",
      "Epoch 3/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9328 - loss: 0.1675 - val_accuracy: 0.9267 - val_loss: 0.2283\n",
      "Epoch 4/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9395 - loss: 0.1423 - val_accuracy: 0.9371 - val_loss: 0.1738\n",
      "Epoch 5/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9517 - loss: 0.1195 - val_accuracy: 0.9385 - val_loss: 0.1444\n",
      "Epoch 6/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9546 - loss: 0.1087 - val_accuracy: 0.9385 - val_loss: 0.1555\n",
      "Epoch 7/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9582 - loss: 0.1022 - val_accuracy: 0.9414 - val_loss: 0.1296\n",
      "Epoch 8/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9604 - loss: 0.0975 - val_accuracy: 0.9385 - val_loss: 0.1666\n",
      "Epoch 9/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9663 - loss: 0.0887 - val_accuracy: 0.9404 - val_loss: 0.1397\n",
      "Epoch 10/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9709 - loss: 0.0762 - val_accuracy: 0.9475 - val_loss: 0.1092\n",
      "Epoch 11/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.0690 - val_accuracy: 0.9759 - val_loss: 0.0469\n",
      "Epoch 12/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9783 - loss: 0.0594 - val_accuracy: 0.9844 - val_loss: 0.0344\n",
      "Epoch 13/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0571 - val_accuracy: 0.9853 - val_loss: 0.0342\n",
      "Epoch 14/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9859 - loss: 0.0411 - val_accuracy: 0.9939 - val_loss: 0.0212\n",
      "Epoch 15/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0392 - val_accuracy: 0.9565 - val_loss: 0.0929\n",
      "Epoch 16/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9917 - loss: 0.0265 - val_accuracy: 0.9806 - val_loss: 0.0535\n",
      "Epoch 17/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0256 - val_accuracy: 0.9697 - val_loss: 0.0716\n",
      "Epoch 18/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0261 - val_accuracy: 0.9697 - val_loss: 0.0714\n",
      "Epoch 19/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.9466 - val_loss: 0.1458\n",
      "Epoch 20/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0175 - val_accuracy: 0.9622 - val_loss: 0.0898\n",
      "Epoch 21/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9956 - loss: 0.0150 - val_accuracy: 0.9835 - val_loss: 0.0385\n",
      "Epoch 22/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9965 - loss: 0.0124 - val_accuracy: 0.9801 - val_loss: 0.0528\n",
      "Epoch 23/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9960 - loss: 0.0123 - val_accuracy: 0.9678 - val_loss: 0.0921\n",
      "Epoch 24/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.9868 - val_loss: 0.0332\n",
      "Epoch 25/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0088 - val_accuracy: 0.9669 - val_loss: 0.1008\n",
      "Epoch 26/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9783 - val_loss: 0.0547\n",
      "Epoch 27/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0105 - val_accuracy: 0.9877 - val_loss: 0.0327\n",
      "Epoch 28/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0113 - val_accuracy: 0.9910 - val_loss: 0.0236\n",
      "Epoch 29/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9960 - loss: 0.0100 - val_accuracy: 0.9735 - val_loss: 0.0734\n",
      "Epoch 30/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0092 - val_accuracy: 0.9173 - val_loss: 0.3757\n",
      "Epoch 31/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.8761 - val_loss: 0.6893\n",
      "Epoch 32/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.9650 - val_loss: 0.1058\n",
      "Epoch 33/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.9891 - val_loss: 0.0334\n",
      "Epoch 34/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0119 - val_accuracy: 0.9622 - val_loss: 0.1298\n",
      "Epoch 35/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0066 - val_accuracy: 0.9797 - val_loss: 0.0608\n",
      "Epoch 36/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.9981 - val_loss: 0.0062\n",
      "Epoch 37/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.9712 - val_loss: 0.0965\n",
      "Epoch 38/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.9957 - val_loss: 0.0113\n",
      "Epoch 39/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.9579 - val_loss: 0.1702\n",
      "Epoch 40/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9948 - val_loss: 0.0245\n",
      "Epoch 41/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0038 - val_accuracy: 0.9991 - val_loss: 0.0022\n",
      "Epoch 42/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0041 - val_accuracy: 0.9400 - val_loss: 0.2464\n",
      "Epoch 43/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9962 - val_loss: 0.0088\n",
      "Epoch 44/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0079 - val_accuracy: 0.9976 - val_loss: 0.0059\n",
      "Epoch 45/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9953 - val_loss: 0.0153\n",
      "Epoch 46/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9934 - val_loss: 0.0170\n",
      "Epoch 47/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9976 - val_loss: 0.0111\n",
      "Epoch 48/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0201 - val_accuracy: 0.9650 - val_loss: 0.1264\n",
      "Epoch 49/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.9641 - val_loss: 0.1348\n",
      "Epoch 50/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9962 - val_loss: 0.0088\n",
      "Epoch 51/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9967 - val_loss: 0.0080\n",
      "Epoch 52/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9953 - val_loss: 0.0124\n",
      "Epoch 53/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9953 - val_loss: 0.0137\n",
      "Epoch 54/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9991 - val_loss: 0.0023\n",
      "Epoch 55/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9962 - val_loss: 0.0141\n",
      "Epoch 56/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9976 - val_loss: 0.0062\n",
      "Epoch 57/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9948 - val_loss: 0.0157\n",
      "Epoch 58/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0111 - val_accuracy: 0.8846 - val_loss: 0.8490\n",
      "Epoch 59/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9887 - val_loss: 0.0332\n",
      "Epoch 60/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0076 - val_accuracy: 0.9811 - val_loss: 0.0802\n",
      "Epoch 61/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.9239e-04 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 62/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9997 - loss: 9.9557e-04 - val_accuracy: 0.9991 - val_loss: 0.0013\n",
      "Epoch 63/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9981 - val_loss: 0.0039\n",
      "Epoch 64/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 5.4951e-04 - val_accuracy: 1.0000 - val_loss: 2.4835e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.1722e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3022e-04 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9678 - val_loss: 0.1824\n",
      "Epoch 68/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9040 - val_loss: 0.3991\n",
      "Epoch 69/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0121 - val_accuracy: 0.9920 - val_loss: 0.0203\n",
      "Epoch 70/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9664 - val_loss: 0.1514\n",
      "Epoch 71/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9995 - val_loss: 8.0702e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9991 - val_loss: 0.0036\n",
      "Epoch 73/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9962 - val_loss: 0.0140\n",
      "Epoch 74/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 3.0579e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9882 - val_loss: 0.0371\n",
      "Epoch 76/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9678 - val_loss: 0.1911\n",
      "Epoch 77/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.9986 - val_loss: 0.0026\n",
      "Epoch 78/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 79/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9995 - val_loss: 5.9182e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.9849 - val_loss: 0.0696\n",
      "Epoch 81/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.4546e-04 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.7118e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 83/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.1343e-04 - val_accuracy: 0.9995 - val_loss: 0.0011\n",
      "Epoch 84/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9910 - val_loss: 0.0366\n",
      "Epoch 85/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.9839 - val_loss: 0.0487\n",
      "Epoch 86/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 87/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 7.5777e-04 - val_accuracy: 1.0000 - val_loss: 2.0056e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.3220e-04 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 89/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 6.1155e-04 - val_accuracy: 0.9995 - val_loss: 0.0020\n",
      "Epoch 90/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.3232e-04 - val_accuracy: 0.9991 - val_loss: 0.0018\n",
      "Epoch 91/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 8.8397e-04 - val_accuracy: 0.9986 - val_loss: 0.0046\n",
      "Epoch 92/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9986 - val_loss: 0.0028\n",
      "Epoch 93/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0072 - val_accuracy: 0.9319 - val_loss: 0.2366\n",
      "Epoch 94/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 7.6440e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 9.4061e-04 - val_accuracy: 0.9986 - val_loss: 0.0055\n",
      "Epoch 96/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9920 - val_loss: 0.0222\n",
      "Epoch 97/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9943 - val_loss: 0.0140\n",
      "Epoch 98/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.9650 - val_loss: 0.1918\n",
      "Epoch 99/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9991 - val_loss: 0.0015\n",
      "Epoch 100/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 101/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9967 - val_loss: 0.0074\n",
      "Epoch 102/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9981 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0319 - val_accuracy: 0.9811 - val_loss: 0.0680\n",
      "Epoch 104/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0015 - val_accuracy: 0.9991 - val_loss: 0.0033\n",
      "Epoch 105/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9991 - val_loss: 0.0020\n",
      "Epoch 106/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.5209e-04 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
      "Epoch 107/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.8014e-04 - val_accuracy: 0.9939 - val_loss: 0.0225\n",
      "Epoch 109/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9982 - loss: 0.0040 - val_accuracy: 0.9981 - val_loss: 0.0052\n",
      "Epoch 110/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.8885e-04 - val_accuracy: 0.9995 - val_loss: 0.0030\n",
      "Epoch 111/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9527 - val_loss: 0.1914\n",
      "Epoch 112/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9787 - val_loss: 0.0809\n",
      "Epoch 113/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 5.4900e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 8.6713e-04 - val_accuracy: 0.9995 - val_loss: 6.6377e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.9581e-04 - val_accuracy: 0.9768 - val_loss: 0.1099\n",
      "Epoch 116/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9943 - val_loss: 0.0193\n",
      "Epoch 117/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9858 - val_loss: 0.0435\n",
      "Epoch 118/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9863 - val_loss: 0.0422\n",
      "Epoch 119/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9981 - val_loss: 0.0081\n",
      "Epoch 120/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 3.8442e-04 - val_accuracy: 1.0000 - val_loss: 2.3134e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
      "Epoch 122/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9991 - val_loss: 0.0033\n",
      "Epoch 123/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.2460e-04 - val_accuracy: 0.9972 - val_loss: 0.0109\n",
      "Epoch 124/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.5114e-04 - val_accuracy: 0.9636 - val_loss: 0.2583\n",
      "Epoch 125/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 2.8324e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 127/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 3.3478e-04 - val_accuracy: 0.9991 - val_loss: 0.0030\n",
      "Epoch 128/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 6.4167e-04 - val_accuracy: 0.9995 - val_loss: 0.0010\n",
      "Epoch 129/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9986 - val_loss: 0.0027\n",
      "Epoch 130/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.9981 - val_loss: 0.0049\n",
      "Epoch 131/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9986 - val_loss: 0.0025\n",
      "Epoch 132/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9929 - val_loss: 0.0203\n",
      "Epoch 133/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.0832e-04 - val_accuracy: 1.0000 - val_loss: 1.9315e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.4569e-04 - val_accuracy: 0.9991 - val_loss: 0.0044\n",
      "Epoch 135/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.2946e-04 - val_accuracy: 1.0000 - val_loss: 1.9285e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5209e-04 - val_accuracy: 0.9986 - val_loss: 0.0038\n",
      "Epoch 137/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9609e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 138/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5292e-04 - val_accuracy: 1.0000 - val_loss: 1.1986e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.6662e-05 - val_accuracy: 0.9991 - val_loss: 7.9427e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.3022e-05 - val_accuracy: 1.0000 - val_loss: 3.5284e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.7151e-04 - val_accuracy: 1.0000 - val_loss: 2.9056e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.9456e-05 - val_accuracy: 0.9995 - val_loss: 5.7228e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.8771 - val_loss: 0.6497\n",
      "Epoch 144/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0121 - val_accuracy: 0.9991 - val_loss: 0.0019\n",
      "Epoch 145/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
      "Epoch 146/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 6.6215e-04 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
      "Epoch 147/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 6.3847e-04 - val_accuracy: 0.9991 - val_loss: 0.0014\n",
      "Epoch 148/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.2049e-04 - val_accuracy: 0.9986 - val_loss: 0.0106\n",
      "Epoch 149/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8223e-04 - val_accuracy: 0.9991 - val_loss: 0.0034\n",
      "Epoch 150/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.9924 - val_loss: 0.0165\n",
      "Epoch 151/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.8223e-04 - val_accuracy: 1.0000 - val_loss: 4.5454e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3070e-04 - val_accuracy: 0.9991 - val_loss: 0.0032\n",
      "Epoch 153/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1227e-04 - val_accuracy: 1.0000 - val_loss: 2.2734e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 0.9924 - val_loss: 0.0238\n",
      "Epoch 155/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0025\n",
      "Epoch 156/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9987 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0031\n",
      "Epoch 157/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 6.1542e-04 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
      "Epoch 158/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 5.7221e-04 - val_accuracy: 0.9995 - val_loss: 7.5876e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.9924e-04 - val_accuracy: 1.0000 - val_loss: 1.7710e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.1317e-04 - val_accuracy: 0.9995 - val_loss: 4.4939e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.4790e-05 - val_accuracy: 0.9995 - val_loss: 6.3981e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2705e-04 - val_accuracy: 0.9929 - val_loss: 0.0384\n",
      "Epoch 163/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0172 - val_accuracy: 0.9991 - val_loss: 0.0035\n",
      "Epoch 164/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0107 - val_accuracy: 0.9981 - val_loss: 0.0146\n",
      "Epoch 165/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.0850e-04 - val_accuracy: 0.9991 - val_loss: 0.0040\n",
      "Epoch 166/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.5673e-04 - val_accuracy: 0.9981 - val_loss: 0.0095\n",
      "Epoch 167/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.9118e-04 - val_accuracy: 0.9702 - val_loss: 0.2022\n",
      "Epoch 168/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 3.8973e-04 - val_accuracy: 0.9962 - val_loss: 0.0161\n",
      "Epoch 169/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 8.0039e-04 - val_accuracy: 0.9797 - val_loss: 0.1093\n",
      "Epoch 170/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0109 - val_accuracy: 0.9811 - val_loss: 0.0718\n",
      "Epoch 171/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0061 - val_accuracy: 0.9764 - val_loss: 0.1200\n",
      "Epoch 172/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9986 - val_loss: 0.0028\n",
      "Epoch 173/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.6487e-04 - val_accuracy: 0.9745 - val_loss: 0.1285\n",
      "Epoch 174/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0083 - val_accuracy: 0.9948 - val_loss: 0.0264\n",
      "Epoch 175/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 5.8591e-04 - val_accuracy: 0.9976 - val_loss: 0.0079\n",
      "Epoch 176/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.5409e-04 - val_accuracy: 0.9976 - val_loss: 0.0066\n",
      "Epoch 177/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3184e-04 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 178/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3703e-04 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 179/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.9991 - val_loss: 0.0011\n",
      "Epoch 180/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.5330e-04 - val_accuracy: 0.9995 - val_loss: 0.0022\n",
      "Epoch 181/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.1440e-05 - val_accuracy: 0.9995 - val_loss: 0.0015\n",
      "Epoch 182/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3663e-04 - val_accuracy: 0.9976 - val_loss: 0.0070\n",
      "Epoch 183/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1755e-04 - val_accuracy: 0.9929 - val_loss: 0.0295\n",
      "Epoch 184/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2746e-04 - val_accuracy: 0.9995 - val_loss: 0.0042\n",
      "Epoch 185/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.8327e-05 - val_accuracy: 0.9995 - val_loss: 5.8352e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.1334e-05 - val_accuracy: 0.9995 - val_loss: 0.0012\n",
      "Epoch 187/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2908e-04 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
      "Epoch 188/200\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.1663e-05 - val_accuracy: 0.9995 - val_loss: 0.0043\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Total Computation Time: 5207.75 seconds (86.80 minutes)\n",
      "Train Accuracy: 99.98%\n",
      "Test Accuracy: 99.93%\n",
      "Train Precision: 99.98%\n",
      "Test Precision: 99.93%\n",
      "Train Recall: 99.98%\n",
      "Test Recall: 99.93%\n",
      "Train Log Loss: 0.0003\n",
      "Test Log Loss: 0.0017\n",
      "Train Balanced Accuracy: 99.98%\n",
      "Test Balanced Accuracy: 99.93%\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def time_series_stratified_split(X, y, train_ratio=0.8):\n",
    "    num_classes = y.shape[1]\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        cls_indices = np.where(np.argmax(y, axis=1) == cls)[0]\n",
    "        n_train = int(train_ratio * len(cls_indices))\n",
    "        train_idx, test_idx = cls_indices[:n_train], cls_indices[n_train:]\n",
    "        X_train.append(X[train_idx])\n",
    "        y_train.append(y[train_idx])\n",
    "        X_test.append(X[test_idx])\n",
    "        y_test.append(y[test_idx])\n",
    "\n",
    "    return (\n",
    "        np.concatenate(X_train),\n",
    "        np.concatenate(y_train),\n",
    "        np.concatenate(X_test),\n",
    "        np.concatenate(y_test)\n",
    "    )\n",
    "\n",
    "# Split original data\n",
    "X_train, y_train, X_test, y_test = time_series_stratified_split(X_train, y_train_positional)\n",
    "\n",
    "print(\"Original data split:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "X_1D_train = X_train_split.reshape([-1, samples_per_block, 1])\n",
    "X_1D_test = X_test_split.reshape([-1, samples_per_block, 1])\n",
    "input_shape = (samples_per_block, 1)   # Reshaped input\n",
    "\n",
    "class CNN_1D():\n",
    "    def __init__(self):\n",
    "        self.model = self.CreateModel()\n",
    "        self.model.summary()\n",
    "\n",
    "    def CreateModel(self):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "            \n",
    "            layers.Conv1D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Optimizer with a slightly higher learning rate\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "# Training with k-fold validation\n",
    "kSplits = 5\n",
    "kfold = KFold(n_splits=kSplits, random_state=32, shuffle=True)\n",
    "accuracy_1D = []\n",
    "precision_1D = []\n",
    "recall_1D = []\n",
    "log_loss_1D = []\n",
    "balanced_accuracy_1D = []  # Store balanced accuracy for each fold\n",
    "accuracy_1D_test = []\n",
    "precision_1D_test = []\n",
    "recall_1D_test = []\n",
    "log_loss_1D_test = []\n",
    "balanced_accuracy_1D_test = []  # Store balanced accuracy for test set\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X_1D_train, y_train_positional_split):\n",
    "    Classification_1D = CNN_1D()\n",
    "    Classification_1D.model.fit(X_1D_train[train_idx], y_train_positional_split[train_idx],\n",
    "                                validation_data=(X_1D_train[test_idx], y_train_positional_split[test_idx]),\n",
    "                                epochs=200, callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    # Train set metrics\n",
    "    y_pred_proba_train = Classification_1D.model.predict(X_1D_train)\n",
    "    y_pred_train = np.argmax(y_pred_proba_train, axis=1)\n",
    "    y_true_train = np.argmax(y_train_positional_split, axis=1)\n",
    "\n",
    "    accuracy_1D.append(accuracy_score(y_true_train, y_pred_train))\n",
    "    precision_1D.append(precision_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    recall_1D.append(recall_score(y_true_train, y_pred_train, average='weighted'))\n",
    "    log_loss_1D.append(log_loss(y_true_train, y_pred_proba_train))\n",
    "    balanced_accuracy_1D.append(balanced_accuracy_score(y_true_train, y_pred_train))  # Balanced accuracy for train set\n",
    "    \n",
    "    # Test set metrics\n",
    "    y_pred_proba_test = Classification_1D.model.predict(X_1D_test)\n",
    "    y_pred_test = np.argmax(y_pred_proba_test, axis=1)\n",
    "    y_true_test = np.argmax(y_test_positional_split, axis=1)\n",
    "\n",
    "    accuracy_1D_test.append(accuracy_score(y_true_test, y_pred_test))\n",
    "    precision_1D_test.append(precision_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    recall_1D_test.append(recall_score(y_true_test, y_pred_test, average='weighted'))\n",
    "    log_loss_1D_test.append(log_loss(y_true_test, y_pred_proba_test))\n",
    "    balanced_accuracy_1D_test.append(balanced_accuracy_score(y_true_test, y_pred_test))  # Balanced accuracy for test set\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total Computation Time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "\n",
    "# Aggregated metrics\n",
    "CNN_1D_train_accuracy = np.mean(accuracy_1D) * 100\n",
    "CNN_1D_test_accuracy = np.mean(accuracy_1D_test) * 100\n",
    "CNN_1D_train_precision = np.mean(precision_1D) * 100\n",
    "CNN_1D_test_precision = np.mean(precision_1D_test) * 100\n",
    "CNN_1D_train_recall = np.mean(recall_1D) * 100\n",
    "CNN_1D_test_recall = np.mean(recall_1D_test) * 100\n",
    "CNN_1D_train_log_loss = np.mean(log_loss_1D)\n",
    "CNN_1D_test_log_loss = np.mean(log_loss_1D_test)\n",
    "CNN_1D_train_balanced_accuracy = np.mean(balanced_accuracy_1D) * 100  # Average balanced accuracy for train set\n",
    "CNN_1D_test_balanced_accuracy = np.mean(balanced_accuracy_1D_test) * 100  # Average balanced accuracy for test set\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Train Accuracy: {CNN_1D_train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {CNN_1D_test_accuracy:.2f}%\")\n",
    "print(f\"Train Precision: {CNN_1D_train_precision:.2f}%\")\n",
    "print(f\"Test Precision: {CNN_1D_test_precision:.2f}%\")\n",
    "print(f\"Train Recall: {CNN_1D_train_recall:.2f}%\")\n",
    "print(f\"Test Recall: {CNN_1D_test_recall:.2f}%\")\n",
    "print(f\"Train Log Loss: {CNN_1D_train_log_loss:.4f}\")\n",
    "print(f\"Test Log Loss: {CNN_1D_test_log_loss:.4f}\")\n",
    "print(f\"Train Balanced Accuracy: {CNN_1D_train_balanced_accuracy:.2f}%\")\n",
    "print(f\"Test Balanced Accuracy: {CNN_1D_test_balanced_accuracy:.2f}%\")\n",
    "\n",
    "# Confusion Matrix Calculation\n",
    "# def ConfusionMatrix(Model, X, y):\n",
    "#     y_pred = np.argmax(Model.model.predict(X), axis=1)\n",
    "#     ConfusionMat = confusion_matrix(np.argmax(y, axis=1), y_pred)\n",
    "#     return ConfusionMat\n",
    "\n",
    "def ConfusionMatrix(Model, X, y):\n",
    "    y_pred_proba = Model.model.predict(X)  # Use Model.model instead of Model\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class labels\n",
    "    y_true = np.argmax(y, axis=1)  # Convert one-hot labels to class indices\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot results - CNN 1D\n",
    "plt.figure(1)\n",
    "plt.title('Confusion Matrix - CNN 1D Train')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_train, y_train_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('Confusion Matrix - CNN 1D Test')\n",
    "sns.heatmap(ConfusionMatrix(Classification_1D, X_1D_test, y_test_positional_split), annot=True, fmt='d', annot_kws={\"fontsize\":8}, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title('Train - Accuracy - CNN 1D')\n",
    "plt.bar(np.arange(1, kSplits + 1), [i * 100 for i in accuracy_1D])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('folds')\n",
    "plt.ylim([70, 100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title('Train vs Test Accuracy - CNN 1D')\n",
    "plt.bar([1, 2], [CNN_1D_train_accuracy, CNN_1D_test_accuracy])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('sets')\n",
    "plt.xticks([1, 2], ['Train', 'Test'])\n",
    "plt.ylim([70, 100])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
